# ALMA Railway Deployment Guide

**Decision Chain**: DECISION_146 (Architecture) → DECISION_165 (Success Criteria)  
**Owner**: OpenFixer  
**Date**: 2026-02-26  

---

## 1. Credentials List (What to Gather)

These are the secrets you need before deployment. Each one must be stored in the vault after gathering.

### Required (Deployment Will Not Work Without These)

| # | Credential | Where to Get It | Vault Key | Notes |
|---|-----------|----------------|-----------|-------|
| 1 | **SETUP_PASSWORD** | You create it (any strong password) | `railway.setup_password` | Gates the `/setup` wizard. Use `openssl rand -hex 16` or similar. |
| 2 | **Model Provider API Key** | One of: OpenAI, Anthropic, OpenRouter, etc. | `railway.model_api_key` | At least ONE model provider key is required during `/setup` wizard. Choose based on budget. |

### Required (Auto-Generated If Not Provided, But Should Be Explicit)

| # | Credential | Where to Get It | Vault Key | Notes |
|---|-----------|----------------|-----------|-------|
| 3 | **OPENCLAW_GATEWAY_TOKEN** | You create it (`openssl rand -hex 32`) | `railway.gateway_token` | Auth token for Control UI + gateway API. The wrapper auto-generates one if not set, but you should set it explicitly for stability across redeploys. |

### Required for Channels (At Least One Channel Needed)

| # | Credential | Where to Get It | Vault Key | Notes |
|---|-----------|----------------|-----------|-------|
| 4 | **Telegram Bot Token** | @BotFather in Telegram → `/newbot` | `channel.telegram.bot_token` | Format: `123456789:AABBcc...`. This is the primary channel for Nate. |
| 5 | **Discord Bot Token** *(optional)* | [Discord Developer Portal](https://discord.com/developers/applications) → New App → Bot | `channel.discord.bot_token` | Enable MESSAGE CONTENT INTENT. Only if Nate wants Discord. |
| 6 | **Slack Bot/App Token** *(optional)* | [Slack API](https://api.slack.com/apps) → Create App | `channel.slack.bot_token` | Only if Nate wants Slack. |

### Post-Deploy Captures (Generated During First Deploy)

| # | Credential | Where to Get It | Vault Key | Notes |
|---|-----------|----------------|-----------|-------|
| 7 | **MONGO_URL** | Railway dashboard → MongoDB service → Variables tab → `MONGO_URL` | `railway.mongo_url` | Auto-generated by Railway MongoDB template. Copy for break-glass access. |
| 8 | **Railway Domain** | Railway dashboard → Service → Settings → Domains | `railway.domain` | The public HTTPS URL (e.g., `alma-xxx.up.railway.app`). |
| 9 | **SFTPGo Host Key Fingerprint** *(if SFTPGo enabled)* | `ssh-keyscan -p $PORT $HOST` after first deploy | `sftpgo.hostkey_fingerprint` | Phase 2 — only if SFTPGo sidecar is added. |

### Summary: Minimum Viable Deploy

To deploy ALMA with Telegram as the only channel, you need exactly **4 things**:

1. ✅ `SETUP_PASSWORD` — you make this up
2. ✅ `OPENCLAW_GATEWAY_TOKEN` — you generate this
3. ✅ A model provider API key (OpenAI/Anthropic/OpenRouter/etc.)
4. ✅ A Telegram bot token from @BotFather

---

## 2. Systems Configuration List (What Needs Configuring)

### A. Railway Dashboard Configuration

These are set in Railway → Service → Variables tab:

| Variable | Value | Required | Source |
|----------|-------|----------|--------|
| `SETUP_PASSWORD` | Your password from vault | **Yes** | You create |
| `OPENCLAW_GATEWAY_TOKEN` | Your token from vault | Recommended | You generate |
| `PORT` | `8080` | Yes (preset) | Template default |
| `OPENCLAW_STATE_DIR` | `/data/.openclaw` | Recommended | Template default |
| `OPENCLAW_WORKSPACE_DIR` | `/data/workspace` | Recommended | Template default |
| `MONGO_URL` | Railway MongoDB connection string | After MongoDB added | Railway auto-populates |

### B. Railway Volume

| Setting | Value | Notes |
|---------|-------|-------|
| Mount path | `/data` | **Critical** — without this, all state is lost on redeploy |
| Size | Start with 1 GB | Scale as needed |

### C. Railway Networking

| Setting | Value | Notes |
|---------|-------|-------|
| HTTP Proxy | Port `8080` | Must be enabled for public access |
| Custom Domain | Optional | Can attach later |

### D. MongoDB (Separate Railway Service)

| Setting | Value | Notes |
|---------|-------|-------|
| Template | Official Railway MongoDB | One-click add |
| TCP Proxy | **Disabled** | Private network only (security) |
| Connection | Private networking (`mongodb://mongo.railway.internal:27017/...`) | Auto-populated by Railway |

### E. OpenClaw Configuration (`/data/.openclaw/openclaw.json`)

This is configured AFTER deployment via the `/setup` wizard, but here's the target state:

```json5
{
  // Model provider (set during /setup wizard)
  // The wizard handles this — just have your API key ready

  // Agent workspace
  agents: {
    defaults: {
      workspace: "/data/workspace",
      // Model is set via /setup wizard
    }
  },

  // Telegram channel (configured via /setup wizard OR post-deploy CLI)
  channels: {
    telegram: {
      enabled: true,
      botToken: "YOUR_BOT_TOKEN",        // From @BotFather
      dmPolicy: "pairing",               // Default: pairing code approval
      groups: {
        "*": { requireMention: true }     // Require @mention in groups
      },
      groupPolicy: "allowlist",           // Only approved groups
      streaming: "partial"               // Live message preview
    }
  }
}
```

### F. Workspace Pre-Population

The deploy template's `OPENCLAW_WORKSPACE_DIR` points to `/data/workspace`. The workspace files from `dev/` need to exist there. Two approaches:

**Option A: SFTP Upload (Post-Deploy)**
- Upload `dev/*` to the Railway container's `/data/workspace/` via SFTPGo (Phase 2) or Railway CLI.

**Option B: Bake Into Docker Image (Recommended for First Deploy)**
- Add workspace COPY to the Dockerfile. This seeds the volume on first deploy.
- After first deploy, the volume persists and subsequent deploys won't overwrite.

```dockerfile
# Add after the existing COPY src line:
COPY workspace/ /data/workspace/
```

---

## 3. Deployment Sequence (Step by Step)

### Phase 1: Pre-Deploy (Local Machine)

```
1. Initialize vault and store credentials:
   cd C:\P4NTH30N\OP3NF1XER\nate-alma\secrets
   python vault.py init
   # Save the key securely!
   
   $env:ALMA_VAULT_KEY = "<your-key>"
   python vault.py set railway.setup_password "<password>"
   python vault.py set railway.gateway_token "<token>"
   python vault.py set railway.model_api_key "<api-key>"
   python vault.py set channel.telegram.bot_token "<bot-token>"

2. Prepare deploy directory:
   - Copy workspace files into deploy/workspace/ (for Docker bake)
   - Or plan to upload via /setup wizard post-deploy

3. Push to GitHub:
   cd C:\P4NTH30N\OP3NF1XER\nate-alma\deploy
   git init && git add . && git commit -m "Initial ALMA Railway deployment"
   git remote add origin <your-github-repo>
   git push -u origin main
```

### Phase 2: Railway Setup

```
1. Go to Railway dashboard → New Project → Deploy from GitHub repo
2. Connect your GitHub repo
3. Add Volume: mount at /data
4. Set Variables:
   - SETUP_PASSWORD = <from vault>
   - OPENCLAW_GATEWAY_TOKEN = <from vault>
   - PORT = 8080
   - OPENCLAW_STATE_DIR = /data/.openclaw
   - OPENCLAW_WORKSPACE_DIR = /data/workspace
5. Add MongoDB: New Service → MongoDB template
6. Wait for deploy to complete (watch build logs)
```

### Phase 3: Post-Deploy Configuration

```
1. Open https://<your-domain>/setup
2. Enter SETUP_PASSWORD when prompted (Basic Auth)
3. Choose model provider, paste API key
4. Configure Telegram: paste bot token
5. Click "Run setup"
6. Verify: https://<your-domain>/setup/healthz should show:
   { "ok": true, "configured": true, "gatewayRunning": true }
```

### Phase 4: Channel Activation

```
1. DM your Telegram bot — you'll get a pairing code
2. Approve via /setup wizard OR Control UI:
   https://<your-domain>/openclaw
3. Test: send a message to the bot
```

### Phase 5: Validation Evidence

Capture these for deployment proof (DECISION_165 requirement):

```bash
# Health check
curl -i https://<domain>/healthz

# Setup status
curl -u admin:<SETUP_PASSWORD> https://<domain>/setup/api/status

# Control UI accessible
curl -I https://<domain>/openclaw
```

---

## 4. Deployment Architecture

```
┌─────────────────────────────────────────────────┐
│              Railway Project                     │
│                                                  │
│  ┌────────────────────────────────────────────┐  │
│  │        ALMA Service (openclaw)              │  │
│  │                                             │  │
│  │  Wrapper (server.js) :8080  ──────┐        │  │
│  │  │ /setup, /healthz, proxy        │        │  │
│  │  │                                │        │  │
│  │  └──→ OpenClaw Gateway :18789     │        │  │
│  │       │ Agent runtime             │        │  │
│  │       │ Telegram/Discord/etc.     │        │  │
│  │       │ Memory/retrieval          │        │  │
│  │                                             │  │
│  │  Volume: /data ─────────────────────────── │  │
│  │  ├── .openclaw/                    ←state  │  │
│  │  │   ├── openclaw.json                     │  │
│  │  │   ├── credentials/                      │  │
│  │  │   └── agents/                           │  │
│  │  └── workspace/                   ←agent   │  │
│  │      ├── AGENTS.md                         │  │
│  │      ├── SOUL.md                           │  │
│  │      ├── memory/                           │  │
│  │      └── skills/                           │  │
│  └────────────────────────────────────────────┘  │
│                                                  │
│  ┌────────────────────────────────────────────┐  │
│  │     MongoDB Service (private network)       │  │
│  │     mongodb://mongo.railway.internal:27017  │  │
│  └────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────┘
```

---

## 5. What About Ollama? (Phase 2)

DECISION_146 specifies Ollama for free local LLM inference. However:

- **Railway's free tier** does not provide GPU access
- **Railway Pro** can allocate GPU, but Ollama + large models requires significant resources
- **Recommendation**: Start with a cloud model provider (OpenAI/Anthropic/OpenRouter) for Phase 1
- **Phase 2**: Add Ollama when GPU access is confirmed and budget allows

If you decide to add Ollama to the container:
```dockerfile
# Add to Dockerfile before USER openclaw
RUN curl -fsSL https://ollama.com/install.sh | sh
```

And add to entrypoint:
```bash
# Start Ollama in background
ollama serve &
sleep 5
ollama pull llama3.3
```

But this requires ~8GB+ RAM and ideally GPU access. **Defer unless Nexus explicitly wants it.**

---

## 6. SFTPGo (Phase 2)

SFTPGo for file transfer is Phase 2. Requires:
- TCP Proxy on Railway (separate port)
- SSH key generation for operator access
- Host key fingerprint capture

**Not needed for initial deployment.** Add when file transfer to the workspace is needed beyond the initial bake.

---

## 7. Post-Deploy Operations

### Backup
```
curl -u admin:<SETUP_PASSWORD> https://<domain>/setup/export -o alma-backup.zip
```

### View Logs
```
# Railway dashboard → Service → Logs tab
# Or via railway CLI:
railway logs
```

### Update Workspace
```
# Option A: Via /setup/export + modify + redeploy
# Option B: Via SFTPGo (Phase 2)
# Option C: Via Railway CLI shell
railway shell
# then edit files in /data/workspace/
```

### Rotate Gateway Token
```
# Generate new token
openssl rand -hex 32

# Update in Railway Variables
# Redeploy service
```

---

## 8. Troubleshooting

| Symptom | Cause | Fix |
|---------|-------|-----|
| `/setup` returns 500 | `SETUP_PASSWORD` not set in Railway vars | Add it in Variables tab |
| Gateway never starts | Config not created (wizard not run) | Visit `/setup` and complete wizard |
| Telegram bot doesn't respond | Bot token wrong or not configured | Check via `/setup/api/debug` |
| Data lost after redeploy | Volume not mounted at `/data` | Add Volume in Railway dashboard |
| `configured: false` after setup | Config write failed | Check Railway logs, re-run `/setup` |
| 503 / "Gateway unavailable" | Gateway starting up (takes ~30s) | Wait, then refresh |

---

*Generated by OpenFixer per DECISION_146 + DECISION_165*
