{
  "version": "2026-02-14",
  "source": "AA API (399 models) + OpenRouter + Scraped Leaderboards",
  "models": {
    "gpt-oss-120B (low)": {
      "id": "c99f3bde-7c08-4de8-bd5c-8ee9123ebffa",
      "name": "gpt-oss-120B (low)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.775,
        "gpqa": 0.672,
        "ifbench": 0.583,
        "aime": null,
        "math_index": 66.7,
        "terminalbench_hard": 0.053,
        "tau2": 0.45,
        "hle": 0.052,
        "scicode": 0.36,
        "livecodebench": 0.707,
        "coding_index": 15.5,
        "intelligence_index": 23.9,
        "speed": 317.58,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.7731,
        "Oracle": 10.421100000000001,
        "Explorer": 0.9888,
        "Librarian": 2.62515,
        "Designer": 1.12275,
        "Fixer": 1.1140499999999998,
        "Builder": 1.79115
      },
      "lastCalculated": "2026-02-14"
    },
    "gpt-oss-20B (low)": {
      "id": "16149b9c-a1e9-4669-a5cb-ff3c00d78f89",
      "name": "gpt-oss-20B (low)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.718,
        "gpqa": 0.611,
        "ifbench": 0.578,
        "aime": null,
        "math_index": 62.3,
        "terminalbench_hard": 0.045,
        "tau2": 0.503,
        "hle": 0.051,
        "scicode": 0.34,
        "livecodebench": 0.652,
        "coding_index": 14.4,
        "intelligence_index": 20.8,
        "speed": 290.835,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.4469,
        "Oracle": 9.724849999999998,
        "Explorer": 0.9381,
        "Librarian": 2.3110999999999997,
        "Designer": 1.04335,
        "Fixer": 1.035725,
        "Builder": 1.6637000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "gpt-oss-120B (high)": {
      "id": "f0083258-8646-45b8-8082-7aaf6c2ea82a",
      "name": "gpt-oss-120B (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.808,
        "gpqa": 0.782,
        "ifbench": 0.69,
        "aime": null,
        "math_index": 93.4,
        "terminalbench_hard": 0.235,
        "tau2": 0.658,
        "hle": 0.185,
        "scicode": 0.389,
        "livecodebench": 0.878,
        "coding_index": 28.6,
        "intelligence_index": 33.3,
        "speed": 310.09,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.7769,
        "Oracle": 14.49105,
        "Explorer": 1.77855,
        "Librarian": 3.6414999999999997,
        "Designer": 1.8342,
        "Fixer": 1.8439750000000001,
        "Builder": 3.1448
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5.2 (Non-reasoning)": {
      "id": "6dd8ba55-5680-44a9-b309-82928165d5f0",
      "name": "GPT-5.2 (Non-reasoning)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.814,
        "gpqa": 0.712,
        "ifbench": 0.474,
        "aime": null,
        "math_index": 51,
        "terminalbench_hard": 0.318,
        "tau2": 0.465,
        "hle": 0.073,
        "scicode": 0.404,
        "livecodebench": 0.669,
        "coding_index": 34.7,
        "intelligence_index": 33.5,
        "speed": 78.951,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 73.6,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 394.6321,
        "Oracle": 8.091050000000001,
        "Explorer": 2.0635000000000003,
        "Librarian": 3.5879000000000003,
        "Designer": 392.98979999999995,
        "Fixer": 19.407774999999997,
        "Builder": 34.63994999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "gpt-oss-20B (high)": {
      "id": "36f73aaf-d38a-4b56-a2b3-d04d17186910",
      "name": "gpt-oss-20B (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.748,
        "gpqa": 0.688,
        "ifbench": 0.651,
        "aime": null,
        "math_index": 89.3,
        "terminalbench_hard": 0.106,
        "tau2": 0.602,
        "hle": 0.098,
        "scicode": 0.344,
        "livecodebench": 0.777,
        "coding_index": 18.5,
        "intelligence_index": 24.5,
        "speed": 310.733,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.85765,
        "Oracle": 13.818699999999998,
        "Explorer": 1.1976,
        "Librarian": 2.7169000000000003,
        "Designer": 1.2841,
        "Fixer": 1.28635,
        "Builder": 2.1053
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5.2 (xhigh)": {
      "id": "498862c3-f9ac-49d2-852f-16a02bb0c38f",
      "name": "GPT-5.2 (xhigh)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.874,
        "gpqa": 0.903,
        "ifbench": 0.754,
        "aime": null,
        "math_index": 99,
        "terminalbench_hard": 0.47,
        "tau2": 0.848,
        "hle": 0.354,
        "scicode": 0.521,
        "livecodebench": 0.889,
        "coding_index": 48.7,
        "intelligence_index": 51.2,
        "speed": 99.222,
        "context_length": null,
        "GDPval_AA_ELO": 1462,
        "SWE_bench_Verified": 73.6,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 444.22959999999995,
        "Oracle": 15.4066,
        "Explorer": 2.9401000000000006,
        "Librarian": 5.517500000000002,
        "Designer": 441.50264999999996,
        "Fixer": 20.217125000000003,
        "Builder": 36.109049999999996
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 mini (high)": {
      "id": "29855680-7469-43eb-8b88-cd3fb1d99da3",
      "name": "GPT-5 mini (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.837,
        "gpqa": 0.828,
        "ifbench": 0.754,
        "aime": null,
        "math_index": 90.7,
        "terminalbench_hard": 0.333,
        "tau2": 0.684,
        "hle": 0.197,
        "scicode": 0.392,
        "livecodebench": 0.838,
        "coding_index": 35.3,
        "intelligence_index": 41,
        "speed": 96.645,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 395.47264999999993,
        "Oracle": 14.11255,
        "Explorer": 2.16275,
        "Librarian": 4.428450000000001,
        "Designer": 393.09264999999994,
        "Fixer": 18.723499999999998,
        "Builder": 33.45204999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "o3": {
      "id": "16c5b637-8bce-4252-81f2-1b87a36a4e4c",
      "name": "o3",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.853,
        "gpqa": 0.827,
        "ifbench": 0.714,
        "aime": 0.903,
        "math_index": 88.3,
        "terminalbench_hard": 0.371,
        "tau2": 0.807,
        "hle": 0.2,
        "scicode": 0.41,
        "livecodebench": 0.808,
        "coding_index": 38.4,
        "intelligence_index": 38.3,
        "speed": 92.164,
        "context_length": 200000,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 4.3111500000000005,
        "Oracle": 13.934399999999998,
        "Explorer": 2.3940875403789317,
        "Librarian": 4.217779233964887,
        "Designer": 2.355645846792977,
        "Fixer": 2.353775,
        "Builder": 4.12225
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok-1": {
      "id": "4c111fbc-d13a-42b4-858c-1dc17fe3c1d1",
      "name": "Grok-1",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 11.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.17,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 1.17,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5.2 (medium)": {
      "id": "84e3f11e-d659-4941-8988-1dbfabbaf538",
      "name": "GPT-5.2 (medium)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.859,
        "gpqa": 0.864,
        "ifbench": 0.652,
        "aime": null,
        "math_index": 96.7,
        "terminalbench_hard": 0.432,
        "tau2": 0.743,
        "hle": 0.249,
        "scicode": 0.462,
        "livecodebench": 0.894,
        "coding_index": 44.2,
        "intelligence_index": 46.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": 1418,
        "SWE_bench_Verified": 73.6,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 430.53375,
        "Oracle": 15.03535,
        "Explorer": 2.6669000000000005,
        "Librarian": 5.00305,
        "Designer": 428.04495,
        "Fixer": 19.972524999999994,
        "Builder": 35.65004999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5.1 Codex (high)": {
      "id": "04d023f3-025c-4d78-9571-53edda3eaf2a",
      "name": "GPT-5.1 Codex (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.86,
        "gpqa": 0.86,
        "ifbench": 0.7,
        "aime": null,
        "math_index": 95.7,
        "terminalbench_hard": 0.348,
        "tau2": 0.83,
        "hle": 0.234,
        "scicode": 0.402,
        "livecodebench": 0.849,
        "coding_index": 36.6,
        "intelligence_index": 42.2,
        "speed": 142.6,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 395.6090000000001,
        "Oracle": 14.8827,
        "Explorer": 2.2744,
        "Librarian": 4.572200000000001,
        "Designer": 393.16739999999993,
        "Fixer": 18.799949999999995,
        "Builder": 33.58535
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5.1 Codex mini (high)": {
      "id": "fd4454ff-e703-46c0-a7f5-fa69af09486d",
      "name": "GPT-5.1 Codex mini (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.82,
        "gpqa": 0.813,
        "ifbench": 0.679,
        "aime": null,
        "math_index": 91.7,
        "terminalbench_hard": 0.333,
        "tau2": 0.629,
        "hle": 0.169,
        "scicode": 0.426,
        "livecodebench": 0.836,
        "coding_index": 36.4,
        "intelligence_index": 38.5,
        "speed": 101.226,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 395.20035,
        "Oracle": 14.25195,
        "Explorer": 2.2009,
        "Librarian": 4.1545,
        "Designer": 393.13105,
        "Fixer": 18.769975,
        "Builder": 33.55564999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 nano (high)": {
      "id": "e18e5e6a-5a31-4c0b-b80b-ac401392f446",
      "name": "GPT-5 nano (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.78,
        "gpqa": 0.676,
        "ifbench": 0.676,
        "aime": null,
        "math_index": 83.7,
        "terminalbench_hard": 0.121,
        "tau2": 0.365,
        "hle": 0.082,
        "scicode": 0.366,
        "livecodebench": 0.789,
        "coding_index": 20.3,
        "intelligence_index": 26.7,
        "speed": 130.592,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 393.9601,
        "Oracle": 12.975099999999998,
        "Explorer": 1.2367500000000002,
        "Librarian": 2.9157,
        "Designer": 392.2768,
        "Fixer": 17.903925,
        "Builder": 31.92275
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5.2 Codex (xhigh)": {
      "id": "019e86f6-e66b-42d8-8a50-235a06b53003",
      "name": "GPT-5.2 Codex (xhigh)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.899,
        "ifbench": 0.776,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.371,
        "tau2": 0.921,
        "hle": 0.335,
        "scicode": 0.546,
        "livecodebench": null,
        "coding_index": 43,
        "intelligence_index": 49,
        "speed": 91.613,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 73.6,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 396.18829999999997,
        "Oracle": 0.46625,
        "Explorer": 2.5454,
        "Librarian": 5.170200000000001,
        "Designer": 393.38584999999995,
        "Fixer": 19.704424999999993,
        "Builder": 35.3627
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.3 Instruct 70B": {
      "id": "976cc8ad-7904-4056-83c5-960181f47d5f",
      "name": "Llama 3.3 Instruct 70B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.713,
        "gpqa": 0.498,
        "ifbench": 0.471,
        "aime": 0.3,
        "math_index": 7.7,
        "terminalbench_hard": 0.03,
        "tau2": 0.266,
        "hle": 0.04,
        "scicode": 0.26,
        "livecodebench": 0.288,
        "coding_index": 10.7,
        "intelligence_index": 14.2,
        "speed": 105.826,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7238,
        "Oracle": 1.5372999999999999,
        "Explorer": 0.6868000000000001,
        "Librarian": 1.6126499999999997,
        "Designer": 0.81755,
        "Fixer": 0.7639,
        "Builder": 1.2222
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.1 Instruct 405B": {
      "id": "45c87531-2d57-48e0-8012-202cd636189e",
      "name": "Llama 3.1 Instruct 405B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.732,
        "gpqa": 0.515,
        "ifbench": 0.39,
        "aime": 0.213,
        "math_index": 3,
        "terminalbench_hard": 0.068,
        "tau2": 0.19,
        "hle": 0.042,
        "scicode": 0.299,
        "livecodebench": 0.305,
        "coding_index": 14.5,
        "intelligence_index": 14.2,
        "speed": 25.158,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7103,
        "Oracle": 0.8254,
        "Explorer": 0.8750000000000001,
        "Librarian": 1.6003999999999998,
        "Designer": 1.00675,
        "Fixer": 0.9597250000000002,
        "Builder": 1.6033500000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.2 Instruct 90B (Vision)": {
      "id": "9ca71ac4-41c8-42c0-87dd-5704a9e5b94d",
      "name": "Llama 3.2 Instruct 90B (Vision)",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.671,
        "gpqa": 0.432,
        "ifbench": null,
        "aime": 0.05,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.049,
        "scicode": 0.24,
        "livecodebench": 0.214,
        "coding_index": null,
        "intelligence_index": 11.9,
        "speed": 47.538,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.37705,
        "Oracle": 0.29555000000000003,
        "Explorer": 0.06955,
        "Librarian": 1.3053500000000002,
        "Designer": 0.21355,
        "Fixer": 0.16999999999999998,
        "Builder": 0.10885
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.2 Instruct 11B (Vision)": {
      "id": "5fb47ff6-a30e-4c2c-96f2-55e95a13390f",
      "name": "Llama 3.2 Instruct 11B (Vision)",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.464,
        "gpqa": 0.221,
        "ifbench": 0.304,
        "aime": 0.093,
        "math_index": 1.7,
        "terminalbench_hard": 0.008,
        "tau2": 0.146,
        "hle": 0.052,
        "scicode": 0.112,
        "livecodebench": 0.11,
        "coding_index": 4.3,
        "intelligence_index": 10.9,
        "speed": 69.651,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.264,
        "Oracle": 0.4331,
        "Explorer": 0.3037,
        "Librarian": 1.2202,
        "Designer": 0.37545,
        "Fixer": 0.3335,
        "Builder": 0.507
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 4 Scout": {
      "id": "adf9a85e-abc3-4f28-937b-db6655cc5238",
      "name": "Llama 4 Scout",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.752,
        "gpqa": 0.587,
        "ifbench": 0.395,
        "aime": 0.283,
        "math_index": 14,
        "terminalbench_hard": 0.015,
        "tau2": 0.155,
        "hle": 0.043,
        "scicode": 0.17,
        "livecodebench": 0.299,
        "coding_index": 6.7,
        "intelligence_index": 13.5,
        "speed": 150.641,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6549500000000001,
        "Oracle": 2.52745,
        "Explorer": 0.4571,
        "Librarian": 1.5307000000000002,
        "Designer": 0.63835,
        "Fixer": 0.572475,
        "Builder": 0.8309
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 4 Maverick": {
      "id": "922c69c7-9037-43c6-8bcf-a1c555e7f3eb",
      "name": "Llama 4 Maverick",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.809,
        "gpqa": 0.671,
        "ifbench": 0.43,
        "aime": 0.39,
        "math_index": 19.3,
        "terminalbench_hard": 0.068,
        "tau2": 0.178,
        "hle": 0.048,
        "scicode": 0.331,
        "livecodebench": 0.397,
        "coding_index": 15.6,
        "intelligence_index": 18.3,
        "speed": 127.946,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.16785,
        "Oracle": 3.3918000000000004,
        "Explorer": 0.935,
        "Librarian": 2.02655,
        "Designer": 1.1169,
        "Fixer": 1.0621250000000002,
        "Builder": 1.7486000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemma 3n E2B Instruct": {
      "id": "a8c67863-9d66-44dd-8d27-f58654ecde03",
      "name": "Gemma 3n E2B Instruct",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.378,
        "gpqa": 0.229,
        "ifbench": 0.22,
        "aime": 0.09,
        "math_index": 10.3,
        "terminalbench_hard": 0.008,
        "tau2": 0,
        "hle": 0.04,
        "scicode": 0.052,
        "livecodebench": 0.095,
        "coding_index": 2.2,
        "intelligence_index": 4.7,
        "speed": 32.111,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.6055,
        "Oracle": 1.7173000000000003,
        "Explorer": 0.15300000000000002,
        "Librarian": 0.5607000000000001,
        "Designer": 0.24995,
        "Fixer": 0.2095,
        "Builder": 0.28705
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 3 Pro Preview (low)": {
      "id": "b2f3191f-77d6-4155-8be6-330f0baa1ae5",
      "name": "Gemini 3 Pro Preview (low)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.895,
        "gpqa": 0.887,
        "ifbench": 0.497,
        "aime": null,
        "math_index": 86.7,
        "terminalbench_hard": 0.341,
        "tau2": 0.681,
        "hle": 0.276,
        "scicode": 0.499,
        "livecodebench": 0.857,
        "coding_index": 39.4,
        "intelligence_index": 41.1,
        "speed": 126.684,
        "context_length": null,
        "GDPval_AA_ELO": 1201,
        "SWE_bench_Verified": 77.4,
        "SWE_bench_Pro": 43.3
      },
      "roleScores": {
        "Orchestrator": 364.8643,
        "Oracle": 13.5518,
        "Explorer": 2.37995,
        "Librarian": 4.444850000000001,
        "Designer": 362.7033,
        "Fixer": 20.51455,
        "Builder": 36.56685
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemma 3 4B Instruct": {
      "id": "222fb320-6e55-4672-846a-b6d5a24a45f4",
      "name": "Gemma 3 4B Instruct",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.417,
        "gpqa": 0.291,
        "ifbench": 0.283,
        "aime": 0.063,
        "math_index": 12.7,
        "terminalbench_hard": 0.008,
        "tau2": 0.05,
        "hle": 0.052,
        "scicode": 0.073,
        "livecodebench": 0.112,
        "coding_index": 2.9,
        "intelligence_index": 6.3,
        "speed": 32.142,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.7982,
        "Oracle": 2.1074,
        "Explorer": 0.205,
        "Librarian": 0.74145,
        "Designer": 0.31379999999999997,
        "Fixer": 0.265175,
        "Builder": 0.37089999999999995
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 3 Pro Preview (high)": {
      "id": "d1122eff-ee85-4fdc-8a9f-23bee6590667",
      "name": "Gemini 3 Pro Preview (high)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.898,
        "gpqa": 0.908,
        "ifbench": 0.704,
        "aime": null,
        "math_index": 95.7,
        "terminalbench_hard": 0.417,
        "tau2": 0.871,
        "hle": 0.372,
        "scicode": 0.561,
        "livecodebench": 0.917,
        "coding_index": 46.5,
        "intelligence_index": 48.4,
        "speed": 130.448,
        "context_length": null,
        "GDPval_AA_ELO": 1201,
        "SWE_bench_Verified": 77.4,
        "SWE_bench_Pro": 43.3
      },
      "roleScores": {
        "Orchestrator": 365.649,
        "Oracle": 14.9174,
        "Explorer": 2.81795,
        "Librarian": 5.2438,
        "Designer": 363.0943,
        "Fixer": 20.90625,
        "Builder": 37.29845
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemma 3 12B Instruct": {
      "id": "2e6400f5-85ca-4ebc-ba8f-c2811a631138",
      "name": "Gemma 3 12B Instruct",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.595,
        "gpqa": 0.349,
        "ifbench": 0.367,
        "aime": 0.22,
        "math_index": 18.3,
        "terminalbench_hard": 0.008,
        "tau2": 0.108,
        "hle": 0.048,
        "scicode": 0.174,
        "livecodebench": 0.137,
        "coding_index": 6.3,
        "intelligence_index": 8.8,
        "speed": 32.38,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.1049,
        "Oracle": 3.0254000000000003,
        "Explorer": 0.4071,
        "Librarian": 1.03115,
        "Designer": 0.533,
        "Fixer": 0.4736,
        "Builder": 0.7335499999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemma 3 270M": {
      "id": "04781a0e-40f0-4e2a-a4e5-18e389364a79",
      "name": "Gemma 3 270M",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.055,
        "gpqa": 0.224,
        "ifbench": 0.121,
        "aime": null,
        "math_index": 2.3,
        "terminalbench_hard": 0,
        "tau2": 0.091,
        "hle": 0.042,
        "scicode": 0,
        "livecodebench": 0.003,
        "coding_index": 0.1,
        "intelligence_index": 8.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9203000000000001,
        "Oracle": 0.46459999999999996,
        "Explorer": 0.035350000000000006,
        "Librarian": 0.8820500000000001,
        "Designer": 0.08555,
        "Fixer": 0.05287499999999999,
        "Builder": 0.041650000000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemma 3 27B Instruct": {
      "id": "2bfdd17a-e027-4068-a54e-b0e90a6df118",
      "name": "Gemma 3 27B Instruct",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.669,
        "gpqa": 0.428,
        "ifbench": 0.318,
        "aime": 0.253,
        "math_index": 20.7,
        "terminalbench_hard": 0.038,
        "tau2": 0.105,
        "hle": 0.047,
        "scicode": 0.212,
        "livecodebench": 0.137,
        "coding_index": 9.6,
        "intelligence_index": 10.2,
        "speed": 33.809,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.26415,
        "Oracle": 3.43885,
        "Explorer": 0.5907,
        "Librarian": 1.17675,
        "Designer": 0.72385,
        "Fixer": 0.6592749999999999,
        "Builder": 1.0727
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 3 Flash Preview (Non-reasoning)": {
      "id": "783a0ea2-1eef-422a-8c3d-f6d40d943f54",
      "name": "Gemini 3 Flash Preview (Non-reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.882,
        "gpqa": 0.812,
        "ifbench": 0.551,
        "aime": null,
        "math_index": 55.7,
        "terminalbench_hard": 0.318,
        "tau2": 0.433,
        "hle": 0.141,
        "scicode": 0.499,
        "livecodebench": 0.797,
        "coding_index": 37.8,
        "intelligence_index": 35.1,
        "speed": 179.601,
        "context_length": null,
        "GDPval_AA_ELO": 1119,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 34.63
      },
      "roleScores": {
        "Orchestrator": 339.63064999999995,
        "Oracle": 8.856250000000001,
        "Explorer": 2.2207,
        "Librarian": 3.783,
        "Designer": 337.9944999999999,
        "Fixer": 7.4967,
        "Builder": 14.441400000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash-Lite Preview (Sep '25) (Reasoning)": {
      "id": "84922739-425f-46e1-87ac-bb4268dcacbb",
      "name": "Gemini 2.5 Flash-Lite Preview (Sep '25) (Reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.808,
        "gpqa": 0.709,
        "ifbench": 0.526,
        "aime": null,
        "math_index": 68.7,
        "terminalbench_hard": 0.129,
        "tau2": 0.307,
        "hle": 0.066,
        "scicode": 0.287,
        "livecodebench": 0.688,
        "coding_index": 18.1,
        "intelligence_index": 21.6,
        "speed": 496.972,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.5326,
        "Oracle": 10.743599999999999,
        "Explorer": 1.1174500000000003,
        "Librarian": 2.3843,
        "Designer": 1.2626500000000003,
        "Fixer": 1.2494,
        "Builder": 2.0508
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemma 3n E4B Instruct": {
      "id": "a797eaf3-6d75-4f29-86a8-e1243ce52d43",
      "name": "Gemma 3n E4B Instruct",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.488,
        "gpqa": 0.296,
        "ifbench": 0.279,
        "aime": 0.137,
        "math_index": 14.3,
        "terminalbench_hard": 0.023,
        "tau2": 0.05,
        "hle": 0.044,
        "scicode": 0.081,
        "livecodebench": 0.146,
        "coding_index": 4.2,
        "intelligence_index": 6.3,
        "speed": 38.588,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.80925,
        "Oracle": 2.3714000000000004,
        "Explorer": 0.2827,
        "Librarian": 0.7493000000000001,
        "Designer": 0.3895,
        "Fixer": 0.344625,
        "Builder": 0.50985
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Pro": {
      "id": "27202e5f-c82d-4710-92e9-4317877d4883",
      "name": "Gemini 2.5 Pro",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.862,
        "gpqa": 0.844,
        "ifbench": 0.487,
        "aime": 0.887,
        "math_index": 87.7,
        "terminalbench_hard": 0.265,
        "tau2": 0.541,
        "hle": 0.211,
        "scicode": 0.428,
        "livecodebench": 0.801,
        "coding_index": 31.9,
        "intelligence_index": 34.5,
        "speed": 149.606,
        "context_length": null,
        "GDPval_AA_ELO": 939,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 285.57525,
        "Oracle": 13.851149999999999,
        "Explorer": 1.933,
        "Librarian": 3.7454000000000005,
        "Designer": 283.7051,
        "Fixer": 2.0030249999999996,
        "Builder": 3.462
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemma 3 1B Instruct": {
      "id": "d1720545-d0a8-4c15-a53e-ef5ca99ac7ea",
      "name": "Gemma 3 1B Instruct",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.135,
        "gpqa": 0.237,
        "ifbench": 0.199,
        "aime": 0,
        "math_index": 3.3,
        "terminalbench_hard": 0,
        "tau2": 0.105,
        "hle": 0.052,
        "scicode": 0.007,
        "livecodebench": 0.017,
        "coding_index": 0.2,
        "intelligence_index": 5.4,
        "speed": 28.602,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.648,
        "Oracle": 0.6295999999999999,
        "Explorer": 0.05235,
        "Librarian": 0.6062500000000001,
        "Designer": 0.11460000000000001,
        "Fixer": 0.07435,
        "Builder": 0.06295
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 3 Flash Preview (Reasoning)": {
      "id": "7c73c3be-7f51-4d14-bec8-d5789488df25",
      "name": "Gemini 3 Flash Preview (Reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.89,
        "gpqa": 0.898,
        "ifbench": 0.78,
        "aime": null,
        "math_index": 97,
        "terminalbench_hard": 0.386,
        "tau2": 0.804,
        "hle": 0.347,
        "scicode": 0.506,
        "livecodebench": 0.908,
        "coding_index": 42.6,
        "intelligence_index": 46.4,
        "speed": 205.036,
        "context_length": null,
        "GDPval_AA_ELO": 1119,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 34.63
      },
      "roleScores": {
        "Orchestrator": 340.8505,
        "Oracle": 15.10535,
        "Explorer": 2.59175,
        "Librarian": 5.036,
        "Designer": 338.30069999999995,
        "Fixer": 7.7947500000000005,
        "Builder": 14.958500000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash-Lite Preview (Sep '25) (Non-reasoning)": {
      "id": "71f51ea9-94fe-4635-a80d-4cfffbb685f4",
      "name": "Gemini 2.5 Flash-Lite Preview (Sep '25) (Non-reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.796,
        "gpqa": 0.651,
        "ifbench": 0.418,
        "aime": null,
        "math_index": 46.7,
        "terminalbench_hard": 0.076,
        "tau2": 0.304,
        "hle": 0.046,
        "scicode": 0.285,
        "livecodebench": 0.641,
        "coding_index": 14.5,
        "intelligence_index": 19.4,
        "speed": 400.2,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2827,
        "Oracle": 7.4124,
        "Explorer": 0.9133000000000001,
        "Librarian": 2.1454,
        "Designer": 1.05355,
        "Fixer": 1.0416250000000002,
        "Builder": 1.67195
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4.5 Haiku (Non-reasoning)": {
      "id": "c2b1e769-7aee-4669-8076-73918bdebf6c",
      "name": "Claude 4.5 Haiku (Non-reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.8,
        "gpqa": 0.646,
        "ifbench": 0.42,
        "aime": null,
        "math_index": 39,
        "terminalbench_hard": 0.273,
        "tau2": 0.325,
        "hle": 0.043,
        "scicode": 0.344,
        "livecodebench": 0.511,
        "coding_index": 29.6,
        "intelligence_index": 31,
        "speed": 110.455,
        "context_length": null,
        "GDPval_AA_ELO": 1167,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 353.54470000000003,
        "Oracle": 6.25515,
        "Explorer": 1.7526000000000002,
        "Librarian": 3.3074,
        "Designer": 351.90779999999995,
        "Fixer": 1.798575,
        "Builder": 3.1622500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude Opus 4.5 (Reasoning)": {
      "id": "2660d74f-ce79-48a8-8b53-6e668e2071a2",
      "name": "Claude Opus 4.5 (Reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.895,
        "gpqa": 0.866,
        "ifbench": 0.58,
        "aime": null,
        "math_index": 91.3,
        "terminalbench_hard": 0.47,
        "tau2": 0.895,
        "hle": 0.284,
        "scicode": 0.495,
        "livecodebench": 0.871,
        "coding_index": 47.8,
        "intelligence_index": 49.7,
        "speed": 84.186,
        "context_length": null,
        "GDPval_AA_ELO": 1400,
        "SWE_bench_Verified": 79.2,
        "SWE_bench_Pro": 45.89
      },
      "roleScores": {
        "Orchestrator": 425.45395,
        "Oracle": 14.231699999999998,
        "Explorer": 2.90545,
        "Librarian": 5.336950000000001,
        "Designer": 422.82714999999996,
        "Fixer": 21.6143,
        "Builder": 38.638000000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4.5 Sonnet (Non-reasoning)": {
      "id": "91cb6144-4937-4e4e-aeda-b4341d355c10",
      "name": "Claude 4.5 Sonnet (Non-reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.86,
        "gpqa": 0.727,
        "ifbench": 0.427,
        "aime": null,
        "math_index": 37,
        "terminalbench_hard": 0.288,
        "tau2": 0.705,
        "hle": 0.071,
        "scicode": 0.428,
        "livecodebench": 0.59,
        "coding_index": 33.5,
        "intelligence_index": 37.1,
        "speed": 70.631,
        "context_length": null,
        "GDPval_AA_ELO": 1319,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 399.81895,
        "Oracle": 6.00305,
        "Explorer": 2.056,
        "Librarian": 3.9735000000000005,
        "Designer": 397.73555000000005,
        "Fixer": 2.037025,
        "Builder": 3.5755500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude Opus 4.5 (Non-reasoning)": {
      "id": "4077490a-bbfb-404e-979a-a97a20e3b5de",
      "name": "Claude Opus 4.5 (Non-reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.889,
        "gpqa": 0.81,
        "ifbench": 0.43,
        "aime": null,
        "math_index": 62.7,
        "terminalbench_hard": 0.409,
        "tau2": 0.863,
        "hle": 0.129,
        "scicode": 0.47,
        "livecodebench": 0.738,
        "coding_index": 42.9,
        "intelligence_index": 43,
        "speed": 73.087,
        "context_length": null,
        "GDPval_AA_ELO": 1416,
        "SWE_bench_Verified": 79.2,
        "SWE_bench_Pro": 45.89
      },
      "roleScores": {
        "Orchestrator": 429.54615,
        "Oracle": 9.905349999999999,
        "Explorer": 2.6197,
        "Librarian": 4.601349999999999,
        "Designer": 427.33675,
        "Fixer": 21.325325,
        "Builder": 38.114650000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4.5 Haiku (Reasoning)": {
      "id": "a6340098-d7ae-462d-b372-0a0a67fc44b4",
      "name": "Claude 4.5 Haiku (Reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.76,
        "gpqa": 0.672,
        "ifbench": 0.543,
        "aime": null,
        "math_index": 83.7,
        "terminalbench_hard": 0.273,
        "tau2": 0.547,
        "hle": 0.097,
        "scicode": 0.433,
        "livecodebench": 0.615,
        "coding_index": 32.6,
        "intelligence_index": 37,
        "speed": 124.151,
        "context_length": null,
        "GDPval_AA_ELO": 1167,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 354.18455,
        "Oracle": 12.97185,
        "Explorer": 1.9568000000000003,
        "Librarian": 3.9521,
        "Designer": 352.07599999999996,
        "Fixer": 1.9780000000000002,
        "Builder": 3.4846
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4.5 Sonnet (Reasoning)": {
      "id": "90e078f2-051b-4c63-8919-76618971cb3f",
      "name": "Claude 4.5 Sonnet (Reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.875,
        "gpqa": 0.834,
        "ifbench": 0.573,
        "aime": null,
        "math_index": 88,
        "terminalbench_hard": 0.356,
        "tau2": 0.781,
        "hle": 0.173,
        "scicode": 0.447,
        "livecodebench": 0.714,
        "coding_index": 38.6,
        "intelligence_index": 42.9,
        "speed": 77.547,
        "context_length": null,
        "GDPval_AA_ELO": 1319,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 400.4521000000001,
        "Oracle": 13.713149999999999,
        "Explorer": 2.3638000000000003,
        "Librarian": 4.60855,
        "Designer": 398.04435,
        "Fixer": 2.34465,
        "Builder": 4.1229000000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude Opus 4.6 (Adaptive Reasoning)": {
      "id": "53c98840-47af-49aa-94e6-469fb17e9a1b",
      "name": "Claude Opus 4.6 (Adaptive Reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.896,
        "ifbench": 0.531,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.462,
        "tau2": 0.921,
        "hle": 0.367,
        "scicode": 0.519,
        "livecodebench": null,
        "coding_index": 48.1,
        "intelligence_index": 53,
        "speed": 64.459,
        "context_length": null,
        "GDPval_AA_ELO": 1606,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 487.45095,
        "Oracle": 0.46635,
        "Explorer": 2.8384,
        "Librarian": 5.555300000000001,
        "Designer": 484.5187999999999,
        "Fixer": 2.6481500000000002,
        "Builder": 4.926150000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude Opus 4.6 (Non-reasoning)": {
      "id": "4386585e-71b4-4a0c-8a63-afb333419cd6",
      "name": "Claude Opus 4.6 (Non-reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.84,
        "ifbench": 0.446,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.485,
        "tau2": 0.848,
        "hle": 0.186,
        "scicode": 0.457,
        "livecodebench": null,
        "coding_index": 47.6,
        "intelligence_index": 46.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": 1579,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 478.65969999999993,
        "Oracle": 0.42929999999999996,
        "Explorer": 2.7953,
        "Librarian": 4.8252,
        "Designer": 476.35319999999996,
        "Fixer": 2.6094250000000003,
        "Builder": 4.866300000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Ministral 3 8B": {
      "id": "9741f3c2-cbb1-4a3f-99ee-7bd7384d9038",
      "name": "Ministral 3 8B",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.642,
        "gpqa": 0.471,
        "ifbench": 0.291,
        "aime": null,
        "math_index": 31.7,
        "terminalbench_hard": 0.045,
        "tau2": 0.266,
        "hle": 0.043,
        "scicode": 0.208,
        "livecodebench": 0.303,
        "coding_index": 10,
        "intelligence_index": 14.6,
        "speed": 184.143,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.72075,
        "Oracle": 5.05685,
        "Explorer": 0.65085,
        "Librarian": 1.6248999999999998,
        "Designer": 0.74745,
        "Fixer": 0.7112,
        "Builder": 1.1392
      },
      "lastCalculated": "2026-02-14"
    },
    "Devstral 2": {
      "id": "09f43999-b67b-4c1b-b050-44df41ed7e62",
      "name": "Devstral 2",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.762,
        "gpqa": 0.594,
        "ifbench": 0.381,
        "aime": null,
        "math_index": 36.7,
        "terminalbench_hard": 0.189,
        "tau2": 0.249,
        "hle": 0.036,
        "scicode": 0.331,
        "livecodebench": 0.448,
        "coding_index": 23.7,
        "intelligence_index": 22,
        "speed": 72.988,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.51515,
        "Oracle": 5.88,
        "Explorer": 1.4008500000000002,
        "Librarian": 2.3881,
        "Designer": 1.4895,
        "Fixer": 1.46995,
        "Builder": 2.5537500000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Small 3.2": {
      "id": "43da3718-3d6e-40dd-901a-05664179ff7f",
      "name": "Mistral Small 3.2",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.681,
        "gpqa": 0.505,
        "ifbench": 0.335,
        "aime": 0.323,
        "math_index": 27,
        "terminalbench_hard": 0.068,
        "tau2": 0.295,
        "hle": 0.043,
        "scicode": 0.264,
        "livecodebench": 0.275,
        "coding_index": 13.3,
        "intelligence_index": 15,
        "speed": 112.955,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7829,
        "Oracle": 4.43735,
        "Explorer": 0.8362,
        "Librarian": 1.6780500000000003,
        "Designer": 0.9312,
        "Fixer": 0.8876250000000001,
        "Builder": 1.47255
      },
      "lastCalculated": "2026-02-14"
    },
    "Ministral 3 14B": {
      "id": "713fae11-c75c-4f10-ae2c-8e4074cd58af",
      "name": "Ministral 3 14B",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.693,
        "gpqa": 0.572,
        "ifbench": 0.32,
        "aime": null,
        "math_index": 30,
        "terminalbench_hard": 0.045,
        "tau2": 0.272,
        "hle": 0.046,
        "scicode": 0.236,
        "livecodebench": 0.351,
        "coding_index": 10.9,
        "intelligence_index": 16,
        "speed": 137.179,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8935500000000003,
        "Oracle": 4.8576,
        "Explorer": 0.7026,
        "Librarian": 1.7769500000000003,
        "Designer": 0.82855,
        "Fixer": 0.78595,
        "Builder": 1.2505000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Large 3": {
      "id": "4928e950-7f37-4475-b0dc-c5bad781a321",
      "name": "Mistral Large 3",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.807,
        "gpqa": 0.68,
        "ifbench": 0.362,
        "aime": null,
        "math_index": 38,
        "terminalbench_hard": 0.159,
        "tau2": 0.246,
        "hle": 0.041,
        "scicode": 0.362,
        "livecodebench": 0.465,
        "coding_index": 22.7,
        "intelligence_index": 22.7,
        "speed": 55.564,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.60595,
        "Oracle": 6.12275,
        "Explorer": 1.3428499999999999,
        "Librarian": 2.46415,
        "Designer": 1.46635,
        "Fixer": 1.4366500000000002,
        "Builder": 2.4662
      },
      "lastCalculated": "2026-02-14"
    },
    "Magistral Medium 1.2": {
      "id": "864da2a5-156c-45fd-873c-8923be91914f",
      "name": "Magistral Medium 1.2",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.815,
        "gpqa": 0.739,
        "ifbench": 0.43,
        "aime": null,
        "math_index": 82,
        "terminalbench_hard": 0.129,
        "tau2": 0.52,
        "hle": 0.096,
        "scicode": 0.392,
        "livecodebench": 0.75,
        "coding_index": 21.7,
        "intelligence_index": 27,
        "speed": 38.002,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.0865500000000003,
        "Oracle": 12.755799999999999,
        "Explorer": 1.3529,
        "Librarian": 2.9460500000000005,
        "Designer": 1.4445999999999999,
        "Fixer": 1.44705,
        "Builder": 2.41865
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Medium 3.1": {
      "id": "05a32e26-e609-4377-951b-8fa23d329926",
      "name": "Mistral Medium 3.1",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.683,
        "gpqa": 0.588,
        "ifbench": 0.398,
        "aime": null,
        "math_index": 38.3,
        "terminalbench_hard": 0.106,
        "tau2": 0.406,
        "hle": 0.044,
        "scicode": 0.338,
        "livecodebench": 0.406,
        "coding_index": 18.3,
        "intelligence_index": 21.1,
        "speed": 90.858,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.4303500000000002,
        "Oracle": 6.109499999999999,
        "Explorer": 1.1294,
        "Librarian": 2.3060500000000004,
        "Designer": 1.20865,
        "Fixer": 1.1815000000000002,
        "Builder": 2.00375
      },
      "lastCalculated": "2026-02-14"
    },
    "Ministral 3 3B": {
      "id": "66f4ce73-9a9b-4b49-9c6e-bedb9bfdc720",
      "name": "Ministral 3 3B",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.524,
        "gpqa": 0.358,
        "ifbench": 0.268,
        "aime": null,
        "math_index": 22,
        "terminalbench_hard": 0,
        "tau2": 0.249,
        "hle": 0.053,
        "scicode": 0.144,
        "livecodebench": 0.247,
        "coding_index": 4.8,
        "intelligence_index": 11.2,
        "speed": 284.157,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.3353,
        "Oracle": 3.5340499999999997,
        "Explorer": 0.3573,
        "Librarian": 1.2661999999999998,
        "Designer": 0.4402,
        "Fixer": 0.40637499999999993,
        "Builder": 0.59245
      },
      "lastCalculated": "2026-02-14"
    },
    "Magistral Small 1.2": {
      "id": "70152cb0-fb36-4732-a925-89ef40994be1",
      "name": "Magistral Small 1.2",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.768,
        "gpqa": 0.663,
        "ifbench": 0.444,
        "aime": null,
        "math_index": 80.3,
        "terminalbench_hard": 0.045,
        "tau2": 0.278,
        "hle": 0.061,
        "scicode": 0.352,
        "livecodebench": 0.723,
        "coding_index": 14.8,
        "intelligence_index": 18.1,
        "speed": 197.646,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.1522000000000006,
        "Oracle": 12.45635,
        "Explorer": 0.9073500000000001,
        "Librarian": 2.0157000000000003,
        "Designer": 1.07145,
        "Fixer": 1.06715,
        "Builder": 1.7153500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Devstral Small 2": {
      "id": "ce819310-af7c-49d3-9a02-6845111e1788",
      "name": "Devstral Small 2",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.678,
        "gpqa": 0.532,
        "ifbench": 0.312,
        "aime": null,
        "math_index": 34.3,
        "terminalbench_hard": 0.167,
        "tau2": 0.234,
        "hle": 0.034,
        "scicode": 0.288,
        "livecodebench": 0.348,
        "coding_index": 20.7,
        "intelligence_index": 19.3,
        "speed": 197.637,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2083000000000004,
        "Oracle": 5.480499999999999,
        "Explorer": 1.2298,
        "Librarian": 2.0965000000000003,
        "Designer": 1.3043,
        "Fixer": 1.28015,
        "Builder": 2.2249
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek R1 Distill Llama 70B": {
      "id": "4a845d7b-a52d-43bb-80b7-b58c7a0c155e",
      "name": "DeepSeek R1 Distill Llama 70B",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.795,
        "gpqa": 0.402,
        "ifbench": 0.276,
        "aime": 0.67,
        "math_index": 53.7,
        "terminalbench_hard": 0.015,
        "tau2": 0.219,
        "hle": 0.061,
        "scicode": 0.312,
        "livecodebench": 0.266,
        "coding_index": 11.4,
        "intelligence_index": 16,
        "speed": 48.518,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8629500000000003,
        "Oracle": 8.47255,
        "Explorer": 0.7133,
        "Librarian": 1.7870500000000002,
        "Designer": 0.82345,
        "Fixer": 0.7782750000000002,
        "Builder": 1.2736500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.2 Speciale": {
      "id": "527e943a-adc6-4e69-93af-d1608e1b5fed",
      "name": "DeepSeek V3.2 Speciale",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.863,
        "gpqa": 0.871,
        "ifbench": 0.639,
        "aime": null,
        "math_index": 96.7,
        "terminalbench_hard": 0.348,
        "tau2": 0,
        "hle": 0.261,
        "scicode": 0.44,
        "livecodebench": 0.896,
        "coding_index": 37.9,
        "intelligence_index": 34.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": 1195,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 362.3095,
        "Oracle": 15.039849999999998,
        "Explorer": 2.13355,
        "Librarian": 3.68165,
        "Designer": 360.8322,
        "Fixer": 2.3241,
        "Builder": 4.0866
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek R1 0528 (May '25)": {
      "id": "a83f84b3-473a-4276-9ae1-8909da723159",
      "name": "DeepSeek R1 0528 (May '25)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.849,
        "gpqa": 0.813,
        "ifbench": 0.396,
        "aime": 0.893,
        "math_index": 76,
        "terminalbench_hard": 0.159,
        "tau2": 0.365,
        "hle": 0.149,
        "scicode": 0.403,
        "livecodebench": 0.77,
        "coding_index": 24,
        "intelligence_index": 27,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.0858500000000006,
        "Oracle": 12.07745,
        "Explorer": 1.4472000000000003,
        "Librarian": 2.9481500000000005,
        "Designer": 1.5851000000000002,
        "Fixer": 1.5772500000000003,
        "Builder": 2.6590500000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.2 (Non-reasoning)": {
      "id": "6d9a176d-feb8-4dac-8872-afe32b31897f",
      "name": "DeepSeek V3.2 (Non-reasoning)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.837,
        "gpqa": 0.751,
        "ifbench": 0.49,
        "aime": null,
        "math_index": 59,
        "terminalbench_hard": 0.326,
        "tau2": 0.789,
        "hle": 0.105,
        "scicode": 0.387,
        "livecodebench": 0.593,
        "coding_index": 34.6,
        "intelligence_index": 32.1,
        "speed": 36.748,
        "context_length": null,
        "GDPval_AA_ELO": 1195,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 362.13814999999994,
        "Oracle": 9.31445,
        "Explorer": 2.1466000000000003,
        "Librarian": 3.4949500000000002,
        "Designer": 360.60279999999995,
        "Fixer": 2.1018000000000003,
        "Builder": 3.690400000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.2 (Reasoning)": {
      "id": "d621247c-d47e-458c-82cb-a166bc3b37e5",
      "name": "DeepSeek V3.2 (Reasoning)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.862,
        "gpqa": 0.84,
        "ifbench": 0.607,
        "aime": null,
        "math_index": 92,
        "terminalbench_hard": 0.356,
        "tau2": 0.906,
        "hle": 0.222,
        "scicode": 0.389,
        "livecodebench": 0.862,
        "coding_index": 36.7,
        "intelligence_index": 41.6,
        "speed": 34.646,
        "context_length": null,
        "GDPval_AA_ELO": 1195,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 363.13895,
        "Oracle": 14.3173,
        "Explorer": 2.3012,
        "Librarian": 4.5072,
        "Designer": 360.75719999999995,
        "Fixer": 2.2748250000000003,
        "Builder": 3.9567500000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek R1 0528 Qwen3 8B": {
      "id": "6000145b-0e3d-4fef-a55f-bcaac84803b2",
      "name": "DeepSeek R1 0528 Qwen3 8B",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.739,
        "gpqa": 0.612,
        "ifbench": 0.199,
        "aime": 0.65,
        "math_index": 63.7,
        "terminalbench_hard": 0.015,
        "tau2": 0,
        "hle": 0.056,
        "scicode": 0.204,
        "livecodebench": 0.513,
        "coding_index": 7.8,
        "intelligence_index": 16.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9030999999999998,
        "Oracle": 10.0677,
        "Explorer": 0.4727,
        "Librarian": 1.78755,
        "Designer": 0.67935,
        "Fixer": 0.6492000000000001,
        "Builder": 0.9650500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek-OCR": {
      "id": "5bebf309-45f9-4711-9dbd-b4502c813e62",
      "name": "DeepSeek-OCR",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": null,
        "speed": 305.803,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.0,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.0,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "R1 1776": {
      "id": "98e3230e-cee1-4c19-b9f8-b6b6a826ca93",
      "name": "R1 1776",
      "provider": "Perplexity",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 12,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2000000000000002,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 1.2000000000000002,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Falcon-H1R-7B": {
      "id": "c76e0ae8-0fd2-45c0-a39d-d398fce9b128",
      "name": "Falcon-H1R-7B",
      "provider": "TII UAE",
      "benchmarks": {
        "mmlu_pro": 0.725,
        "gpqa": 0.661,
        "ifbench": 0.544,
        "aime": null,
        "math_index": 80,
        "terminalbench_hard": 0.023,
        "tau2": 0.278,
        "hle": 0.108,
        "scicode": 0.249,
        "livecodebench": 0.724,
        "coding_index": 9.8,
        "intelligence_index": 15.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9303500000000002,
        "Oracle": 12.4084,
        "Explorer": 0.6466000000000001,
        "Librarian": 1.8033500000000002,
        "Designer": 0.8292,
        "Fixer": 0.812925,
        "Builder": 1.21815
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok Voice Agent": {
      "id": "277d74aa-82dd-4bf3-bdcc-9b5f15108b00",
      "name": "Grok Voice Agent",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": null,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.0,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.0,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 4.1 Fast (Reasoning)": {
      "id": "23149f9b-c904-43e2-9ec4-afa2bf843941",
      "name": "Grok 4.1 Fast (Reasoning)",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.854,
        "gpqa": 0.853,
        "ifbench": 0.527,
        "aime": null,
        "math_index": 89.3,
        "terminalbench_hard": 0.242,
        "tau2": 0.933,
        "hle": 0.176,
        "scicode": 0.442,
        "livecodebench": 0.822,
        "coding_index": 30.9,
        "intelligence_index": 38.5,
        "speed": 174.509,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 4.32105,
        "Oracle": 13.915700000000001,
        "Explorer": 1.96925,
        "Librarian": 4.1769,
        "Designer": 1.95665,
        "Fixer": 1.966575,
        "Builder": 3.36765
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok Code Fast 1": {
      "id": "a06bd3fc-86db-4a8e-ae6d-7459444d08c9",
      "name": "Grok Code Fast 1",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.793,
        "gpqa": 0.727,
        "ifbench": 0.414,
        "aime": null,
        "math_index": 43.3,
        "terminalbench_hard": 0.174,
        "tau2": 0.757,
        "hle": 0.075,
        "scicode": 0.362,
        "livecodebench": 0.657,
        "coding_index": 23.7,
        "intelligence_index": 28.7,
        "speed": 299.74,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.27215,
        "Oracle": 6.941549999999999,
        "Explorer": 1.5269000000000001,
        "Librarian": 3.1285499999999997,
        "Designer": 1.5346,
        "Fixer": 1.537975,
        "Builder": 2.6016000000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 3 mini Reasoning (high)": {
      "id": "ff9bc5e5-a02f-4270-983e-4b3f834f3363",
      "name": "Grok 3 mini Reasoning (high)",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.828,
        "gpqa": 0.791,
        "ifbench": 0.459,
        "aime": 0.933,
        "math_index": 84.7,
        "terminalbench_hard": 0.174,
        "tau2": 0.904,
        "hle": 0.111,
        "scicode": 0.406,
        "livecodebench": 0.696,
        "coding_index": 25.2,
        "intelligence_index": 32,
        "speed": 195.241,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.64165,
        "Oracle": 13.37545,
        "Explorer": 1.64395,
        "Librarian": 3.4938,
        "Designer": 1.63895,
        "Fixer": 1.6389500000000001,
        "Builder": 2.7678499999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 4": {
      "id": "5ea94a4a-55ac-4ea1-8898-2b3971e94af6",
      "name": "Grok 4",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.866,
        "gpqa": 0.877,
        "ifbench": 0.537,
        "aime": 0.943,
        "math_index": 92.7,
        "terminalbench_hard": 0.379,
        "tau2": 0.749,
        "hle": 0.239,
        "scicode": 0.457,
        "livecodebench": 0.819,
        "coding_index": 40.5,
        "intelligence_index": 41.4,
        "speed": 37.547,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 4.60075,
        "Oracle": 14.630650000000001,
        "Explorer": 2.4623999999999997,
        "Librarian": 4.4702,
        "Designer": 2.4517499999999997,
        "Fixer": 2.4608999999999996,
        "Builder": 4.330699999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 4.1 Fast (Non-reasoning)": {
      "id": "49fd01f9-887d-4479-b8ce-771a81ecef4e",
      "name": "Grok 4.1 Fast (Non-reasoning)",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.743,
        "gpqa": 0.637,
        "ifbench": 0.365,
        "aime": null,
        "math_index": 34.3,
        "terminalbench_hard": 0.144,
        "tau2": 0.637,
        "hle": 0.05,
        "scicode": 0.296,
        "livecodebench": 0.399,
        "coding_index": 19.5,
        "intelligence_index": 23.5,
        "speed": 128.61,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.7072999999999996,
        "Oracle": 5.5403,
        "Explorer": 1.26865,
        "Librarian": 2.5766500000000003,
        "Designer": 1.2872000000000001,
        "Fixer": 1.2606750000000002,
        "Builder": 2.12895
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova Micro": {
      "id": "344c6718-c573-41d4-9556-10287a3fa1fc",
      "name": "Nova Micro",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.531,
        "gpqa": 0.358,
        "ifbench": 0.294,
        "aime": 0.08,
        "math_index": 6,
        "terminalbench_hard": 0.015,
        "tau2": 0.14,
        "hle": 0.047,
        "scicode": 0.094,
        "livecodebench": 0.14,
        "coding_index": 4.1,
        "intelligence_index": 10.3,
        "speed": 412.494,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.23935,
        "Oracle": 1.15045,
        "Explorer": 0.30145,
        "Librarian": 1.1671500000000001,
        "Designer": 0.40825,
        "Fixer": 0.35485,
        "Builder": 0.50805
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Lite (medium)": {
      "id": "fbdf8da1-b341-448c-b3cb-8aff1d8f70b9",
      "name": "Nova 2.0 Lite (medium)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.813,
        "gpqa": 0.768,
        "ifbench": 0.685,
        "aime": null,
        "math_index": 88.7,
        "terminalbench_hard": 0.174,
        "tau2": 0.757,
        "hle": 0.086,
        "scicode": 0.368,
        "livecodebench": 0.663,
        "coding_index": 23.9,
        "intelligence_index": 29.6,
        "speed": 237.481,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.414,
        "Oracle": 13.774600000000001,
        "Explorer": 1.53945,
        "Librarian": 3.2519500000000003,
        "Designer": 1.5860500000000002,
        "Fixer": 1.5707250000000004,
        "Builder": 2.64115
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Omni (medium)": {
      "id": "018c60e8-e908-431a-ba57-c840b1df3987",
      "name": "Nova 2.0 Omni (medium)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.809,
        "gpqa": 0.76,
        "ifbench": 0.662,
        "aime": null,
        "math_index": 89.7,
        "terminalbench_hard": 0.045,
        "tau2": 0.804,
        "hle": 0.068,
        "scicode": 0.362,
        "livecodebench": 0.66,
        "coding_index": 15.1,
        "intelligence_index": 27.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.24305,
        "Oracle": 13.9193,
        "Explorer": 1.0583,
        "Librarian": 3.07835,
        "Designer": 1.13935,
        "Fixer": 1.11565,
        "Builder": 1.75855
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Pro Preview (medium)": {
      "id": "0d94dc87-12c8-4d4a-8d99-804ce3f17bc2",
      "name": "Nova 2.0 Pro Preview (medium)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.83,
        "gpqa": 0.785,
        "ifbench": 0.79,
        "aime": null,
        "math_index": 89,
        "terminalbench_hard": 0.242,
        "tau2": 0.927,
        "hle": 0.089,
        "scicode": 0.427,
        "livecodebench": 0.73,
        "coding_index": 30.4,
        "intelligence_index": 35.6,
        "speed": 127.093,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 4.052700000000001,
        "Oracle": 13.82995,
        "Explorer": 1.936,
        "Librarian": 3.8829000000000002,
        "Designer": 1.92865,
        "Fixer": 1.9278,
        "Builder": 3.309
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Lite (low)": {
      "id": "6fd796d3-f346-4f66-97df-5da81714fc73",
      "name": "Nova 2.0 Lite (low)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.788,
        "gpqa": 0.698,
        "ifbench": 0.612,
        "aime": null,
        "math_index": 46.7,
        "terminalbench_hard": 0.038,
        "tau2": 0.719,
        "hle": 0.042,
        "scicode": 0.333,
        "livecodebench": 0.469,
        "coding_index": 13.6,
        "intelligence_index": 24.2,
        "speed": 233.709,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.8415,
        "Oracle": 7.434900000000001,
        "Explorer": 0.9558500000000001,
        "Librarian": 2.6838999999999995,
        "Designer": 1.0381,
        "Fixer": 0.99455,
        "Builder": 1.5701500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Pro Preview (Non-reasoning)": {
      "id": "a20ae33a-46e1-41e6-81a0-fe8b00d2e538",
      "name": "Nova 2.0 Pro Preview (Non-reasoning)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.772,
        "gpqa": 0.636,
        "ifbench": 0.52,
        "aime": null,
        "math_index": 30.7,
        "terminalbench_hard": 0.167,
        "tau2": 0.716,
        "hle": 0.04,
        "scicode": 0.281,
        "livecodebench": 0.473,
        "coding_index": 20.5,
        "intelligence_index": 22.9,
        "speed": 156.869,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.6826,
        "Oracle": 5.002199999999999,
        "Explorer": 1.35,
        "Librarian": 2.5414000000000003,
        "Designer": 1.3558000000000001,
        "Fixer": 1.3361750000000003,
        "Builder": 2.24915
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Pro Preview (low)": {
      "id": "f4274721-ef28-4121-aa88-8e97267a5a82",
      "name": "Nova 2.0 Pro Preview (low)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.822,
        "gpqa": 0.751,
        "ifbench": 0.796,
        "aime": null,
        "math_index": 63.3,
        "terminalbench_hard": 0.174,
        "tau2": 0.906,
        "hle": 0.052,
        "scicode": 0.387,
        "livecodebench": 0.638,
        "coding_index": 24.5,
        "intelligence_index": 31.9,
        "speed": 135.097,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.6734999999999998,
        "Oracle": 9.9553,
        "Explorer": 1.6059,
        "Librarian": 3.4991000000000003,
        "Designer": 1.6208500000000001,
        "Fixer": 1.6050750000000003,
        "Builder": 2.7017
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Omni (low)": {
      "id": "b36ff8f3-0323-49d1-a063-ab09704fdb0c",
      "name": "Nova 2.0 Omni (low)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.798,
        "gpqa": 0.699,
        "ifbench": 0.618,
        "aime": null,
        "math_index": 56,
        "terminalbench_hard": 0.038,
        "tau2": 0.678,
        "hle": 0.04,
        "scicode": 0.343,
        "livecodebench": 0.592,
        "coding_index": 13.9,
        "intelligence_index": 23.2,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.7399999999999998,
        "Oracle": 8.831300000000002,
        "Explorer": 0.9615,
        "Librarian": 2.5812999999999997,
        "Designer": 1.05525,
        "Fixer": 1.028675,
        "Builder": 1.6195000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova Premier": {
      "id": "e58bbffd-fdc2-412a-b6d7-ca0e3f5d611a",
      "name": "Nova Premier",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.733,
        "gpqa": 0.569,
        "ifbench": 0.362,
        "aime": 0.17,
        "math_index": 17.3,
        "terminalbench_hard": 0.068,
        "tau2": 0.383,
        "hle": 0.047,
        "scicode": 0.279,
        "livecodebench": 0.317,
        "coding_index": 13.8,
        "intelligence_index": 18.9,
        "speed": 78.003,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.20635,
        "Oracle": 2.98915,
        "Explorer": 0.8886000000000001,
        "Librarian": 2.08855,
        "Designer": 0.9831000000000001,
        "Fixer": 0.93765,
        "Builder": 1.5392000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Lite (Non-reasoning)": {
      "id": "76bce7fb-3a3f-4b66-a78d-35ccf3edf5d2",
      "name": "Nova 2.0 Lite (Non-reasoning)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.743,
        "gpqa": 0.603,
        "ifbench": 0.405,
        "aime": null,
        "math_index": 33.7,
        "terminalbench_hard": 0.068,
        "tau2": 0.62,
        "hle": 0.03,
        "scicode": 0.24,
        "livecodebench": 0.346,
        "coding_index": 12.5,
        "intelligence_index": 17.9,
        "speed": 194.408,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.1448,
        "Oracle": 5.432300000000001,
        "Explorer": 0.883,
        "Librarian": 2.01295,
        "Designer": 0.9307,
        "Fixer": 0.8902,
        "Builder": 1.4196000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova 2.0 Omni (Non-reasoning)": {
      "id": "1f6478c9-3e22-4586-adbe-841782859677",
      "name": "Nova 2.0 Omni (Non-reasoning)",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.719,
        "gpqa": 0.555,
        "ifbench": 0.411,
        "aime": null,
        "math_index": 37,
        "terminalbench_hard": 0.068,
        "tau2": 0.447,
        "hle": 0.039,
        "scicode": 0.279,
        "livecodebench": 0.305,
        "coding_index": 13.8,
        "intelligence_index": 16.6,
        "speed": 208.561,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9852,
        "Oracle": 5.90135,
        "Explorer": 0.9028,
        "Librarian": 1.86535,
        "Designer": 0.9816,
        "Fixer": 0.9364,
        "Builder": 1.5377500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Phi-4": {
      "id": "ee708f92-374e-4123-b900-e22d7b2afc19",
      "name": "Phi-4",
      "provider": "Microsoft Azure",
      "benchmarks": {
        "mmlu_pro": 0.714,
        "gpqa": 0.575,
        "ifbench": 0.235,
        "aime": 0.143,
        "math_index": 18,
        "terminalbench_hard": 0.038,
        "tau2": 0,
        "hle": 0.041,
        "scicode": 0.26,
        "livecodebench": 0.231,
        "coding_index": 11.2,
        "intelligence_index": 10.5,
        "speed": 6.985,
        "context_length": 16384,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.30735,
        "Oracle": 3.08955,
        "Explorer": 0.650995987307842,
        "Librarian": 1.1968099788464037,
        "Designer": 0.8392319957692806,
        "Fixer": 0.7743499999999999,
        "Builder": 1.2595999999999998
      },
      "lastCalculated": "2026-02-14"
    },
    "Phi-4 Mini Instruct": {
      "id": "9f873c2f-2c2d-4ccb-9e1b-71bf61b052be",
      "name": "Phi-4 Mini Instruct",
      "provider": "Microsoft Azure",
      "benchmarks": {
        "mmlu_pro": 0.465,
        "gpqa": 0.331,
        "ifbench": 0.211,
        "aime": 0.03,
        "math_index": 6.7,
        "terminalbench_hard": 0,
        "tau2": 0.082,
        "hle": 0.042,
        "scicode": 0.108,
        "livecodebench": 0.126,
        "coding_index": 3.6,
        "intelligence_index": 10.9,
        "speed": 43.905,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2658,
        "Oracle": 1.2250999999999999,
        "Explorer": 0.24910000000000004,
        "Librarian": 1.2016499999999999,
        "Designer": 0.35780000000000006,
        "Fixer": 0.31035,
        "Builder": 0.44580000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Phi-4 Multimodal Instruct": {
      "id": "2cd04201-2b6e-47ef-853e-7601f705f2a8",
      "name": "Phi-4 Multimodal Instruct",
      "provider": "Microsoft Azure",
      "benchmarks": {
        "mmlu_pro": 0.485,
        "gpqa": 0.315,
        "ifbench": null,
        "aime": 0.093,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.044,
        "scicode": 0.11,
        "livecodebench": 0.131,
        "coding_index": null,
        "intelligence_index": 10,
        "speed": 17.167,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.13575,
        "Oracle": 0.22680000000000003,
        "Explorer": 0.0507,
        "Librarian": 1.08595,
        "Designer": 0.15589999999999998,
        "Fixer": 0.11815,
        "Builder": 0.0754
      },
      "lastCalculated": "2026-02-14"
    },
    "LFM2.5-1.2B-Instruct": {
      "id": "48194e0f-8226-4c57-8cb2-2a0fb68a84c9",
      "name": "LFM2.5-1.2B-Instruct",
      "provider": "Liquid AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.326,
        "ifbench": 0.438,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0,
        "tau2": 0.108,
        "hle": 0.068,
        "scicode": 0.023,
        "livecodebench": null,
        "coding_index": 0.8,
        "intelligence_index": 8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9417000000000001,
        "Oracle": 0.1664,
        "Explorer": 0.0704,
        "Librarian": 0.8750000000000001,
        "Designer": 0.1721,
        "Fixer": 0.11407500000000001,
        "Builder": 0.1345
      },
      "lastCalculated": "2026-02-14"
    },
    "LFM2 8B A1B": {
      "id": "686ab020-ee58-4a70-a9ac-24d675a73506",
      "name": "LFM2 8B A1B",
      "provider": "Liquid AI",
      "benchmarks": {
        "mmlu_pro": 0.505,
        "gpqa": 0.344,
        "ifbench": 0.263,
        "aime": null,
        "math_index": 25.3,
        "terminalbench_hard": 0,
        "tau2": 0.105,
        "hle": 0.049,
        "scicode": 0.068,
        "livecodebench": 0.151,
        "coding_index": 2.3,
        "intelligence_index": 6.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8745,
        "Oracle": 4.01995,
        "Explorer": 0.19419999999999998,
        "Librarian": 0.80725,
        "Designer": 0.30795,
        "Fixer": 0.257225,
        "Builder": 0.32544999999999996
      },
      "lastCalculated": "2026-02-14"
    },
    "LFM2.5-1.2B-Thinking": {
      "id": "5a088cde-18e2-4dfa-98dd-d283e1c19654",
      "name": "LFM2.5-1.2B-Thinking",
      "provider": "Liquid AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.339,
        "ifbench": 0.418,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0,
        "tau2": 0.196,
        "hle": 0.061,
        "scicode": 0.042,
        "livecodebench": null,
        "coding_index": 1.4,
        "intelligence_index": 8.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9601,
        "Oracle": 0.17255,
        "Explorer": 0.12204999999999999,
        "Librarian": 0.8897,
        "Designer": 0.20265,
        "Fixer": 0.14769999999999997,
        "Builder": 0.1948
      },
      "lastCalculated": "2026-02-14"
    },
    "LFM2.5-VL-1.6B": {
      "id": "3c5289e5-1c62-434c-bc44-c51c39f640a1",
      "name": "LFM2.5-VL-1.6B",
      "provider": "Liquid AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.289,
        "ifbench": 0.331,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0,
        "tau2": 0.085,
        "hle": 0.051,
        "scicode": 0.03,
        "livecodebench": null,
        "coding_index": 1,
        "intelligence_index": 6.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.7259499999999999,
        "Oracle": 0.14705,
        "Explorer": 0.0738,
        "Librarian": 0.6668999999999999,
        "Designer": 0.16045,
        "Fixer": 0.112775,
        "Builder": 0.14545000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "LFM2 2.6B": {
      "id": "739e531a-eb0a-478f-bb67-5845b79ce65d",
      "name": "LFM2 2.6B",
      "provider": "Liquid AI",
      "benchmarks": {
        "mmlu_pro": 0.298,
        "gpqa": 0.306,
        "ifbench": 0.195,
        "aime": null,
        "math_index": 8.3,
        "terminalbench_hard": 0.008,
        "tau2": 0.135,
        "hle": 0.052,
        "scicode": 0.025,
        "livecodebench": 0.081,
        "coding_index": 1.4,
        "intelligence_index": 7.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.93865,
        "Oracle": 1.4304000000000001,
        "Explorer": 0.13935,
        "Librarian": 0.8833,
        "Designer": 0.21590000000000004,
        "Fixer": 0.17239999999999997,
        "Builder": 0.20739999999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "Solar Open 100B (Reasoning)": {
      "id": "59a1bb20-9170-4dc2-ba9c-12d326cf068e",
      "name": "Solar Open 100B (Reasoning)",
      "provider": "Upstage",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.657,
        "ifbench": 0.577,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.023,
        "tau2": 0.482,
        "hle": 0.092,
        "scicode": 0.269,
        "livecodebench": null,
        "coding_index": 10.5,
        "intelligence_index": 21.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.4261500000000003,
        "Oracle": 0.3331,
        "Explorer": 0.6593,
        "Librarian": 2.2935000000000003,
        "Designer": 0.75615,
        "Fixer": 0.673475,
        "Builder": 1.1445500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Solar Pro 2 (Reasoning)": {
      "id": "eb689f7a-f210-4a87-b407-f249897f2764",
      "name": "Solar Pro 2 (Reasoning)",
      "provider": "Upstage",
      "benchmarks": {
        "mmlu_pro": 0.805,
        "gpqa": 0.687,
        "ifbench": 0.371,
        "aime": 0.69,
        "math_index": 61.3,
        "terminalbench_hard": 0.03,
        "tau2": 0.281,
        "hle": 0.07,
        "scicode": 0.302,
        "livecodebench": 0.616,
        "coding_index": 12.1,
        "intelligence_index": 14.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8319000000000003,
        "Oracle": 9.7605,
        "Explorer": 0.77125,
        "Librarian": 1.6969500000000002,
        "Designer": 0.9416,
        "Fixer": 0.917075,
        "Builder": 1.4299
      },
      "lastCalculated": "2026-02-14"
    },
    "Solar Pro 2 (Non-reasoning)": {
      "id": "44db6283-aa82-4799-af4a-679fe0530845",
      "name": "Solar Pro 2 (Non-reasoning)",
      "provider": "Upstage",
      "benchmarks": {
        "mmlu_pro": 0.75,
        "gpqa": 0.561,
        "ifbench": 0.337,
        "aime": 0.407,
        "math_index": 30,
        "terminalbench_hard": 0.045,
        "tau2": 0.319,
        "hle": 0.038,
        "scicode": 0.248,
        "livecodebench": 0.424,
        "coding_index": 11.3,
        "intelligence_index": 13.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6571500000000001,
        "Oracle": 4.9388000000000005,
        "Explorer": 0.7396500000000001,
        "Librarian": 1.5395,
        "Designer": 0.8552500000000001,
        "Fixer": 0.823275,
        "Builder": 1.3040500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "MiniMax-M2.1": {
      "id": "272ff333-442f-4169-a804-ac9177bc99d7",
      "name": "MiniMax-M2.1",
      "provider": "MiniMax",
      "benchmarks": {
        "mmlu_pro": 0.875,
        "gpqa": 0.83,
        "ifbench": 0.699,
        "aime": null,
        "math_index": 82.7,
        "terminalbench_hard": 0.288,
        "tau2": 0.854,
        "hle": 0.222,
        "scicode": 0.407,
        "livecodebench": 0.81,
        "coding_index": 32.8,
        "intelligence_index": 39.5,
        "speed": 56.606,
        "context_length": 196608,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 36.81
      },
      "roleScores": {
        "Orchestrator": 4.4375,
        "Oracle": 12.9186,
        "Explorer": 2.0954518476941053,
        "Librarian": 4.350069746156842,
        "Designer": 2.0802339492313684,
        "Fixer": 7.590275000000002,
        "Builder": 14.6062
      },
      "lastCalculated": "2026-02-14"
    },
    "MiniMax-M2.5": {
      "id": "12adec16-19fe-4d92-aeff-5ef3eb7e780a",
      "name": "MiniMax-M2.5",
      "provider": "MiniMax",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.848,
        "ifbench": 0.716,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.348,
        "tau2": 0.953,
        "hle": 0.191,
        "scicode": 0.426,
        "livecodebench": null,
        "coding_index": 37.4,
        "intelligence_index": 42,
        "speed": 77.986,
        "context_length": 204800,
        "GDPval_AA_ELO": 1213,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 36.81
      },
      "roleScores": {
        "Orchestrator": 368.47229999999996,
        "Oracle": 0.43355,
        "Explorer": 2.2863248413480264,
        "Librarian": 4.473074735580044,
        "Designer": 366.08247494711594,
        "Fixer": 7.623775000000001,
        "Builder": 14.9036
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.1 Nemotron Instruct 70B": {
      "id": "7393c56a-ec31-48e9-b804-c04f2d2cb641",
      "name": "Llama 3.1 Nemotron Instruct 70B",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.69,
        "gpqa": 0.465,
        "ifbench": 0.307,
        "aime": 0.247,
        "math_index": 11,
        "terminalbench_hard": 0.045,
        "tau2": 0.231,
        "hle": 0.046,
        "scicode": 0.233,
        "livecodebench": 0.169,
        "coding_index": 10.8,
        "intelligence_index": 13.4,
        "speed": 39.884,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.60565,
        "Oracle": 2.0032,
        "Explorer": 0.68705,
        "Librarian": 1.5110999999999999,
        "Designer": 0.79505,
        "Fixer": 0.73555,
        "Builder": 1.2017
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama Nemotron Super 49B v1.5 (Reasoning)": {
      "id": "e1cfa926-9e2b-4a0d-8c31-48366a5041c5",
      "name": "Llama Nemotron Super 49B v1.5 (Reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.814,
        "gpqa": 0.748,
        "ifbench": 0.37,
        "aime": 0.86,
        "math_index": 76.7,
        "terminalbench_hard": 0.053,
        "tau2": 0.281,
        "hle": 0.068,
        "scicode": 0.348,
        "livecodebench": 0.737,
        "coding_index": 15.2,
        "intelligence_index": 18.6,
        "speed": 74.654,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2153,
        "Oracle": 12.1358,
        "Explorer": 0.93625,
        "Librarian": 2.0676,
        "Designer": 1.1129,
        "Fixer": 1.103675,
        "Builder": 1.7645499999999998
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.3 Nemotron Super 49B v1 (Reasoning)": {
      "id": "1a8ba535-df18-459b-ad40-3199191296d7",
      "name": "Llama 3.3 Nemotron Super 49B v1 (Reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.785,
        "gpqa": 0.643,
        "ifbench": 0.381,
        "aime": 0.583,
        "math_index": 54.7,
        "terminalbench_hard": 0,
        "tau2": null,
        "hle": 0.065,
        "scicode": 0.282,
        "livecodebench": 0.277,
        "coding_index": 9.4,
        "intelligence_index": 18.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.1535,
        "Oracle": 8.72485,
        "Explorer": 0.5517500000000001,
        "Librarian": 2.02535,
        "Designer": 0.7931,
        "Fixer": 0.7126000000000001,
        "Builder": 1.10415
      },
      "lastCalculated": "2026-02-14"
    },
    "NVIDIA Nemotron 3 Nano 30B A3B (Non-reasoning)": {
      "id": "23b379f7-18df-492a-9fc1-a56c5a5b9cfc",
      "name": "NVIDIA Nemotron 3 Nano 30B A3B (Non-reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.579,
        "gpqa": 0.399,
        "ifbench": 0.375,
        "aime": null,
        "math_index": 13.3,
        "terminalbench_hard": 0.121,
        "tau2": 0.254,
        "hle": 0.046,
        "scicode": 0.23,
        "livecodebench": 0.36,
        "coding_index": 15.8,
        "intelligence_index": 13.3,
        "speed": 223.741,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5783,
        "Oracle": 2.2547,
        "Explorer": 0.9621000000000001,
        "Librarian": 1.4935500000000002,
        "Designer": 1.0187,
        "Fixer": 1.0047000000000001,
        "Builder": 1.7216000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "NVIDIA Nemotron 3 Nano 30B A3B (Reasoning)": {
      "id": "76dcf6ef-39ea-4be0-b693-b88da25b4caf",
      "name": "NVIDIA Nemotron 3 Nano 30B A3B (Reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.794,
        "gpqa": 0.757,
        "ifbench": 0.711,
        "aime": null,
        "math_index": 91,
        "terminalbench_hard": 0.136,
        "tau2": 0.409,
        "hle": 0.102,
        "scicode": 0.296,
        "livecodebench": 0.741,
        "coding_index": 19,
        "intelligence_index": 24.3,
        "speed": 202.711,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.8480500000000006,
        "Oracle": 14.113000000000001,
        "Explorer": 1.1911500000000002,
        "Librarian": 2.6917000000000004,
        "Designer": 1.33965,
        "Fixer": 1.3208750000000002,
        "Builder": 2.1621
      },
      "lastCalculated": "2026-02-14"
    },
    "NVIDIA Nemotron Nano 9B V2 (Non-reasoning)": {
      "id": "2e8694f9-7782-47a6-a6ba-fdce89d939c8",
      "name": "NVIDIA Nemotron Nano 9B V2 (Non-reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.739,
        "gpqa": 0.557,
        "ifbench": 0.271,
        "aime": null,
        "math_index": 62.3,
        "terminalbench_hard": 0.008,
        "tau2": 0.234,
        "hle": 0.04,
        "scicode": 0.209,
        "livecodebench": 0.701,
        "coding_index": 7.5,
        "intelligence_index": 13.1,
        "speed": 117.949,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5963000000000003,
        "Oracle": 9.699399999999999,
        "Explorer": 0.5126,
        "Librarian": 1.48335,
        "Designer": 0.6562,
        "Fixer": 0.6630250000000001,
        "Builder": 0.9613499999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama Nemotron Super 49B v1.5 (Non-reasoning)": {
      "id": "26c0b5df-efa7-470f-a65e-2d883329e493",
      "name": "Llama Nemotron Super 49B v1.5 (Non-reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.692,
        "gpqa": 0.481,
        "ifbench": 0.329,
        "aime": 0.137,
        "math_index": 8,
        "terminalbench_hard": 0.038,
        "tau2": 0.251,
        "hle": 0.043,
        "scicode": 0.238,
        "livecodebench": 0.29,
        "coding_index": 10.5,
        "intelligence_index": 14.5,
        "speed": 67.795,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.72445,
        "Oracle": 1.53925,
        "Explorer": 0.6743,
        "Librarian": 1.6247,
        "Designer": 0.78625,
        "Fixer": 0.742325,
        "Builder": 1.1926500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.3 Nemotron Super 49B v1 (Non-reasoning)": {
      "id": "c4c3b42f-e0f0-48ca-b6f9-b296e7697806",
      "name": "Llama 3.3 Nemotron Super 49B v1 (Non-reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.698,
        "gpqa": 0.517,
        "ifbench": 0.395,
        "aime": 0.193,
        "math_index": 7.7,
        "terminalbench_hard": 0,
        "tau2": null,
        "hle": 0.035,
        "scicode": 0.229,
        "livecodebench": 0.28,
        "coding_index": 7.6,
        "intelligence_index": 14.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6973500000000001,
        "Oracle": 1.5236500000000002,
        "Explorer": 0.45155,
        "Librarian": 1.5847000000000002,
        "Designer": 0.65695,
        "Fixer": 0.5948249999999999,
        "Builder": 0.9083500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "NVIDIA Nemotron Nano 12B v2 VL (Non-reasoning)": {
      "id": "ab7f016c-a29b-4710-bdf6-6a5cd96aacca",
      "name": "NVIDIA Nemotron Nano 12B v2 VL (Non-reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.649,
        "gpqa": 0.439,
        "ifbench": 0.259,
        "aime": null,
        "math_index": 26.7,
        "terminalbench_hard": 0,
        "tau2": 0.193,
        "hle": 0.045,
        "scicode": 0.176,
        "livecodebench": 0.345,
        "coding_index": 5.9,
        "intelligence_index": 10.1,
        "speed": 135.759,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2533,
        "Oracle": 4.29165,
        "Explorer": 0.41040000000000004,
        "Librarian": 1.16605,
        "Designer": 0.5325000000000001,
        "Fixer": 0.4996750000000001,
        "Builder": 0.7310500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.1 Nemotron Ultra 253B v1 (Reasoning)": {
      "id": "cf095603-72b6-47f8-8ee1-09a42890f92a",
      "name": "Llama 3.1 Nemotron Ultra 253B v1 (Reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.825,
        "gpqa": 0.728,
        "ifbench": 0.382,
        "aime": 0.747,
        "math_index": 63.7,
        "terminalbench_hard": 0.023,
        "tau2": 0.114,
        "hle": 0.081,
        "scicode": 0.347,
        "livecodebench": 0.641,
        "coding_index": 13.1,
        "intelligence_index": 15,
        "speed": 37.025,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.83805,
        "Oracle": 10.15495,
        "Explorer": 0.77925,
        "Librarian": 1.69765,
        "Designer": 1.00705,
        "Fixer": 0.9757750000000001,
        "Builder": 1.5393
      },
      "lastCalculated": "2026-02-14"
    },
    "NVIDIA Nemotron Nano 12B v2 VL (Reasoning)": {
      "id": "6e6e02fd-9cbd-417f-9bfc-673df89c313d",
      "name": "NVIDIA Nemotron Nano 12B v2 VL (Reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.759,
        "gpqa": 0.572,
        "ifbench": 0.319,
        "aime": null,
        "math_index": 75,
        "terminalbench_hard": 0.045,
        "tau2": 0.213,
        "hle": 0.053,
        "scicode": 0.262,
        "livecodebench": 0.694,
        "coding_index": 11.8,
        "intelligence_index": 14.8,
        "speed": 129.89,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7774000000000003,
        "Oracle": 11.61455,
        "Explorer": 0.7398000000000001,
        "Librarian": 1.6629500000000004,
        "Designer": 0.88405,
        "Fixer": 0.888125,
        "Builder": 1.3952
      },
      "lastCalculated": "2026-02-14"
    },
    "NVIDIA Nemotron Nano 9B V2 (Reasoning)": {
      "id": "f1d52583-9d20-4099-99ac-b5df9430c3b6",
      "name": "NVIDIA Nemotron Nano 9B V2 (Reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.742,
        "gpqa": 0.57,
        "ifbench": 0.276,
        "aime": null,
        "math_index": 69.7,
        "terminalbench_hard": 0.015,
        "tau2": 0.219,
        "hle": 0.046,
        "scicode": 0.22,
        "livecodebench": 0.724,
        "coding_index": 8.3,
        "intelligence_index": 14.8,
        "speed": 114.833,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7686000000000004,
        "Oracle": 10.8165,
        "Explorer": 0.55225,
        "Librarian": 1.6546000000000003,
        "Designer": 0.7010000000000001,
        "Fixer": 0.709575,
        "Builder": 1.0465
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning)": {
      "id": "b1fa84f8-1ed3-4124-b403-4655dafa4267",
      "name": "Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning)",
      "provider": "NVIDIA",
      "benchmarks": {
        "mmlu_pro": 0.556,
        "gpqa": 0.408,
        "ifbench": 0.255,
        "aime": 0.707,
        "math_index": 50,
        "terminalbench_hard": null,
        "tau2": 0.117,
        "hle": 0.051,
        "scicode": 0.101,
        "livecodebench": 0.493,
        "coding_index": null,
        "intelligence_index": 14.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6549500000000001,
        "Oracle": 7.90355,
        "Explorer": 0.0874,
        "Librarian": 1.5759000000000003,
        "Designer": 0.216,
        "Fixer": 0.20895000000000002,
        "Builder": 0.1553
      },
      "lastCalculated": "2026-02-14"
    },
    "Kimi K2.5 (Reasoning)": {
      "id": "a550ffca-f89e-4381-ade6-a85dc6a1fb4c",
      "name": "Kimi K2.5 (Reasoning)",
      "provider": "Kimi",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.879,
        "ifbench": 0.702,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.348,
        "tau2": 0.959,
        "hle": 0.294,
        "scicode": 0.49,
        "livecodebench": null,
        "coding_index": 39.5,
        "intelligence_index": 46.7,
        "speed": 44.603,
        "context_length": null,
        "GDPval_AA_ELO": 1288,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 27.67
      },
      "roleScores": {
        "Orchestrator": 391.44699999999995,
        "Oracle": 0.4542,
        "Explorer": 2.36865,
        "Librarian": 4.924300000000001,
        "Designer": 388.69435,
        "Fixer": 6.363474999999999,
        "Builder": 12.374
      },
      "lastCalculated": "2026-02-14"
    },
    "Kimi K2.5 (Non-reasoning)": {
      "id": "ba04694d-326a-4a6a-8f1b-46316f872a7f",
      "name": "Kimi K2.5 (Non-reasoning)",
      "provider": "Kimi",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.789,
        "ifbench": 0.437,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.189,
        "tau2": 0.813,
        "hle": 0.123,
        "scicode": 0.396,
        "livecodebench": null,
        "coding_index": 25.8,
        "intelligence_index": 37.2,
        "speed": 39.919,
        "context_length": null,
        "GDPval_AA_ELO": 1288,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 27.67
      },
      "roleScores": {
        "Orchestrator": 390.42465,
        "Oracle": 0.40065,
        "Explorer": 1.575,
        "Librarian": 3.881900000000001,
        "Designer": 387.94325,
        "Fixer": 5.629825,
        "Builder": 10.981750000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Kimi Linear 48B A3B Instruct": {
      "id": "598de97d-029e-47b6-96ec-dbc1e0f9045a",
      "name": "Kimi Linear 48B A3B Instruct",
      "provider": "Kimi",
      "benchmarks": {
        "mmlu_pro": 0.585,
        "gpqa": 0.412,
        "ifbench": 0.281,
        "aime": null,
        "math_index": 36.3,
        "terminalbench_hard": 0.114,
        "tau2": 0,
        "hle": 0.027,
        "scicode": 0.199,
        "livecodebench": 0.378,
        "coding_index": 14.2,
        "intelligence_index": 14.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6523,
        "Oracle": 5.710850000000001,
        "Explorer": 0.81545,
        "Librarian": 1.5639500000000002,
        "Designer": 0.93155,
        "Fixer": 0.9174249999999999,
        "Builder": 1.5611999999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "Step3 VL 10B": {
      "id": "acad0665-9457-4531-abd5-b59efd7a89ea",
      "name": "Step3 VL 10B",
      "provider": "StepFun",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.69,
        "ifbench": 0.502,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.053,
        "tau2": 0.161,
        "hle": 0.102,
        "scicode": 0.311,
        "livecodebench": null,
        "coding_index": 13.9,
        "intelligence_index": 15.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7693999999999999,
        "Oracle": 0.35009999999999997,
        "Explorer": 0.7615500000000001,
        "Librarian": 1.6369,
        "Designer": 0.9279000000000001,
        "Fixer": 0.8407,
        "Builder": 1.4841
      },
      "lastCalculated": "2026-02-14"
    },
    "Molmo2-8B": {
      "id": "3ef6db79-1dfa-4780-8c4b-affe2740d9ac",
      "name": "Molmo2-8B",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.425,
        "ifbench": 0.269,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0,
        "tau2": 0,
        "hle": 0.044,
        "scicode": 0.133,
        "livecodebench": null,
        "coding_index": 4.4,
        "intelligence_index": null,
        "speed": 70.184,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.12535000000000002,
        "Oracle": 0.2147,
        "Explorer": 0.22220000000000004,
        "Librarian": 0.040100000000000004,
        "Designer": 0.35755000000000003,
        "Fixer": 0.30052500000000004,
        "Builder": 0.49595000000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "Molmo 7B-D": {
      "id": "af74f222-05c7-422d-a653-b9c0707c9c72",
      "name": "Molmo 7B-D",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": 0.371,
        "gpqa": 0.24,
        "ifbench": 0.197,
        "aime": null,
        "math_index": 0,
        "terminalbench_hard": 0,
        "tau2": 0,
        "hle": 0.051,
        "scicode": 0.036,
        "livecodebench": 0.039,
        "coding_index": 1.2,
        "intelligence_index": 9.2,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0532,
        "Oracle": 0.15965,
        "Explorer": 0.09965,
        "Librarian": 1.0106499999999998,
        "Designer": 0.20045,
        "Fixer": 0.1497,
        "Builder": 0.17825
      },
      "lastCalculated": "2026-02-14"
    },
    "Olmo 3 7B Think": {
      "id": "338216fb-62c2-48f1-898a-9166d12fb35e",
      "name": "Olmo 3 7B Think",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": 0.655,
        "gpqa": 0.516,
        "ifbench": 0.415,
        "aime": null,
        "math_index": 70.7,
        "terminalbench_hard": 0.008,
        "tau2": 0,
        "hle": 0.057,
        "scicode": 0.212,
        "livecodebench": 0.617,
        "coding_index": 7.6,
        "intelligence_index": 9.5,
        "speed": 175.011,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2137,
        "Oracle": 10.93135,
        "Explorer": 0.45155,
        "Librarian": 1.1068500000000001,
        "Designer": 0.65445,
        "Fixer": 0.6423,
        "Builder": 0.9576500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Olmo 3.1 32B Think": {
      "id": "39b64e04-7a69-4aa2-9e2e-fe38c24681ec",
      "name": "Olmo 3.1 32B Think",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": 0.763,
        "gpqa": 0.591,
        "ifbench": 0.66,
        "aime": null,
        "math_index": 77.3,
        "terminalbench_hard": 0,
        "tau2": 0,
        "hle": 0.06,
        "scicode": 0.293,
        "livecodebench": 0.695,
        "coding_index": 9.8,
        "intelligence_index": 14.2,
        "speed": 96.753,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.75165,
        "Oracle": 11.9698,
        "Explorer": 0.5693,
        "Librarian": 1.61845,
        "Designer": 0.8242,
        "Fixer": 0.799525,
        "Builder": 1.2145
      },
      "lastCalculated": "2026-02-14"
    },
    "Olmo 3.1 32B Instruct": {
      "id": "94a6d26e-a903-47f3-8323-ae422d237bb9",
      "name": "Olmo 3.1 32B Instruct",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.539,
        "ifbench": 0.392,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0,
        "tau2": 0.213,
        "hle": 0.049,
        "scicode": 0.167,
        "livecodebench": null,
        "coding_index": 5.6,
        "intelligence_index": 12,
        "speed": 46.842,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.3879000000000004,
        "Oracle": 0.27195,
        "Explorer": 0.3357,
        "Librarian": 1.2752000000000001,
        "Designer": 0.45885,
        "Fixer": 0.38994999999999996,
        "Builder": 0.6334999999999998
      },
      "lastCalculated": "2026-02-14"
    },
    "Olmo 3 7B Instruct": {
      "id": "8f74a6ed-f82f-4a2f-a96b-4914993e47da",
      "name": "Olmo 3 7B Instruct",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": 0.522,
        "gpqa": 0.4,
        "ifbench": 0.328,
        "aime": null,
        "math_index": 41.3,
        "terminalbench_hard": 0,
        "tau2": 0.126,
        "hle": 0.058,
        "scicode": 0.103,
        "livecodebench": 0.266,
        "coding_index": 3.4,
        "intelligence_index": 8.1,
        "speed": 36.838,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0301,
        "Oracle": 6.4501,
        "Explorer": 0.2566,
        "Librarian": 0.9511000000000001,
        "Designer": 0.3869,
        "Fixer": 0.344225,
        "Builder": 0.4624000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Granite 4.0 Micro": {
      "id": "1fc32894-1060-493b-af94-62bb1068555e",
      "name": "Granite 4.0 Micro",
      "provider": "IBM",
      "benchmarks": {
        "mmlu_pro": 0.447,
        "gpqa": 0.336,
        "ifbench": 0.248,
        "aime": null,
        "math_index": 6,
        "terminalbench_hard": 0.015,
        "tau2": 0.126,
        "hle": 0.051,
        "scicode": 0.119,
        "livecodebench": 0.18,
        "coding_index": 5,
        "intelligence_index": 7.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9540500000000001,
        "Oracle": 1.1152499999999999,
        "Explorer": 0.33475,
        "Librarian": 0.88975,
        "Designer": 0.43095,
        "Fixer": 0.392125,
        "Builder": 0.5953499999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Granite 4.0 H 350M": {
      "id": "a68afa0b-7fe2-4e9d-bf3e-741cce3c6aeb",
      "name": "Granite 4.0 H 350M",
      "provider": "IBM",
      "benchmarks": {
        "mmlu_pro": 0.127,
        "gpqa": 0.257,
        "ifbench": 0.176,
        "aime": null,
        "math_index": 1.3,
        "terminalbench_hard": 0,
        "tau2": 0.146,
        "hle": 0.064,
        "scicode": 0.017,
        "livecodebench": 0.019,
        "coding_index": 0.6,
        "intelligence_index": 5.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.64145,
        "Oracle": 0.3394,
        "Explorer": 0.0824,
        "Librarian": 0.6004499999999999,
        "Designer": 0.1373,
        "Fixer": 0.09697499999999999,
        "Builder": 0.1037
      },
      "lastCalculated": "2026-02-14"
    },
    "Granite 4.0 H 1B": {
      "id": "dafbb6d2-4825-43d1-a927-feedcfd2e998",
      "name": "Granite 4.0 H 1B",
      "provider": "IBM",
      "benchmarks": {
        "mmlu_pro": 0.277,
        "gpqa": 0.263,
        "ifbench": 0.262,
        "aime": null,
        "math_index": 6.3,
        "terminalbench_hard": 0,
        "tau2": 0.196,
        "hle": 0.05,
        "scicode": 0.082,
        "livecodebench": 0.115,
        "coding_index": 2.7,
        "intelligence_index": 8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.95305,
        "Oracle": 1.1067,
        "Explorer": 0.2142,
        "Librarian": 0.90235,
        "Designer": 0.2735,
        "Fixer": 0.23945,
        "Builder": 0.3405
      },
      "lastCalculated": "2026-02-14"
    },
    "Granite 4.0 H Small": {
      "id": "5dba8d07-9992-483c-81db-dac97cb15ba8",
      "name": "Granite 4.0 H Small",
      "provider": "IBM",
      "benchmarks": {
        "mmlu_pro": 0.624,
        "gpqa": 0.416,
        "ifbench": 0.315,
        "aime": null,
        "math_index": 13.7,
        "terminalbench_hard": 0.023,
        "tau2": 0.173,
        "hle": 0.037,
        "scicode": 0.209,
        "livecodebench": 0.251,
        "coding_index": 8.5,
        "intelligence_index": 10.8,
        "speed": 389.884,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.3213500000000002,
        "Oracle": 2.32725,
        "Explorer": 0.5417000000000001,
        "Librarian": 1.2335000000000003,
        "Designer": 0.6578,
        "Fixer": 0.6150500000000001,
        "Builder": 0.9762000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Granite 4.0 350M": {
      "id": "54c7f3fc-7078-442a-b472-e8691257a88c",
      "name": "Granite 4.0 350M",
      "provider": "IBM",
      "benchmarks": {
        "mmlu_pro": 0.124,
        "gpqa": 0.261,
        "ifbench": 0.159,
        "aime": null,
        "math_index": 0,
        "terminalbench_hard": 0,
        "tau2": 0.132,
        "hle": 0.057,
        "scicode": 0.009,
        "livecodebench": 0.024,
        "coding_index": 0.3,
        "intelligence_index": 6.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.76785,
        "Oracle": 0.14575,
        "Explorer": 0.06325,
        "Librarian": 0.7248,
        "Designer": 0.12045,
        "Fixer": 0.081625,
        "Builder": 0.07385
      },
      "lastCalculated": "2026-02-14"
    },
    "Granite 4.0 1B": {
      "id": "a2c8e7b2-57bf-4d1e-96ea-7944d786d94d",
      "name": "Granite 4.0 1B",
      "provider": "IBM",
      "benchmarks": {
        "mmlu_pro": 0.325,
        "gpqa": 0.281,
        "ifbench": 0.205,
        "aime": null,
        "math_index": 6.3,
        "terminalbench_hard": 0,
        "tau2": 0.228,
        "hle": 0.051,
        "scicode": 0.087,
        "livecodebench": 0.047,
        "coding_index": 2.9,
        "intelligence_index": 7.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8885,
        "Oracle": 1.12055,
        "Explorer": 0.23704999999999998,
        "Librarian": 0.8373499999999999,
        "Designer": 0.28959999999999997,
        "Fixer": 0.24482500000000001,
        "Builder": 0.35164999999999996
      },
      "lastCalculated": "2026-02-14"
    },
    "Reka Flash 3": {
      "id": "dbbcf240-a69e-4078-8f16-7c94c7a8c514",
      "name": "Reka Flash 3",
      "provider": "Reka AI",
      "benchmarks": {
        "mmlu_pro": 0.669,
        "gpqa": 0.529,
        "ifbench": 0.304,
        "aime": 0.51,
        "math_index": 33.7,
        "terminalbench_hard": 0,
        "tau2": 0,
        "hle": 0.051,
        "scicode": 0.267,
        "livecodebench": 0.435,
        "coding_index": 8.9,
        "intelligence_index": 9.5,
        "speed": 49.898,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.20175,
        "Oracle": 5.4909500000000016,
        "Explorer": 0.5144500000000001,
        "Librarian": 1.09605,
        "Designer": 0.7131000000000001,
        "Fixer": 0.6783750000000001,
        "Builder": 1.0568000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Hermes 4 - Llama-3.1 70B (Non-reasoning)": {
      "id": "235060f4-057d-4bd1-8b8e-4a92908c770e",
      "name": "Hermes 4 - Llama-3.1 70B (Non-reasoning)",
      "provider": "Nous Research",
      "benchmarks": {
        "mmlu_pro": 0.664,
        "gpqa": 0.491,
        "ifbench": 0.29,
        "aime": null,
        "math_index": 11.3,
        "terminalbench_hard": 0,
        "tau2": 0.216,
        "hle": 0.036,
        "scicode": 0.277,
        "livecodebench": 0.269,
        "coding_index": 9.2,
        "intelligence_index": 13.6,
        "speed": 75.072,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6229000000000002,
        "Oracle": 2.0086999999999997,
        "Explorer": 0.5821999999999999,
        "Librarian": 1.5210000000000001,
        "Designer": 0.71495,
        "Fixer": 0.667225,
        "Builder": 1.0571499999999998
      },
      "lastCalculated": "2026-02-14"
    },
    "Hermes 4 - Llama-3.1 70B (Reasoning)": {
      "id": "6ba9e8eb-8124-436d-842f-dbe36df80c27",
      "name": "Hermes 4 - Llama-3.1 70B (Reasoning)",
      "provider": "Nous Research",
      "benchmarks": {
        "mmlu_pro": 0.811,
        "gpqa": 0.699,
        "ifbench": 0.313,
        "aime": null,
        "math_index": 68.7,
        "terminalbench_hard": 0.045,
        "tau2": 0.225,
        "hle": 0.079,
        "scicode": 0.341,
        "livecodebench": 0.653,
        "coding_index": 14.4,
        "intelligence_index": 16,
        "speed": 83.451,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9309,
        "Oracle": 10.73955,
        "Explorer": 0.8793000000000001,
        "Librarian": 1.7991500000000002,
        "Designer": 1.0556,
        "Fixer": 1.0382,
        "Builder": 1.6640500000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepHermes 3 - Llama-3.1 8B Preview (Non-reasoning)": {
      "id": "b7726745-9c77-40c3-8452-974cb53d6fbc",
      "name": "DeepHermes 3 - Llama-3.1 8B Preview (Non-reasoning)",
      "provider": "Nous Research",
      "benchmarks": {
        "mmlu_pro": 0.365,
        "gpqa": 0.27,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.043,
        "scicode": 0.091,
        "livecodebench": 0.085,
        "coding_index": null,
        "intelligence_index": 7.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.86875,
        "Oracle": 0.17365000000000003,
        "Explorer": 0.03865,
        "Librarian": 0.82765,
        "Designer": 0.12655,
        "Fixer": 0.092025,
        "Builder": 0.05800000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Hermes 4 - Llama-3.1 405B (Reasoning)": {
      "id": "82b207dd-d285-4a52-b2fc-2cbd27543899",
      "name": "Hermes 4 - Llama-3.1 405B (Reasoning)",
      "provider": "Nous Research",
      "benchmarks": {
        "mmlu_pro": 0.829,
        "gpqa": 0.727,
        "ifbench": 0.327,
        "aime": null,
        "math_index": 69.7,
        "terminalbench_hard": 0.114,
        "tau2": 0.222,
        "hle": 0.103,
        "scicode": 0.252,
        "livecodebench": 0.686,
        "coding_index": 16,
        "intelligence_index": 18.6,
        "speed": 34.231,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2010000000000005,
        "Oracle": 10.906550000000001,
        "Explorer": 0.98915,
        "Librarian": 2.070150000000001,
        "Designer": 1.1491,
        "Fixer": 1.13445,
        "Builder": 1.8334000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Hermes 4 - Llama-3.1 405B (Non-reasoning)": {
      "id": "d3968fd3-97d8-4693-8d26-19cefc6f5d5f",
      "name": "Hermes 4 - Llama-3.1 405B (Non-reasoning)",
      "provider": "Nous Research",
      "benchmarks": {
        "mmlu_pro": 0.729,
        "gpqa": 0.536,
        "ifbench": 0.348,
        "aime": null,
        "math_index": 15.3,
        "terminalbench_hard": 0.098,
        "tau2": 0.266,
        "hle": 0.042,
        "scicode": 0.346,
        "livecodebench": 0.546,
        "coding_index": 18.1,
        "intelligence_index": 17.6,
        "speed": 31.568,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.0553500000000002,
        "Oracle": 2.638,
        "Explorer": 1.0857,
        "Librarian": 1.9433500000000001,
        "Designer": 1.1873500000000001,
        "Fixer": 1.1827000000000003,
        "Builder": 1.9993500000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepHermes 3 - Mistral 24B Preview (Non-reasoning)": {
      "id": "a8efb564-9d17-4d7f-8f43-e9110657ce21",
      "name": "DeepHermes 3 - Mistral 24B Preview (Non-reasoning)",
      "provider": "Nous Research",
      "benchmarks": {
        "mmlu_pro": 0.58,
        "gpqa": 0.382,
        "ifbench": null,
        "aime": 0.047,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.039,
        "scicode": 0.228,
        "livecodebench": 0.195,
        "coding_index": null,
        "intelligence_index": 10.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2534,
        "Oracle": 0.26034999999999997,
        "Explorer": 0.059949999999999996,
        "Librarian": 1.1887,
        "Designer": 0.18639999999999998,
        "Fixer": 0.15025,
        "Builder": 0.09645000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Exaone 4.0 1.2B (Reasoning)": {
      "id": "d734e2ce-5cf8-467f-8148-586d02671333",
      "name": "Exaone 4.0 1.2B (Reasoning)",
      "provider": "LG AI Research",
      "benchmarks": {
        "mmlu_pro": 0.588,
        "gpqa": 0.515,
        "ifbench": 0.23,
        "aime": null,
        "math_index": 50.3,
        "terminalbench_hard": 0,
        "tau2": 0.164,
        "hle": 0.058,
        "scicode": 0.093,
        "livecodebench": 0.516,
        "coding_index": 3.1,
        "intelligence_index": 8.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0721,
        "Oracle": 7.864199999999999,
        "Explorer": 0.25770000000000004,
        "Librarian": 0.9750000000000001,
        "Designer": 0.40075,
        "Fixer": 0.386375,
        "Builder": 0.47980000000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "K-EXAONE (Reasoning)": {
      "id": "715e05fb-1313-441c-bf1d-8651c752a841",
      "name": "K-EXAONE (Reasoning)",
      "provider": "LG AI Research",
      "benchmarks": {
        "mmlu_pro": 0.838,
        "gpqa": 0.783,
        "ifbench": 0.647,
        "aime": null,
        "math_index": 90.3,
        "terminalbench_hard": 0.227,
        "tau2": 0.743,
        "hle": 0.131,
        "scicode": 0.356,
        "livecodebench": 0.768,
        "coding_index": 27,
        "intelligence_index": 32.1,
        "speed": 143.261,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.66365,
        "Oracle": 14.026850000000001,
        "Explorer": 1.7169,
        "Librarian": 3.5140000000000007,
        "Designer": 1.74925,
        "Fixer": 1.748975,
        "Builder": 2.9677500000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "EXAONE 4.0 32B (Non-reasoning)": {
      "id": "2f60d80d-c3d3-4a43-bded-0557898c4618",
      "name": "EXAONE 4.0 32B (Non-reasoning)",
      "provider": "LG AI Research",
      "benchmarks": {
        "mmlu_pro": 0.768,
        "gpqa": 0.628,
        "ifbench": 0.335,
        "aime": 0.47,
        "math_index": 39.3,
        "terminalbench_hard": 0.015,
        "tau2": 0.041,
        "hle": 0.049,
        "scicode": 0.252,
        "livecodebench": 0.472,
        "coding_index": 9.4,
        "intelligence_index": 11.5,
        "speed": 88.934,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.44515,
        "Oracle": 6.38225,
        "Explorer": 0.5655,
        "Librarian": 1.3175000000000001,
        "Designer": 0.7806,
        "Fixer": 0.7373750000000001,
        "Builder": 1.1287500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "EXAONE 4.0 32B (Reasoning)": {
      "id": "44b19b51-5367-4ef9-a2ff-2f90b89a0867",
      "name": "EXAONE 4.0 32B (Reasoning)",
      "provider": "LG AI Research",
      "benchmarks": {
        "mmlu_pro": 0.818,
        "gpqa": 0.739,
        "ifbench": 0.363,
        "aime": 0.843,
        "math_index": 80,
        "terminalbench_hard": 0.038,
        "tau2": 0.173,
        "hle": 0.105,
        "scicode": 0.344,
        "livecodebench": 0.747,
        "coding_index": 14,
        "intelligence_index": 16.6,
        "speed": 97.754,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.00225,
        "Oracle": 12.62515,
        "Explorer": 0.8455,
        "Librarian": 1.8678000000000001,
        "Designer": 1.0542500000000001,
        "Fixer": 1.039575,
        "Builder": 1.6450000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "K-EXAONE (Non-reasoning)": {
      "id": "9cc377dc-67ae-4042-bafc-0466b5f05089",
      "name": "K-EXAONE (Non-reasoning)",
      "provider": "LG AI Research",
      "benchmarks": {
        "mmlu_pro": 0.81,
        "gpqa": 0.695,
        "ifbench": 0.396,
        "aime": null,
        "math_index": 44,
        "terminalbench_hard": 0.068,
        "tau2": 0.591,
        "hle": 0.054,
        "scicode": 0.27,
        "livecodebench": null,
        "coding_index": 13.5,
        "intelligence_index": 23,
        "speed": 89.238,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.6790000000000003,
        "Oracle": 7.0312,
        "Explorer": 0.9336500000000001,
        "Librarian": 2.5364000000000004,
        "Designer": 1.01525,
        "Fixer": 0.908375,
        "Builder": 1.4798
      },
      "lastCalculated": "2026-02-14"
    },
    "Exaone 4.0 1.2B (Non-reasoning)": {
      "id": "8273650d-40e5-45ee-aeda-df71de784164",
      "name": "Exaone 4.0 1.2B (Non-reasoning)",
      "provider": "LG AI Research",
      "benchmarks": {
        "mmlu_pro": 0.5,
        "gpqa": 0.424,
        "ifbench": 0.253,
        "aime": null,
        "math_index": 24,
        "terminalbench_hard": 0,
        "tau2": 0.205,
        "hle": 0.058,
        "scicode": 0.074,
        "livecodebench": 0.293,
        "coding_index": 2.5,
        "intelligence_index": 8.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0282499999999999,
        "Oracle": 3.8648999999999996,
        "Explorer": 0.22915000000000002,
        "Librarian": 0.9482,
        "Designer": 0.3371,
        "Fixer": 0.30217499999999997,
        "Builder": 0.374
      },
      "lastCalculated": "2026-02-14"
    },
    "MiMo-V2-Flash (Reasoning)": {
      "id": "be185709-ddb4-4268-9597-856464359b25",
      "name": "MiMo-V2-Flash (Reasoning)",
      "provider": "Xiaomi",
      "benchmarks": {
        "mmlu_pro": 0.843,
        "gpqa": 0.846,
        "ifbench": 0.642,
        "aime": null,
        "math_index": 96.3,
        "terminalbench_hard": 0.28,
        "tau2": 0.95,
        "hle": 0.211,
        "scicode": 0.394,
        "livecodebench": 0.868,
        "coding_index": 31.8,
        "intelligence_index": 39.2,
        "speed": 155.284,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 4.40695,
        "Oracle": 14.96285,
        "Explorer": 2.03435,
        "Librarian": 4.268949999999999,
        "Designer": 2.01325,
        "Fixer": 2.0251,
        "Builder": 3.4690499999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "MiMo-V2-Flash (Non-reasoning)": {
      "id": "82b36b4d-84dd-4bc0-ad32-e3aee9442789",
      "name": "MiMo-V2-Flash (Non-reasoning)",
      "provider": "Xiaomi",
      "benchmarks": {
        "mmlu_pro": 0.744,
        "gpqa": 0.656,
        "ifbench": 0.399,
        "aime": null,
        "math_index": 67.7,
        "terminalbench_hard": 0.258,
        "tau2": 0.839,
        "hle": 0.08,
        "scicode": 0.259,
        "livecodebench": 0.402,
        "coding_index": 25.8,
        "intelligence_index": 30.6,
        "speed": 134.863,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.4465500000000002,
        "Oracle": 10.561399999999999,
        "Explorer": 1.6813500000000001,
        "Librarian": 3.3194000000000004,
        "Designer": 1.6135000000000002,
        "Fixer": 1.5963,
        "Builder": 2.76305
      },
      "lastCalculated": "2026-02-14"
    },
    "MiMo-V2-Flash (Feb 2026)": {
      "id": "1479f50b-d37f-4b55-bb8b-4212a15042eb",
      "name": "MiMo-V2-Flash (Feb 2026)",
      "provider": "Xiaomi",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.835,
        "ifbench": 0.718,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.311,
        "tau2": 0.933,
        "hle": 0.2,
        "scicode": 0.383,
        "livecodebench": null,
        "coding_index": 33.5,
        "intelligence_index": 41.4,
        "speed": 156.569,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 4.508,
        "Oracle": 0.4275,
        "Explorer": 2.04265,
        "Librarian": 4.365099999999999,
        "Designer": 1.9755500000000001,
        "Fixer": 1.9001500000000002,
        "Builder": 3.4694
      },
      "lastCalculated": "2026-02-14"
    },
    "ERNIE 5.0 Thinking Preview": {
      "id": "a518a64b-e337-48f3-85a1-ba7dc0e8f961",
      "name": "ERNIE 5.0 Thinking Preview",
      "provider": "Baidu",
      "benchmarks": {
        "mmlu_pro": 0.83,
        "gpqa": 0.777,
        "ifbench": 0.414,
        "aime": null,
        "math_index": 85,
        "terminalbench_hard": 0.25,
        "tau2": 0.839,
        "hle": 0.127,
        "scicode": 0.375,
        "livecodebench": 0.812,
        "coding_index": 29.2,
        "intelligence_index": 29.1,
        "speed": 32.343,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.3359,
        "Oracle": 13.22785,
        "Explorer": 1.8591,
        "Librarian": 3.1978999999999997,
        "Designer": 1.8328499999999999,
        "Fixer": 1.8574,
        "Builder": 3.1817
      },
      "lastCalculated": "2026-02-14"
    },
    "ERNIE 4.5 300B A47B": {
      "id": "ae4fe623-80ab-4ea3-8921-70a18ea0fc7e",
      "name": "ERNIE 4.5 300B A47B",
      "provider": "Baidu",
      "benchmarks": {
        "mmlu_pro": 0.776,
        "gpqa": 0.811,
        "ifbench": 0.391,
        "aime": 0.493,
        "math_index": 41.3,
        "terminalbench_hard": 0.061,
        "tau2": 0,
        "hle": 0.035,
        "scicode": 0.315,
        "livecodebench": 0.467,
        "coding_index": 14.5,
        "intelligence_index": 14.9,
        "speed": 29.278,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8272500000000003,
        "Oracle": 6.77845,
        "Explorer": 0.8287500000000001,
        "Librarian": 1.6560000000000001,
        "Designer": 1.08675,
        "Fixer": 1.0278250000000002,
        "Builder": 1.6595
      },
      "lastCalculated": "2026-02-14"
    },
    "Cogito v2.1 (Reasoning)": {
      "id": "ea5d2c10-1051-437d-95c2-18d5e4d14ff3",
      "name": "Cogito v2.1 (Reasoning)",
      "provider": "Deep Cogito",
      "benchmarks": {
        "mmlu_pro": 0.849,
        "gpqa": 0.768,
        "ifbench": 0.463,
        "aime": null,
        "math_index": 72.7,
        "terminalbench_hard": 0.167,
        "tau2": null,
        "hle": 0.11,
        "scicode": 0.41,
        "livecodebench": 0.688,
        "coding_index": 24.8,
        "intelligence_index": null,
        "speed": 73.442,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.35040000000000004,
        "Oracle": 11.379399999999999,
        "Explorer": 1.3972000000000002,
        "Librarian": 0.20665,
        "Designer": 1.6166500000000004,
        "Fixer": 1.5934000000000004,
        "Builder": 2.7256000000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 65B": {
      "id": "fe11ab6c-a4dd-4c28-9fef-07da76d5ed14",
      "name": "Llama 65B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.4,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.4,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "KAT-Coder-Pro V1": {
      "id": "fb112343-c82c-4b43-afea-996bd5101d62",
      "name": "KAT-Coder-Pro V1",
      "provider": "KwaiKAT",
      "benchmarks": {
        "mmlu_pro": 0.813,
        "gpqa": 0.764,
        "ifbench": 0.684,
        "aime": null,
        "math_index": 94.7,
        "terminalbench_hard": 0.091,
        "tau2": 0.886,
        "hle": 0.334,
        "scicode": 0.366,
        "livecodebench": 0.747,
        "coding_index": 18.3,
        "intelligence_index": 36.1,
        "speed": 57.582,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 4.075950000000001,
        "Oracle": 14.685,
        "Explorer": 1.2709000000000001,
        "Librarian": 3.9891500000000004,
        "Designer": 1.32975,
        "Fixer": 1.2975500000000002,
        "Builder": 2.0932999999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "INTELLECT-3": {
      "id": "369329e4-629f-425d-975a-e8980aec2965",
      "name": "INTELLECT-3",
      "provider": "Prime Intellect",
      "benchmarks": {
        "mmlu_pro": 0.822,
        "gpqa": 0.761,
        "ifbench": 0.34,
        "aime": null,
        "math_index": 88,
        "terminalbench_hard": 0.091,
        "tau2": 0.266,
        "hle": 0.121,
        "scicode": 0.391,
        "livecodebench": 0.777,
        "coding_index": 19.1,
        "intelligence_index": 22.1,
        "speed": 85.996,
        "context_length": 131072,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.563100000000001,
        "Oracle": 13.66875,
        "Explorer": 1.1649178984627369,
        "Librarian": 2.4614798307712284,
        "Designer": 1.3209059661542457,
        "Fixer": 1.3104250000000002,
        "Builder": 2.16075
      },
      "lastCalculated": "2026-02-14"
    },
    "Motif-2-12.7B-Reasoning": {
      "id": "666eb13f-0d22-4438-8eb0-01876e1a8604",
      "name": "Motif-2-12.7B-Reasoning",
      "provider": "Motif Technologies",
      "benchmarks": {
        "mmlu_pro": 0.796,
        "gpqa": 0.695,
        "ifbench": 0.57,
        "aime": null,
        "math_index": 80.3,
        "terminalbench_hard": 0.038,
        "tau2": 0.465,
        "hle": 0.082,
        "scicode": 0.282,
        "livecodebench": 0.651,
        "coding_index": 11.9,
        "intelligence_index": 19.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.3004000000000002,
        "Oracle": 12.476199999999999,
        "Explorer": 0.8101500000000001,
        "Librarian": 2.1575,
        "Designer": 0.9533500000000001,
        "Fixer": 0.927475,
        "Builder": 1.42545
      },
      "lastCalculated": "2026-02-14"
    },
    "K2-V2 (low)": {
      "id": "dae31abc-0587-44d0-ba53-f78e96b6e486",
      "name": "K2-V2 (low)",
      "provider": "MBZUAI Institute of Foundation Models",
      "benchmarks": {
        "mmlu_pro": 0.713,
        "gpqa": 0.541,
        "ifbench": 0.41,
        "aime": null,
        "math_index": 35.3,
        "terminalbench_hard": 0.045,
        "tau2": 0.208,
        "hle": 0.039,
        "scicode": 0.223,
        "livecodebench": 0.393,
        "coding_index": 10.5,
        "intelligence_index": 14.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.73745,
        "Oracle": 5.638749999999999,
        "Explorer": 0.66825,
        "Librarian": 1.62045,
        "Designer": 0.8121,
        "Fixer": 0.7721750000000001,
        "Builder": 1.2192
      },
      "lastCalculated": "2026-02-14"
    },
    "K2-V2 (high)": {
      "id": "a38d719a-709c-4983-b3e7-7090389ae9a6",
      "name": "K2-V2 (high)",
      "provider": "MBZUAI Institute of Foundation Models",
      "benchmarks": {
        "mmlu_pro": 0.786,
        "gpqa": 0.681,
        "ifbench": 0.601,
        "aime": null,
        "math_index": 78.3,
        "terminalbench_hard": 0.098,
        "tau2": 0.278,
        "hle": 0.098,
        "scicode": 0.286,
        "livecodebench": 0.694,
        "coding_index": 16.1,
        "intelligence_index": 20.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.4420499999999996,
        "Oracle": 12.168999999999999,
        "Explorer": 0.9972000000000002,
        "Librarian": 2.3051999999999997,
        "Designer": 1.1630500000000001,
        "Fixer": 1.1438000000000001,
        "Builder": 1.8515500000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "K2 Think V2": {
      "id": "5a49ef80-3af5-404b-8ac0-e1b230ae95de",
      "name": "K2 Think V2",
      "provider": "MBZUAI Institute of Foundation Models",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.713,
        "ifbench": 0.628,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.068,
        "tau2": 0.254,
        "hle": 0.095,
        "scicode": 0.33,
        "livecodebench": null,
        "coding_index": 15.5,
        "intelligence_index": 24.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.7121999999999997,
        "Oracle": 0.36124999999999996,
        "Explorer": 0.8704500000000001,
        "Librarian": 2.5667000000000004,
        "Designer": 1.02555,
        "Fixer": 0.93475,
        "Builder": 1.6527
      },
      "lastCalculated": "2026-02-14"
    },
    "K2-V2 (medium)": {
      "id": "dd738be7-2b69-4775-91a5-8851d3341c2d",
      "name": "K2-V2 (medium)",
      "provider": "MBZUAI Institute of Foundation Models",
      "benchmarks": {
        "mmlu_pro": 0.761,
        "gpqa": 0.598,
        "ifbench": 0.551,
        "aime": null,
        "math_index": 64.7,
        "terminalbench_hard": 0.083,
        "tau2": 0.249,
        "hle": 0.044,
        "scicode": 0.252,
        "livecodebench": 0.541,
        "coding_index": 14,
        "intelligence_index": 18.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2113000000000005,
        "Oracle": 10.0823,
        "Explorer": 0.87375,
        "Librarian": 2.0773500000000005,
        "Designer": 1.0231500000000002,
        "Fixer": 0.9953250000000001,
        "Builder": 1.6065500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Mi:dm K 2.5 Pro": {
      "id": "df4c5a29-4b5c-4fef-9f7f-5e24e118ab65",
      "name": "Mi:dm K 2.5 Pro",
      "provider": "Korea Telecom",
      "benchmarks": {
        "mmlu_pro": 0.809,
        "gpqa": 0.701,
        "ifbench": 0.493,
        "aime": null,
        "math_index": 76.7,
        "terminalbench_hard": 0.023,
        "tau2": 0.865,
        "hle": 0.077,
        "scicode": 0.332,
        "livecodebench": 0.656,
        "coding_index": 12.6,
        "intelligence_index": 23,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.7220000000000004,
        "Oracle": 11.94025,
        "Explorer": 0.9402,
        "Librarian": 2.5802500000000004,
        "Designer": 0.9836,
        "Fixer": 0.971325,
        "Builder": 1.4936000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Mi:dm K 2.5 Pro Preview": {
      "id": "e0099b99-d368-4562-b0de-4016ea58af54",
      "name": "Mi:dm K 2.5 Pro Preview",
      "provider": "Korea Telecom",
      "benchmarks": {
        "mmlu_pro": 0.813,
        "gpqa": 0.722,
        "ifbench": 0.456,
        "aime": null,
        "math_index": 78.7,
        "terminalbench_hard": 0.03,
        "tau2": 0.494,
        "hle": 0.088,
        "scicode": 0.297,
        "livecodebench": 0.576,
        "coding_index": 11.9,
        "intelligence_index": null,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.38415,
        "Oracle": 12.251700000000001,
        "Explorer": 0.8162,
        "Librarian": 0.24334999999999998,
        "Designer": 0.9518500000000001,
        "Fixer": 0.916575,
        "Builder": 1.4120500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "HyperCLOVA X SEED Think (32B)": {
      "id": "339a92c1-8a42-417f-8d1f-cdbc605acd9e",
      "name": "HyperCLOVA X SEED Think (32B)",
      "provider": "Naver",
      "benchmarks": {
        "mmlu_pro": 0.785,
        "gpqa": 0.615,
        "ifbench": 0.379,
        "aime": null,
        "math_index": 59,
        "terminalbench_hard": 0.121,
        "tau2": 0.874,
        "hle": 0.055,
        "scicode": 0.284,
        "livecodebench": 0.629,
        "coding_index": 17.5,
        "intelligence_index": 23.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.755,
        "Oracle": 9.23875,
        "Explorer": 1.22315,
        "Librarian": 2.62955,
        "Designer": 1.1899,
        "Fixer": 1.2001,
        "Builder": 1.96405
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.7 (Reasoning)": {
      "id": "6fc35842-0165-44cf-8570-c484a92b3d8c",
      "name": "GLM-4.7 (Reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.856,
        "gpqa": 0.859,
        "ifbench": 0.679,
        "aime": null,
        "math_index": 95,
        "terminalbench_hard": 0.318,
        "tau2": 0.959,
        "hle": 0.251,
        "scicode": 0.451,
        "livecodebench": 0.894,
        "coding_index": 36.3,
        "intelligence_index": 42,
        "speed": 115.081,
        "context_length": null,
        "GDPval_AA_ELO": 1199,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 364.39795,
        "Oracle": 14.77765,
        "Explorer": 2.2801,
        "Librarian": 4.567500000000001,
        "Designer": 361.95115,
        "Fixer": 2.26455,
        "Builder": 3.92675
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-5 (Reasoning)": {
      "id": "40663ad2-b218-471e-bdd4-a1e0c2360e2b",
      "name": "GLM-5 (Reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.82,
        "ifbench": 0.723,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.432,
        "tau2": 0.982,
        "hle": 0.272,
        "scicode": 0.462,
        "livecodebench": null,
        "coding_index": 44.2,
        "intelligence_index": 49.6,
        "speed": 67.241,
        "context_length": null,
        "GDPval_AA_ELO": 1409,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 428.03065,
        "Oracle": 0.4236,
        "Explorer": 2.6419000000000006,
        "Librarian": 5.212100000000001,
        "Designer": 425.21449999999993,
        "Fixer": 2.4484500000000007,
        "Builder": 4.538150000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-5 (Non-reasoning)": {
      "id": "f164b41f-44c5-4675-bca3-fea1db4bd9ae",
      "name": "GLM-5 (Non-reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.666,
        "ifbench": 0.552,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.394,
        "tau2": 0.974,
        "hle": 0.072,
        "scicode": 0.383,
        "livecodebench": null,
        "coding_index": 39,
        "intelligence_index": 40.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": 1333,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 404.2634,
        "Oracle": 0.3366,
        "Explorer": 2.3547000000000002,
        "Librarian": 4.224200000000001,
        "Designer": 402.0789,
        "Fixer": 2.150825,
        "Builder": 3.9942000000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.7-Flash (Reasoning)": {
      "id": "2c4394a2-b443-470a-908e-5c4a271b780c",
      "name": "GLM-4.7-Flash (Reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.581,
        "ifbench": 0.608,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.22,
        "tau2": 0.988,
        "hle": 0.071,
        "scicode": 0.337,
        "livecodebench": null,
        "coding_index": 25.9,
        "intelligence_index": 30.1,
        "speed": 49.498,
        "context_length": null,
        "GDPval_AA_ELO": 1199,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 363.01619999999997,
        "Oracle": 0.29405,
        "Explorer": 1.63355,
        "Librarian": 3.1909,
        "Designer": 361.20814999999993,
        "Fixer": 1.4676749999999998,
        "Builder": 2.6785
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.7-Flash (Non-reasoning)": {
      "id": "c8673741-5e1a-46a1-9e4f-710a5c920982",
      "name": "GLM-4.7-Flash (Non-reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.452,
        "ifbench": 0.463,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.038,
        "tau2": 0.918,
        "hle": 0.049,
        "scicode": 0.255,
        "livecodebench": null,
        "coding_index": 11,
        "intelligence_index": 21.5,
        "speed": 102.537,
        "context_length": null,
        "GDPval_AA_ELO": 1199,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 362.10164999999995,
        "Oracle": 0.22845000000000001,
        "Explorer": 0.79715,
        "Librarian": 2.3028,
        "Designer": 360.4142,
        "Fixer": 0.6740750000000001,
        "Builder": 1.16835
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.7 (Non-reasoning)": {
      "id": "81b6ddfc-111e-4422-bd44-42ee6165b699",
      "name": "GLM-4.7 (Non-reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.794,
        "gpqa": 0.664,
        "ifbench": 0.546,
        "aime": null,
        "math_index": 48,
        "terminalbench_hard": 0.303,
        "tau2": 0.942,
        "hle": 0.061,
        "scicode": 0.354,
        "livecodebench": 0.562,
        "coding_index": 32,
        "intelligence_index": 34.1,
        "speed": 123.989,
        "context_length": null,
        "GDPval_AA_ELO": 1199,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 363.538,
        "Oracle": 7.614449999999999,
        "Explorer": 2.0391500000000002,
        "Librarian": 3.6962,
        "Designer": 361.6458,
        "Fixer": 1.9533,
        "Builder": 3.4176999999999995
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.5-Air": {
      "id": "5d303dc9-c027-401f-9803-4e9aa3331007",
      "name": "GLM-4.5-Air",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.815,
        "gpqa": 0.733,
        "ifbench": 0.376,
        "aime": 0.673,
        "math_index": 80.7,
        "terminalbench_hard": 0.205,
        "tau2": 0.465,
        "hle": 0.068,
        "scicode": 0.306,
        "livecodebench": 0.684,
        "coding_index": 23.8,
        "intelligence_index": 23.2,
        "speed": 101.255,
        "context_length": 131072,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.69175,
        "Oracle": 12.690999999999999,
        "Explorer": 1.491917898462737,
        "Librarian": 2.5780298307712277,
        "Designer": 1.5461559661542459,
        "Fixer": 1.5426250000000001,
        "Builder": 2.6154500000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.6V (Reasoning)": {
      "id": "d2d7dd95-770f-4cb0-9bbc-d275ac19c265",
      "name": "GLM-4.6V (Reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.799,
        "gpqa": 0.719,
        "ifbench": 0.301,
        "aime": null,
        "math_index": 85.3,
        "terminalbench_hard": 0.144,
        "tau2": 0.316,
        "hle": 0.089,
        "scicode": 0.304,
        "livecodebench": 0.16,
        "coding_index": 19.7,
        "intelligence_index": 23.5,
        "speed": 78.519,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.6904000000000003,
        "Oracle": 13.238850000000001,
        "Explorer": 1.20595,
        "Librarian": 2.55825,
        "Designer": 1.3235999999999999,
        "Fixer": 1.2417,
        "Builder": 2.1209000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.6V (Non-reasoning)": {
      "id": "43098bd0-77ca-408b-b698-9d60b1d1c3b8",
      "name": "GLM-4.6V (Non-reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.752,
        "gpqa": 0.566,
        "ifbench": 0.279,
        "aime": null,
        "math_index": 26.3,
        "terminalbench_hard": 0.03,
        "tau2": 0.307,
        "hle": 0.037,
        "scicode": 0.272,
        "livecodebench": 0.411,
        "coding_index": 11.1,
        "intelligence_index": 17.1,
        "speed": 35.038,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.00855,
        "Oracle": 4.30505,
        "Explorer": 0.7208,
        "Librarian": 1.8925,
        "Designer": 0.8409,
        "Fixer": 0.8081750000000001,
        "Builder": 1.2798
      },
      "lastCalculated": "2026-02-14"
    },
    "Command A": {
      "id": "3bc32f13-5afa-4e28-bce1-10e57376686b",
      "name": "Command A",
      "provider": "Cohere",
      "benchmarks": {
        "mmlu_pro": 0.712,
        "gpqa": 0.527,
        "ifbench": 0.365,
        "aime": 0.097,
        "math_index": 13,
        "terminalbench_hard": 0.008,
        "tau2": 0.152,
        "hle": 0.046,
        "scicode": 0.281,
        "livecodebench": 0.287,
        "coding_index": 9.9,
        "intelligence_index": 13.4,
        "speed": 57.007,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6221500000000002,
        "Oracle": 2.3064,
        "Explorer": 0.6097,
        "Librarian": 1.5123000000000002,
        "Designer": 0.7746500000000001,
        "Fixer": 0.718175,
        "Builder": 1.1396000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Apriel-v1.6-15B-Thinker": {
      "id": "a71c1a35-ccc8-43f0-a5a2-070a690b9a00",
      "name": "Apriel-v1.6-15B-Thinker",
      "provider": "ServiceNow",
      "benchmarks": {
        "mmlu_pro": 0.79,
        "gpqa": 0.733,
        "ifbench": 0.691,
        "aime": null,
        "math_index": 88,
        "terminalbench_hard": 0.144,
        "tau2": 0.693,
        "hle": 0.098,
        "scicode": 0.373,
        "livecodebench": 0.807,
        "coding_index": 22,
        "intelligence_index": 27.5,
        "speed": 143.862,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.18805,
        "Oracle": 13.6504,
        "Explorer": 1.4147500000000002,
        "Librarian": 3.0363,
        "Designer": 1.48065,
        "Fixer": 1.4856000000000003,
        "Builder": 2.4684
      },
      "lastCalculated": "2026-02-14"
    },
    "Jamba 1.7 Mini": {
      "id": "b4f14013-37dd-4c75-bd8a-378365d9ed77",
      "name": "Jamba 1.7 Mini",
      "provider": "AI21 Labs",
      "benchmarks": {
        "mmlu_pro": 0.388,
        "gpqa": 0.322,
        "ifbench": 0.314,
        "aime": 0.013,
        "math_index": 0.3,
        "terminalbench_hard": 0,
        "tau2": 0.126,
        "hle": 0.045,
        "scicode": 0.093,
        "livecodebench": 0.061,
        "coding_index": 3.1,
        "intelligence_index": 7.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9123000000000001,
        "Oracle": 0.24965,
        "Explorer": 0.22755000000000003,
        "Librarian": 0.8456999999999999,
        "Designer": 0.3296,
        "Fixer": 0.27242500000000003,
        "Builder": 0.38645000000000007
      },
      "lastCalculated": "2026-02-14"
    },
    "Jamba Reasoning 3B": {
      "id": "f78138d6-2e04-4a84-919a-20d177cb6ff1",
      "name": "Jamba Reasoning 3B",
      "provider": "AI21 Labs",
      "benchmarks": {
        "mmlu_pro": 0.577,
        "gpqa": 0.333,
        "ifbench": 0.524,
        "aime": null,
        "math_index": 10.7,
        "terminalbench_hard": 0.008,
        "tau2": 0.158,
        "hle": 0.046,
        "scicode": 0.059,
        "livecodebench": 0.21,
        "coding_index": 2.5,
        "intelligence_index": 10.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.27755,
        "Oracle": 1.8315,
        "Explorer": 0.2277,
        "Librarian": 1.19855,
        "Designer": 0.3518,
        "Fixer": 0.29657500000000003,
        "Builder": 0.36984999999999996
      },
      "lastCalculated": "2026-02-14"
    },
    "Jamba 1.7 Large": {
      "id": "78452c64-7303-4192-bca5-2d9ec5c623d4",
      "name": "Jamba 1.7 Large",
      "provider": "AI21 Labs",
      "benchmarks": {
        "mmlu_pro": 0.577,
        "gpqa": 0.39,
        "ifbench": 0.352,
        "aime": 0.057,
        "math_index": 2.3,
        "terminalbench_hard": 0.023,
        "tau2": 0.135,
        "hle": 0.038,
        "scicode": 0.188,
        "livecodebench": 0.181,
        "coding_index": 7.8,
        "intelligence_index": 9.3,
        "speed": 44.306,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.1608500000000002,
        "Oracle": 0.611,
        "Explorer": 0.49255000000000004,
        "Librarian": 1.07665,
        "Designer": 0.61305,
        "Fixer": 0.5613250000000001,
        "Builder": 0.8926000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Coder 480B A35B Instruct": {
      "id": "093883ed-f5fc-443b-8e18-afbfb166699e",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.788,
        "gpqa": 0.618,
        "ifbench": 0.405,
        "aime": 0.477,
        "math_index": 39.3,
        "terminalbench_hard": 0.189,
        "tau2": 0.436,
        "hle": 0.044,
        "scicode": 0.359,
        "livecodebench": 0.585,
        "coding_index": 24.6,
        "intelligence_index": 24.6,
        "speed": 53.088,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.8061500000000006,
        "Oracle": 6.3804,
        "Explorer": 1.4956,
        "Librarian": 2.675500000000001,
        "Designer": 1.5476,
        "Fixer": 1.548275,
        "Builder": 2.6692000000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 235B A22B Instruct": {
      "id": "d58cf573-1bd3-4d1f-9182-5482a460f570",
      "name": "Qwen3 VL 235B A22B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.823,
        "gpqa": 0.712,
        "ifbench": 0.427,
        "aime": null,
        "math_index": 70.7,
        "terminalbench_hard": 0.068,
        "tau2": 0.351,
        "hle": 0.063,
        "scicode": 0.359,
        "livecodebench": 0.594,
        "coding_index": 16.5,
        "intelligence_index": 20.6,
        "speed": 45.399,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.425,
        "Oracle": 11.04645,
        "Explorer": 1.0254,
        "Librarian": 2.28015,
        "Designer": 1.17545,
        "Fixer": 1.1491,
        "Builder": 1.8728
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Max": {
      "id": "7ae943a9-9310-4472-a834-c61f0ab68485",
      "name": "Qwen3 Max",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.841,
        "gpqa": 0.764,
        "ifbench": 0.441,
        "aime": null,
        "math_index": 80.7,
        "terminalbench_hard": 0.205,
        "tau2": 0.743,
        "hle": 0.111,
        "scicode": 0.383,
        "livecodebench": 0.767,
        "coding_index": 26.4,
        "intelligence_index": 31.3,
        "speed": 26.957,
        "context_length": null,
        "GDPval_AA_ELO": 1161,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 351.8494,
        "Oracle": 12.576649999999999,
        "Explorer": 1.6774,
        "Librarian": 3.4078500000000003,
        "Designer": 349.99235,
        "Fixer": 1.7044500000000002,
        "Builder": 2.8955500000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 235B A22B 2507 Instruct": {
      "id": "3373245b-e6dc-4b66-a7b0-3f06f9b7bd46",
      "name": "Qwen3 235B A22B 2507 Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.828,
        "gpqa": 0.753,
        "ifbench": 0.461,
        "aime": 0.717,
        "math_index": 71.7,
        "terminalbench_hard": 0.152,
        "tau2": 0.333,
        "hle": 0.106,
        "scicode": 0.36,
        "livecodebench": 0.524,
        "coding_index": 22.1,
        "intelligence_index": 24.7,
        "speed": 54.897,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.8472500000000003,
        "Oracle": 11.363000000000001,
        "Explorer": 1.3371500000000003,
        "Librarian": 2.7054000000000005,
        "Designer": 1.4741500000000003,
        "Fixer": 1.434925,
        "Builder": 2.4283500000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 235B A22B (Reasoning)": {
      "id": "a803d3d0-d22e-49a0-ac2c-b9c6f1141065",
      "name": "Qwen3 VL 235B A22B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.836,
        "gpqa": 0.772,
        "ifbench": 0.565,
        "aime": null,
        "math_index": 88.3,
        "terminalbench_hard": 0.114,
        "tau2": 0.541,
        "hle": 0.101,
        "scicode": 0.399,
        "livecodebench": 0.646,
        "coding_index": 20.9,
        "intelligence_index": 27.5,
        "speed": 48.951,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.16865,
        "Oracle": 13.71965,
        "Explorer": 1.3145,
        "Librarian": 3.0163,
        "Designer": 1.43,
        "Fixer": 1.40445,
        "Builder": 2.3341499999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3-Coder-Next": {
      "id": "fc92f822-04b7-420d-9c07-a21af5e9aac7",
      "name": "Qwen3-Coder-Next",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.737,
        "ifbench": 0.352,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.182,
        "tau2": 0.795,
        "hle": 0.093,
        "scicode": 0.323,
        "livecodebench": null,
        "coding_index": 22.9,
        "intelligence_index": 28.1,
        "speed": 122.395,
        "context_length": 262144,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 38.7
      },
      "roleScores": {
        "Orchestrator": 3.0897000000000006,
        "Oracle": 0.37315,
        "Explorer": 1.4587357969254737,
        "Librarian": 3.0151596615424565,
        "Designer": 1.3862619323084913,
        "Fixer": 7.124300000000001,
        "Builder": 13.991300000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen Chat 14B": {
      "id": "c43aa1f9-31bd-4a99-be70-84c5e6bd2e75",
      "name": "Qwen Chat 14B",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 7.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.7400000000000001,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.7400000000000001,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Coder 30B A3B Instruct": {
      "id": "da9fe224-8af3-46d7-a8c4-6220779c3f35",
      "name": "Qwen3 Coder 30B A3B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.706,
        "gpqa": 0.516,
        "ifbench": 0.327,
        "aime": 0.297,
        "math_index": 29,
        "terminalbench_hard": 0.152,
        "tau2": 0.345,
        "hle": 0.04,
        "scicode": 0.278,
        "livecodebench": 0.403,
        "coding_index": 19.4,
        "intelligence_index": 20,
        "speed": 22.353,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2926499999999996,
        "Oracle": 4.739999999999999,
        "Explorer": 1.1896499999999999,
        "Librarian": 2.1851000000000003,
        "Designer": 1.2416,
        "Fixer": 1.225575,
        "Builder": 2.1037
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 4B (Reasoning)": {
      "id": "f93d0750-b659-4ceb-a123-7e657904ef2b",
      "name": "Qwen3 VL 4B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.7,
        "gpqa": 0.494,
        "ifbench": 0.366,
        "aime": null,
        "math_index": 25.7,
        "terminalbench_hard": 0.015,
        "tau2": 0.155,
        "hle": 0.044,
        "scicode": 0.171,
        "livecodebench": 0.32,
        "coding_index": 6.7,
        "intelligence_index": 14.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7642000000000002,
        "Oracle": 4.1742,
        "Explorer": 0.45195,
        "Librarian": 1.6603000000000003,
        "Designer": 0.6045,
        "Fixer": 0.55505,
        "Builder": 0.8207000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Next 80B A3B (Reasoning)": {
      "id": "c8a79180-7d16-4474-8701-9a77c0baa56a",
      "name": "Qwen3 Next 80B A3B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.824,
        "gpqa": 0.759,
        "ifbench": 0.607,
        "aime": null,
        "math_index": 84.3,
        "terminalbench_hard": 0.098,
        "tau2": 0.415,
        "hle": 0.117,
        "scicode": 0.388,
        "livecodebench": 0.784,
        "coding_index": 19.5,
        "intelligence_index": 26.5,
        "speed": 154.167,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.0579500000000004,
        "Oracle": 13.11275,
        "Explorer": 1.2062000000000002,
        "Librarian": 2.9109000000000007,
        "Designer": 1.3607500000000001,
        "Fixer": 1.3490750000000002,
        "Builder": 2.2150499999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 235B A22B 2507 (Reasoning)": {
      "id": "f6ccbe1d-bd7e-484b-9795-18cc9f91552d",
      "name": "Qwen3 235B A22B 2507 (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.843,
        "gpqa": 0.79,
        "ifbench": 0.512,
        "aime": 0.94,
        "math_index": 91,
        "terminalbench_hard": 0.136,
        "tau2": 0.532,
        "hle": 0.15,
        "scicode": 0.424,
        "livecodebench": 0.788,
        "coding_index": 23.2,
        "intelligence_index": 29.5,
        "speed": 43.702,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.36445,
        "Oracle": 14.324800000000002,
        "Explorer": 1.4392,
        "Librarian": 3.2258500000000003,
        "Designer": 1.55015,
        "Fixer": 1.5441,
        "Builder": 2.5849499999999996
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 30B A3B (Reasoning)": {
      "id": "ce3d286e-093d-413d-a81a-0270309f039e",
      "name": "Qwen3 VL 30B A3B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.807,
        "gpqa": 0.72,
        "ifbench": 0.451,
        "aime": null,
        "math_index": 82.3,
        "terminalbench_hard": 0.053,
        "tau2": 0.199,
        "hle": 0.087,
        "scicode": 0.288,
        "livecodebench": 0.697,
        "coding_index": 13.1,
        "intelligence_index": 19.6,
        "speed": 116.375,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.3126,
        "Oracle": 12.790049999999999,
        "Explorer": 0.811,
        "Librarian": 2.1721500000000002,
        "Designer": 1.0098500000000001,
        "Fixer": 0.9882749999999999,
        "Builder": 1.5494500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 1.7B (Reasoning)": {
      "id": "5962d643-0a6f-4630-bb08-ab5720d80056",
      "name": "Qwen3 1.7B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.57,
        "gpqa": 0.356,
        "ifbench": 0.269,
        "aime": 0.51,
        "math_index": 38.7,
        "terminalbench_hard": 0,
        "tau2": 0.26,
        "hle": 0.048,
        "scicode": 0.043,
        "livecodebench": 0.308,
        "coding_index": 1.4,
        "intelligence_index": 7.9,
        "speed": 124.685,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.01305,
        "Oracle": 6.144400000000001,
        "Explorer": 0.1944,
        "Librarian": 0.9428000000000001,
        "Designer": 0.2762,
        "Fixer": 0.24762499999999998,
        "Builder": 0.26374999999999993
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Omni 30B A3B (Reasoning)": {
      "id": "b97ef678-2d31-4375-9416-67ea97f87204",
      "name": "Qwen3 Omni 30B A3B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.792,
        "gpqa": 0.726,
        "ifbench": 0.434,
        "aime": null,
        "math_index": 74,
        "terminalbench_hard": 0.038,
        "tau2": 0.213,
        "hle": 0.073,
        "scicode": 0.306,
        "livecodebench": 0.679,
        "coding_index": 12.7,
        "intelligence_index": 15.6,
        "speed": 96.31,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9104,
        "Oracle": 11.54585,
        "Explorer": 0.7863,
        "Librarian": 1.7654000000000003,
        "Designer": 0.986,
        "Fixer": 0.9634250000000001,
        "Builder": 1.5057500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 4B 2507 Instruct": {
      "id": "b0249961-b8b2-479d-8325-a29ea17c7b89",
      "name": "Qwen3 4B 2507 Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.672,
        "gpqa": 0.517,
        "ifbench": 0.335,
        "aime": null,
        "math_index": 52.3,
        "terminalbench_hard": 0.045,
        "tau2": 0.266,
        "hle": 0.047,
        "scicode": 0.181,
        "livecodebench": 0.377,
        "coding_index": 9.1,
        "intelligence_index": 13.2,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6010499999999999,
        "Oracle": 8.173049999999998,
        "Explorer": 0.60905,
        "Librarian": 1.495,
        "Designer": 0.72325,
        "Fixer": 0.6887250000000001,
        "Builder": 1.0686000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Omni 30B A3B Instruct": {
      "id": "0b226b82-1462-4860-bf1a-f8aed7024791",
      "name": "Qwen3 Omni 30B A3B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.725,
        "gpqa": 0.62,
        "ifbench": 0.312,
        "aime": null,
        "math_index": 52.3,
        "terminalbench_hard": 0.015,
        "tau2": 0.164,
        "hle": 0.051,
        "scicode": 0.186,
        "livecodebench": 0.422,
        "coding_index": 7.2,
        "intelligence_index": 10.7,
        "speed": 87.309,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.36595,
        "Oracle": 8.230049999999999,
        "Explorer": 0.48205000000000003,
        "Librarian": 1.24165,
        "Designer": 0.66005,
        "Fixer": 0.6146500000000001,
        "Builder": 0.8971500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 8B (Reasoning)": {
      "id": "dec8073c-57e2-41c0-b1aa-7a62960f103f",
      "name": "Qwen3 VL 8B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.749,
        "gpqa": 0.579,
        "ifbench": 0.399,
        "aime": null,
        "math_index": 30.7,
        "terminalbench_hard": 0.038,
        "tau2": 0.225,
        "hle": 0.033,
        "scicode": 0.219,
        "livecodebench": 0.353,
        "coding_index": 9.8,
        "intelligence_index": 16.6,
        "speed": 121.393,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9705000000000001,
        "Oracle": 4.97105,
        "Explorer": 0.6380000000000001,
        "Librarian": 1.8446500000000001,
        "Designer": 0.7903,
        "Fixer": 0.73955,
        "Builder": 1.14825
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 30B A3B Instruct": {
      "id": "51d0b717-953d-4b44-af61-406c6b7dff39",
      "name": "Qwen3 VL 30B A3B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.764,
        "gpqa": 0.695,
        "ifbench": 0.331,
        "aime": null,
        "math_index": 72.3,
        "terminalbench_hard": 0.061,
        "tau2": 0.19,
        "hle": 0.064,
        "scicode": 0.308,
        "livecodebench": 0.476,
        "coding_index": 14.3,
        "intelligence_index": 16,
        "speed": 104.463,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.92225,
        "Oracle": 11.272099999999998,
        "Explorer": 0.8665,
        "Librarian": 1.7858999999999998,
        "Designer": 1.04285,
        "Fixer": 1.00215,
        "Builder": 1.62565
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Next 80B A3B Instruct": {
      "id": "2698f6c6-e436-47ce-a583-dbc25596c571",
      "name": "Qwen3 Next 80B A3B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.819,
        "gpqa": 0.738,
        "ifbench": 0.397,
        "aime": null,
        "math_index": 66.3,
        "terminalbench_hard": 0.076,
        "tau2": 0.216,
        "hle": 0.073,
        "scicode": 0.307,
        "livecodebench": 0.684,
        "coding_index": 15.3,
        "intelligence_index": 20.1,
        "speed": 147.782,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.3616,
        "Oracle": 10.399549999999998,
        "Explorer": 0.9349500000000002,
        "Librarian": 2.21605,
        "Designer": 1.11935,
        "Fixer": 1.1007250000000002,
        "Builder": 1.7672000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 1.7B (Non-reasoning)": {
      "id": "2bb84433-f38e-4edc-9b65-4d7b1f473db9",
      "name": "Qwen3 1.7B (Non-reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.411,
        "gpqa": 0.283,
        "ifbench": 0.211,
        "aime": 0.097,
        "math_index": 7.3,
        "terminalbench_hard": 0,
        "tau2": 0.216,
        "hle": 0.052,
        "scicode": 0.069,
        "livecodebench": 0.126,
        "coding_index": 2.3,
        "intelligence_index": 6.8,
        "speed": 113.282,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8514999999999999,
        "Oracle": 1.2995999999999999,
        "Explorer": 0.2127,
        "Librarian": 0.79995,
        "Designer": 0.2737,
        "Fixer": 0.23512499999999997,
        "Builder": 0.3083
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 0.6B (Non-reasoning)": {
      "id": "0e5f6140-1154-4583-a3e0-8c032a338892",
      "name": "Qwen3 0.6B (Non-reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.231,
        "gpqa": 0.231,
        "ifbench": 0.219,
        "aime": 0.017,
        "math_index": 10.3,
        "terminalbench_hard": 0,
        "tau2": 0.146,
        "hle": 0.052,
        "scicode": 0.041,
        "livecodebench": 0.073,
        "coding_index": 1.4,
        "intelligence_index": 5.6,
        "speed": 187.277,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.6882999999999999,
        "Oracle": 1.6896,
        "Explorer": 0.13219999999999998,
        "Librarian": 0.6467499999999999,
        "Designer": 0.1895,
        "Fixer": 0.154325,
        "Builder": 0.19655
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 30B A3B 2507 Instruct": {
      "id": "7ec1065a-c90e-41e4-bd17-abb7042eed76",
      "name": "Qwen3 30B A3B 2507 Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.777,
        "gpqa": 0.659,
        "ifbench": 0.331,
        "aime": 0.727,
        "math_index": 66.3,
        "terminalbench_hard": 0.061,
        "tau2": 0.102,
        "hle": 0.068,
        "scicode": 0.304,
        "livecodebench": 0.515,
        "coding_index": 14.2,
        "intelligence_index": 15,
        "speed": 61.419,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8082,
        "Oracle": 10.500999999999998,
        "Explorer": 0.841,
        "Librarian": 1.68025,
        "Designer": 1.0312000000000001,
        "Fixer": 0.9966000000000002,
        "Builder": 1.6185500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 8B Instruct": {
      "id": "3cf875b8-b6b5-42c0-ad70-617d5be59d00",
      "name": "Qwen3 VL 8B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.686,
        "gpqa": 0.427,
        "ifbench": 0.323,
        "aime": null,
        "math_index": 27.3,
        "terminalbench_hard": 0.023,
        "tau2": 0.292,
        "hle": 0.029,
        "scicode": 0.174,
        "livecodebench": 0.332,
        "coding_index": 7.3,
        "intelligence_index": 14.3,
        "speed": 118.319,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.69595,
        "Oracle": 4.37855,
        "Explorer": 0.51725,
        "Librarian": 1.6031,
        "Designer": 0.60985,
        "Fixer": 0.57755,
        "Builder": 0.8729499999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 0.6B (Reasoning)": {
      "id": "4ae6c88d-9e4a-4850-89fe-18a1c04a66cc",
      "name": "Qwen3 0.6B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.347,
        "gpqa": 0.239,
        "ifbench": 0.233,
        "aime": 0.1,
        "math_index": 18,
        "terminalbench_hard": 0,
        "tau2": 0.211,
        "hle": 0.057,
        "scicode": 0.028,
        "livecodebench": 0.121,
        "coding_index": 0.9,
        "intelligence_index": 6.4,
        "speed": 200.283,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.7959000000000002,
        "Oracle": 2.8770499999999997,
        "Explorer": 0.1353,
        "Librarian": 0.7535500000000002,
        "Designer": 0.1858,
        "Fixer": 0.15132500000000002,
        "Builder": 0.16105
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 32B Instruct": {
      "id": "6da314d3-a984-4734-8f31-47dd32fb4699",
      "name": "Qwen3 VL 32B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.791,
        "gpqa": 0.671,
        "ifbench": 0.392,
        "aime": null,
        "math_index": 68.3,
        "terminalbench_hard": 0.083,
        "tau2": 0.292,
        "hle": 0.063,
        "scicode": 0.301,
        "livecodebench": 0.514,
        "coding_index": 15.6,
        "intelligence_index": 17.2,
        "speed": 67.8,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.06085,
        "Oracle": 10.662749999999999,
        "Explorer": 0.96845,
        "Librarian": 1.9259499999999998,
        "Designer": 1.1118999999999999,
        "Fixer": 1.0795750000000002,
        "Builder": 1.76335
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 4B 2507 (Reasoning)": {
      "id": "2aacdc07-5f4e-4ab9-8ea5-5f7ab93f9eeb",
      "name": "Qwen3 4B 2507 (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.743,
        "gpqa": 0.667,
        "ifbench": 0.498,
        "aime": null,
        "math_index": 82.7,
        "terminalbench_hard": 0.015,
        "tau2": 0.254,
        "hle": 0.059,
        "scicode": 0.256,
        "livecodebench": 0.641,
        "coding_index": 9.5,
        "intelligence_index": 18.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.20495,
        "Oracle": 12.81575,
        "Explorer": 0.62175,
        "Librarian": 2.06435,
        "Designer": 0.8089000000000001,
        "Fixer": 0.78465,
        "Builder": 1.1749
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 32B (Reasoning)": {
      "id": "d370fcbf-c4a1-41a2-abc4-d204fcc3fcbf",
      "name": "Qwen3 VL 32B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.818,
        "gpqa": 0.733,
        "ifbench": 0.594,
        "aime": null,
        "math_index": 84.7,
        "terminalbench_hard": 0.076,
        "tau2": 0.456,
        "hle": 0.096,
        "scicode": 0.285,
        "livecodebench": 0.738,
        "coding_index": 14.5,
        "intelligence_index": 24.5,
        "speed": 83.404,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.854,
        "Oracle": 13.1581,
        "Explorer": 0.9560000000000001,
        "Librarian": 2.7065,
        "Designer": 1.0999500000000002,
        "Fixer": 1.0832750000000002,
        "Builder": 1.7046000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 30B A3B 2507 (Reasoning)": {
      "id": "5e0164b3-d902-4bcb-a1b2-83b4f4cd6143",
      "name": "Qwen3 30B A3B 2507 (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.805,
        "gpqa": 0.707,
        "ifbench": 0.507,
        "aime": 0.907,
        "math_index": 56.3,
        "terminalbench_hard": 0.053,
        "tau2": 0.281,
        "hle": 0.098,
        "scicode": 0.333,
        "livecodebench": 0.707,
        "coding_index": 14.7,
        "intelligence_index": 22.4,
        "speed": 143.841,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.6062999999999996,
        "Oracle": 9.065299999999999,
        "Explorer": 0.91185,
        "Librarian": 2.4689499999999995,
        "Designer": 1.093,
        "Fixer": 1.0735999999999999,
        "Builder": 1.7123499999999998
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 VL 4B Instruct": {
      "id": "f5d83128-047f-496d-ba49-8a428abe8345",
      "name": "Qwen3 VL 4B Instruct",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.634,
        "gpqa": 0.371,
        "ifbench": 0.318,
        "aime": null,
        "math_index": 37,
        "terminalbench_hard": 0,
        "tau2": 0.234,
        "hle": 0.037,
        "scicode": 0.137,
        "livecodebench": 0.29,
        "coding_index": 4.5,
        "intelligence_index": 9.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.1904000000000001,
        "Oracle": 5.80075,
        "Explorer": 0.34875,
        "Librarian": 1.1114000000000002,
        "Designer": 0.44835,
        "Fixer": 0.412725,
        "Builder": 0.5781999999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Max Thinking": {
      "id": "806032ff-6252-4c22-ba99-a126e411b7a4",
      "name": "Qwen3 Max Thinking",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.861,
        "ifbench": 0.707,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.242,
        "tau2": 0.836,
        "hle": 0.262,
        "scicode": 0.431,
        "livecodebench": null,
        "coding_index": 30.5,
        "intelligence_index": 39.7,
        "speed": 39.158,
        "context_length": null,
        "GDPval_AA_ELO": 1161,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 352.63185,
        "Oracle": 0.4436,
        "Explorer": 1.8439,
        "Librarian": 4.2029000000000005,
        "Designer": 350.13715,
        "Fixer": 1.7453750000000001,
        "Builder": 3.1714500000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Max Thinking (Preview)": {
      "id": "cbac8c35-e069-4c73-823e-0953e6ed0e85",
      "name": "Qwen3 Max Thinking (Preview)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.824,
        "gpqa": 0.776,
        "ifbench": 0.538,
        "aime": null,
        "math_index": 82.3,
        "terminalbench_hard": 0.174,
        "tau2": 0.836,
        "hle": 0.12,
        "scicode": 0.387,
        "livecodebench": 0.535,
        "coding_index": 24.5,
        "intelligence_index": 32.5,
        "speed": 51.272,
        "context_length": null,
        "GDPval_AA_ELO": 1161,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 351.99309999999997,
        "Oracle": 12.821399999999999,
        "Explorer": 1.592,
        "Librarian": 3.547,
        "Designer": 349.9084000000001,
        "Fixer": 1.5789250000000001,
        "Builder": 2.67595
      },
      "lastCalculated": "2026-02-14"
    },
    "Ling-mini-2.0": {
      "id": "3d64bf83-232e-427e-8590-26b478bae4a8",
      "name": "Ling-mini-2.0",
      "provider": "InclusionAI",
      "benchmarks": {
        "mmlu_pro": 0.671,
        "gpqa": 0.562,
        "ifbench": 0.236,
        "aime": null,
        "math_index": 49.3,
        "terminalbench_hard": 0.008,
        "tau2": 0.132,
        "hle": 0.05,
        "scicode": 0.135,
        "livecodebench": 0.429,
        "coding_index": 5,
        "intelligence_index": 8.9,
        "speed": 149.585,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.1516500000000003,
        "Oracle": 7.7456,
        "Explorer": 0.3558,
        "Librarian": 1.0424500000000003,
        "Designer": 0.51975,
        "Fixer": 0.4850250000000001,
        "Builder": 0.6659
      },
      "lastCalculated": "2026-02-14"
    },
    "Ring-1T": {
      "id": "a29e66d6-1c3c-456a-8770-59ee3845b35d",
      "name": "Ring-1T",
      "provider": "InclusionAI",
      "benchmarks": {
        "mmlu_pro": 0.806,
        "gpqa": 0.774,
        "ifbench": 0.446,
        "aime": null,
        "math_index": 89.3,
        "terminalbench_hard": 0.068,
        "tau2": 0.263,
        "hle": 0.102,
        "scicode": 0.367,
        "livecodebench": 0.643,
        "coding_index": 16.8,
        "intelligence_index": 22.5,
        "speed": 51.306,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.6189,
        "Oracle": 13.867700000000001,
        "Explorer": 1.01865,
        "Librarian": 2.4724,
        "Designer": 1.2092,
        "Fixer": 1.178,
        "Builder": 1.91645
      },
      "lastCalculated": "2026-02-14"
    },
    "Ring-flash-2.0": {
      "id": "47b7df55-5804-40de-ba11-317de786710a",
      "name": "Ring-flash-2.0",
      "provider": "InclusionAI",
      "benchmarks": {
        "mmlu_pro": 0.793,
        "gpqa": 0.725,
        "ifbench": 0.433,
        "aime": null,
        "math_index": 83.7,
        "terminalbench_hard": 0.076,
        "tau2": 0,
        "hle": 0.089,
        "scicode": 0.168,
        "livecodebench": 0.628,
        "coding_index": 10.6,
        "intelligence_index": 14,
        "speed": 83.729,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7289000000000003,
        "Oracle": 13.00125,
        "Explorer": 0.64415,
        "Librarian": 1.58895,
        "Designer": 0.8824000000000001,
        "Fixer": 0.8457,
        "Builder": 1.288
      },
      "lastCalculated": "2026-02-14"
    },
    "Ling-1T": {
      "id": "15b56b8e-7b93-4ed9-ac06-75c922e3b86e",
      "name": "Ling-1T",
      "provider": "InclusionAI",
      "benchmarks": {
        "mmlu_pro": 0.822,
        "gpqa": 0.719,
        "ifbench": 0.348,
        "aime": null,
        "math_index": 71.3,
        "terminalbench_hard": 0.106,
        "tau2": 0.327,
        "hle": 0.072,
        "scicode": 0.352,
        "livecodebench": 0.677,
        "coding_index": 18.8,
        "intelligence_index": 19,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2520000000000002,
        "Oracle": 11.1403,
        "Explorer": 1.14995,
        "Librarian": 2.1124000000000005,
        "Designer": 1.28505,
        "Fixer": 1.276575,
        "Builder": 2.11195
      },
      "lastCalculated": "2026-02-14"
    },
    "Ling-flash-2.0": {
      "id": "882a5da3-94ca-4602-8693-c45970df17e2",
      "name": "Ling-flash-2.0",
      "provider": "InclusionAI",
      "benchmarks": {
        "mmlu_pro": 0.777,
        "gpqa": 0.657,
        "ifbench": 0.344,
        "aime": null,
        "math_index": 65.3,
        "terminalbench_hard": 0.106,
        "tau2": 0.208,
        "hle": 0.063,
        "scicode": 0.289,
        "livecodebench": 0.589,
        "coding_index": 16.7,
        "intelligence_index": 15.5,
        "speed": 58.494,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8703500000000002,
        "Oracle": 10.20435,
        "Explorer": 1.01025,
        "Librarian": 1.74065,
        "Designer": 1.1564999999999999,
        "Fixer": 1.139825,
        "Builder": 1.8801
      },
      "lastCalculated": "2026-02-14"
    },
    "Doubao Seed Code": {
      "id": "4d6dd5ce-08cb-4e87-9288-1dd2f022aa35",
      "name": "Doubao Seed Code",
      "provider": "ByteDance Seed",
      "benchmarks": {
        "mmlu_pro": 0.854,
        "gpqa": 0.764,
        "ifbench": 0.514,
        "aime": null,
        "math_index": 79.3,
        "terminalbench_hard": 0.265,
        "tau2": 0.582,
        "hle": 0.133,
        "scicode": 0.407,
        "livecodebench": 0.766,
        "coding_index": 31.3,
        "intelligence_index": 33.5,
        "speed": 44.585,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.7662,
        "Oracle": 12.36905,
        "Explorer": 1.9085500000000002,
        "Librarian": 3.6276,
        "Designer": 1.9488,
        "Fixer": 1.9568250000000003,
        "Builder": 3.3897000000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "Doubao-Seed-1.8": {
      "id": "80fb9560-3613-4865-be24-548f8559e5e7",
      "name": "Doubao-Seed-1.8",
      "provider": "ByteDance Seed",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": 0.22,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": null,
        "speed": 44.26,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.0,
        "Oracle": 0.0,
        "Explorer": 0.08800000000000001,
        "Librarian": 0.0,
        "Designer": 0.0,
        "Fixer": 0.022000000000000002,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "o1": {
      "id": "5ad2f60f-ee05-49fd-85a0-cef69aa7cb7b",
      "name": "o1",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.841,
        "gpqa": 0.747,
        "ifbench": 0.703,
        "aime": 0.723,
        "math_index": null,
        "terminalbench_hard": 0.129,
        "tau2": 0.626,
        "hle": 0.077,
        "scicode": 0.358,
        "livecodebench": 0.679,
        "coding_index": 20.5,
        "intelligence_index": 30.7,
        "speed": 96.451,
        "context_length": 200000,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.5136000000000003,
        "Oracle": 0.6060500000000001,
        "Explorer": 1.3496875403789321,
        "Librarian": 3.399879233964887,
        "Designer": 1.4254458467929774,
        "Fixer": 1.39565,
        "Builder": 2.3037500000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "o1-preview": {
      "id": "078f4dc8-5350-40a2-a5ea-e8359f795b70",
      "name": "o1-preview",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": 34,
        "intelligence_index": 23.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.37,
        "Oracle": 0.0,
        "Explorer": 1.7000000000000002,
        "Librarian": 2.37,
        "Designer": 1.7000000000000002,
        "Fixer": 1.7000000000000002,
        "Builder": 3.4000000000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "o1-mini": {
      "id": "b515503d-4d65-4a3f-8a4a-6c731e2b079f",
      "name": "o1-mini",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.742,
        "gpqa": 0.603,
        "ifbench": null,
        "aime": 0.603,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.049,
        "scicode": 0.323,
        "livecodebench": 0.576,
        "coding_index": null,
        "intelligence_index": 20.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2719,
        "Oracle": 0.49874999999999997,
        "Explorer": 0.07665,
        "Librarian": 2.166,
        "Designer": 0.26695,
        "Fixer": 0.259125,
        "Builder": 0.1838
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4o (Aug '24)": {
      "id": "8c1be908-67b6-4cf4-ba08-83ddbe44fde3",
      "name": "GPT-4o (Aug '24)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.521,
        "ifbench": 0.36,
        "aime": 0.117,
        "math_index": null,
        "terminalbench_hard": 0.083,
        "tau2": 0.289,
        "hle": 0.029,
        "scicode": 0.331,
        "livecodebench": 0.317,
        "coding_index": 16.6,
        "intelligence_index": 18.8,
        "speed": 80.827,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.0671000000000004,
        "Oracle": 0.28535000000000005,
        "Explorer": 0.9369000000000001,
        "Librarian": 1.9536,
        "Designer": 0.9991500000000001,
        "Fixer": 0.9975000000000002,
        "Builder": 1.7776500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4o (May '24)": {
      "id": "e98e911e-9fb2-4a9a-826e-3d681d0cdca8",
      "name": "GPT-4o (May '24)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.74,
        "gpqa": 0.526,
        "ifbench": null,
        "aime": 0.11,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.028,
        "scicode": 0.309,
        "livecodebench": 0.334,
        "coding_index": 24.2,
        "intelligence_index": 16,
        "speed": 84.004,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8162,
        "Oracle": 0.36040000000000005,
        "Explorer": 1.2853999999999999,
        "Librarian": 1.7194,
        "Designer": 1.4553,
        "Fixer": 1.420725,
        "Builder": 2.5597
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4 Turbo": {
      "id": "76aa6af5-fdc6-4739-a300-983f14e74a67",
      "name": "GPT-4 Turbo",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.694,
        "gpqa": null,
        "ifbench": null,
        "aime": 0.15,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.033,
        "scicode": 0.319,
        "livecodebench": 0.291,
        "coding_index": 21.5,
        "intelligence_index": 13.7,
        "speed": 26.971,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.4741000000000002,
        "Oracle": 0.10105,
        "Explorer": 1.14605,
        "Librarian": 1.484,
        "Designer": 1.1824,
        "Fixer": 1.1960250000000001,
        "Builder": 2.22835
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4o (Nov '24)": {
      "id": "c1045dc0-4fd3-4adb-9548-18763e0d051f",
      "name": "GPT-4o (Nov '24)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.748,
        "gpqa": 0.543,
        "ifbench": 0.343,
        "aime": 0.15,
        "math_index": 6,
        "terminalbench_hard": 0.083,
        "tau2": 0.251,
        "hle": 0.033,
        "scicode": 0.333,
        "livecodebench": 0.309,
        "coding_index": 16.7,
        "intelligence_index": 17.3,
        "speed": 134.454,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.02735,
        "Oracle": 1.2779499999999997,
        "Explorer": 1.0074,
        "Librarian": 1.9115000000000002,
        "Designer": 1.12055,
        "Fixer": 1.07765,
        "Builder": 1.8252
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4o mini": {
      "id": "b5c1c91a-7474-4409-9a9c-9c2ac45d9eb6",
      "name": "GPT-4o mini",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.648,
        "gpqa": 0.426,
        "ifbench": 0.31,
        "aime": 0.117,
        "math_index": 14.7,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.04,
        "scicode": 0.229,
        "livecodebench": 0.234,
        "coding_index": null,
        "intelligence_index": 12.6,
        "speed": 51.509,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.4889000000000001,
        "Oracle": 2.5081999999999995,
        "Explorer": 0.06680000000000001,
        "Librarian": 1.4002,
        "Designer": 0.2387,
        "Fixer": 0.18502500000000002,
        "Builder": 0.1256
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-3.5 Turbo": {
      "id": "037dec2f-51e8-4127-a1f1-85155dae7a1d",
      "name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.462,
        "gpqa": 0.297,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": 10.7,
        "intelligence_index": 9,
        "speed": 89.778,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0287,
        "Oracle": 0.19469999999999998,
        "Explorer": 0.5812,
        "Librarian": 0.9693,
        "Designer": 0.67855,
        "Fixer": 0.62575,
        "Builder": 1.1228
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4.1": {
      "id": "3b608b70-6434-4baa-99ad-45d499703c67",
      "name": "GPT-4.1",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.806,
        "gpqa": 0.666,
        "ifbench": 0.43,
        "aime": 0.437,
        "math_index": 34.7,
        "terminalbench_hard": 0.136,
        "tau2": 0.471,
        "hle": 0.046,
        "scicode": 0.381,
        "livecodebench": 0.457,
        "coding_index": 21.8,
        "intelligence_index": 25.6,
        "speed": 79.283,
        "context_length": 1047576,
        "GDPval_AA_ELO": 830,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 251.9257,
        "Oracle": 5.7082999999999995,
        "Explorer": 1.49505,
        "Librarian": 3.0348000000000006,
        "Designer": 250.47500000000005,
        "Fixer": 1.3954500000000003,
        "Builder": 2.376950000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4.1 mini": {
      "id": "9f7c7566-a704-49a2-a383-cb3181da33a4",
      "name": "GPT-4.1 mini",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.781,
        "gpqa": 0.664,
        "ifbench": 0.383,
        "aime": 0.43,
        "math_index": 46.3,
        "terminalbench_hard": 0.076,
        "tau2": 0.529,
        "hle": 0.046,
        "scicode": 0.404,
        "livecodebench": 0.483,
        "coding_index": 18.5,
        "intelligence_index": 22.4,
        "speed": 68.63,
        "context_length": null,
        "GDPval_AA_ELO": 830,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 251.6003,
        "Oracle": 7.4434,
        "Explorer": 1.16805,
        "Librarian": 2.46215,
        "Designer": 250.25105000000002,
        "Fixer": 1.2252250000000002,
        "Builder": 2.04705
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 mini (minimal)": {
      "id": "bc26bfdb-4923-4442-a6ca-e77392923581",
      "name": "GPT-5 mini (minimal)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.775,
        "gpqa": 0.687,
        "ifbench": 0.456,
        "aime": null,
        "math_index": 46.7,
        "terminalbench_hard": 0.144,
        "tau2": 0.319,
        "hle": 0.05,
        "scicode": 0.369,
        "livecodebench": 0.545,
        "coding_index": 21.9,
        "intelligence_index": 20.7,
        "speed": 104.808,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 393.32394999999997,
        "Oracle": 7.4285,
        "Explorer": 1.31235,
        "Librarian": 2.2787499999999996,
        "Designer": 392.33359999999993,
        "Fixer": 17.938699999999997,
        "Builder": 32.036
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 (high)": {
      "id": "48e50f00-1fd1-4acc-b337-61078aa341e6",
      "name": "GPT-5 (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.871,
        "gpqa": 0.854,
        "ifbench": 0.731,
        "aime": 0.957,
        "math_index": 94.3,
        "terminalbench_hard": 0.326,
        "tau2": 0.848,
        "hle": 0.265,
        "scicode": 0.429,
        "livecodebench": 0.846,
        "coding_index": 36,
        "intelligence_index": 44.6,
        "speed": 89.73,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 395.8558999999999,
        "Oracle": 14.863749999999998,
        "Explorer": 2.24275,
        "Librarian": 4.82805,
        "Designer": 393.14375,
        "Fixer": 18.770175,
        "Builder": 33.5264
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 (minimal)": {
      "id": "c3738fb0-3408-4430-a699-760ae4b70c93",
      "name": "GPT-5 (minimal)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.806,
        "gpqa": 0.673,
        "ifbench": 0.456,
        "aime": 0.367,
        "math_index": 31.7,
        "terminalbench_hard": 0.182,
        "tau2": 0.67,
        "hle": 0.054,
        "scicode": 0.388,
        "livecodebench": 0.558,
        "coding_index": 25.1,
        "intelligence_index": 23.7,
        "speed": 80.731,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 393.66089999999997,
        "Oracle": 5.2482,
        "Explorer": 1.5786000000000002,
        "Librarian": 2.6197000000000004,
        "Designer": 392.49514999999997,
        "Fixer": 18.114699999999996,
        "Builder": 32.3581
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 (ChatGPT)": {
      "id": "eab1492c-b853-4852-aa71-06b0ec2481c1",
      "name": "GPT-5 (ChatGPT)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.82,
        "gpqa": 0.686,
        "ifbench": 0.45,
        "aime": null,
        "math_index": 48.3,
        "terminalbench_hard": 0.129,
        "tau2": 0,
        "hle": 0.058,
        "scicode": 0.378,
        "livecodebench": 0.543,
        "coding_index": 21.2,
        "intelligence_index": 21.8,
        "speed": 200.867,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 393.4077,
        "Oracle": 7.672899999999999,
        "Explorer": 1.1965000000000001,
        "Librarian": 2.3654,
        "Designer": 392.3053,
        "Fixer": 17.8982,
        "Builder": 31.967550000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5.1 (Non-reasoning)": {
      "id": "d0b3d47e-aec6-425e-9de7-168dcc6d1e28",
      "name": "GPT-5.1 (Non-reasoning)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.801,
        "gpqa": 0.643,
        "ifbench": 0.432,
        "aime": null,
        "math_index": 38,
        "terminalbench_hard": 0.227,
        "tau2": 0.465,
        "hle": 0.052,
        "scicode": 0.365,
        "livecodebench": 0.494,
        "coding_index": 27.3,
        "intelligence_index": 27.4,
        "speed": 87.387,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 394.00005,
        "Oracle": 6.1042000000000005,
        "Explorer": 1.6547500000000002,
        "Librarian": 2.96545,
        "Designer": 392.59430000000003,
        "Fixer": 18.207700000000003,
        "Builder": 32.56405000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 (low)": {
      "id": "7f3c9423-3ee3-4369-a6d9-3f2a40aff00e",
      "name": "GPT-5 (low)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.86,
        "gpqa": 0.808,
        "ifbench": 0.666,
        "aime": 0.83,
        "math_index": 83,
        "terminalbench_hard": 0.265,
        "tau2": 0.842,
        "hle": 0.184,
        "scicode": 0.391,
        "livecodebench": 0.763,
        "coding_index": 30.7,
        "intelligence_index": 39,
        "speed": 84.623,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 395.2747,
        "Oracle": 13.1152,
        "Explorer": 1.9467,
        "Librarian": 4.235,
        "Designer": 392.851,
        "Fixer": 18.474275,
        "Builder": 32.97555
      },
      "lastCalculated": "2026-02-14"
    },
    "o3-pro": {
      "id": "ca04852c-eaae-4881-a208-f9b2ca3b7cd6",
      "name": "o3-pro",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.845,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 40.7,
        "speed": 22.979,
        "context_length": 200000,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 4.239,
        "Oracle": 0.4225,
        "Explorer": 0.02863754037893193,
        "Librarian": 4.117729233964887,
        "Designer": 0.2207958467929773,
        "Fixer": 0.12675,
        "Builder": 0.0845
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4o Realtime (Dec '24)": {
      "id": "e2e9ddc3-8c2d-4bf5-a60a-83a1afe61034",
      "name": "GPT-4o Realtime (Dec '24)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": null,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.0,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.0,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 (medium)": {
      "id": "5e965af0-ca5c-4f47-9ba9-06000508b84a",
      "name": "GPT-5 (medium)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.867,
        "gpqa": 0.842,
        "ifbench": 0.706,
        "aime": 0.917,
        "math_index": 91.7,
        "terminalbench_hard": 0.379,
        "tau2": 0.865,
        "hle": 0.235,
        "scicode": 0.411,
        "livecodebench": 0.703,
        "coding_index": 39,
        "intelligence_index": 41.8,
        "speed": 91.485,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 395.57085,
        "Oracle": 14.45785,
        "Explorer": 2.4163,
        "Librarian": 4.537649999999999,
        "Designer": 393.28465,
        "Fixer": 18.900550000000003,
        "Builder": 33.8023
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 mini (medium)": {
      "id": "c3274a19-6d3c-4d01-ab9b-5055a0a40429",
      "name": "GPT-5 mini (medium)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.828,
        "gpqa": 0.803,
        "ifbench": 0.712,
        "aime": null,
        "math_index": 85,
        "terminalbench_hard": 0.288,
        "tau2": 0.711,
        "hle": 0.146,
        "scicode": 0.41,
        "livecodebench": 0.692,
        "coding_index": 32.9,
        "intelligence_index": 38.8,
        "speed": 91.166,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 395.24269999999996,
        "Oracle": 13.241600000000002,
        "Explorer": 2.02805,
        "Librarian": 4.190300000000001,
        "Designer": 392.9557499999999,
        "Fixer": 18.571474999999996,
        "Builder": 33.185100000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 nano (minimal)": {
      "id": "05e45a36-b5c6-47a1-8adb-9ddc19add5b3",
      "name": "GPT-5 nano (minimal)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.556,
        "gpqa": 0.428,
        "ifbench": 0.325,
        "aime": null,
        "math_index": 27.3,
        "terminalbench_hard": 0.068,
        "tau2": 0.257,
        "hle": 0.041,
        "scicode": 0.291,
        "livecodebench": 0.47,
        "coding_index": 14.2,
        "intelligence_index": 13.7,
        "speed": 122.685,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 392.5134499999999,
        "Oracle": 4.36665,
        "Explorer": 0.8591,
        "Librarian": 1.5239,
        "Designer": 391.837,
        "Fixer": 17.464049999999997,
        "Builder": 31.211349999999996
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4.1 nano": {
      "id": "72c358fd-7d45-4d68-89aa-699743710924",
      "name": "GPT-4.1 nano",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.657,
        "gpqa": 0.512,
        "ifbench": 0.32,
        "aime": 0.237,
        "math_index": 24,
        "terminalbench_hard": 0.038,
        "tau2": 0.173,
        "hle": 0.039,
        "scicode": 0.259,
        "livecodebench": 0.326,
        "coding_index": 11.2,
        "intelligence_index": 12.9,
        "speed": 95.81,
        "context_length": null,
        "GDPval_AA_ELO": 830,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 250.55624999999998,
        "Oracle": 3.9710499999999995,
        "Explorer": 0.6860999999999999,
        "Librarian": 1.4495500000000001,
        "Designer": 249.82244999999998,
        "Fixer": 0.7819999999999999,
        "Builder": 1.2689499999999998
      },
      "lastCalculated": "2026-02-14"
    },
    "o3-mini (high)": {
      "id": "076f2674-bc4b-4925-be59-50832eb8c090",
      "name": "o3-mini (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.802,
        "gpqa": 0.773,
        "ifbench": 0.671,
        "aime": 0.86,
        "math_index": null,
        "terminalbench_hard": 0.061,
        "tau2": 0.313,
        "hle": 0.123,
        "scicode": 0.398,
        "livecodebench": 0.734,
        "coding_index": 17.3,
        "intelligence_index": 25.1,
        "speed": 129.013,
        "context_length": null,
        "GDPval_AA_ELO": 808,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 245.31684999999993,
        "Oracle": 0.64485,
        "Explorer": 1.054,
        "Librarian": 2.7656,
        "Designer": 243.65795,
        "Fixer": 1.228675,
        "Builder": 1.9910500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 Codex (high)": {
      "id": "5d11e7a1-4f70-4e5a-9364-e193761d6757",
      "name": "GPT-5 Codex (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.865,
        "gpqa": 0.837,
        "ifbench": 0.741,
        "aime": null,
        "math_index": 98.7,
        "terminalbench_hard": 0.379,
        "tau2": 0.868,
        "hle": 0.256,
        "scicode": 0.409,
        "livecodebench": 0.84,
        "coding_index": 38.9,
        "intelligence_index": 44.5,
        "speed": 255.347,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 395.84509999999995,
        "Oracle": 15.322799999999999,
        "Explorer": 2.4129,
        "Librarian": 4.81745,
        "Designer": 393.28369999999995,
        "Fixer": 18.916925,
        "Builder": 33.814
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4o (March 2025, chatgpt-4o-latest)": {
      "id": "575498d6-60ec-466b-9372-fea19911fd07",
      "name": "GPT-4o (March 2025, chatgpt-4o-latest)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.803,
        "gpqa": 0.655,
        "ifbench": null,
        "aime": 0.327,
        "math_index": 25.7,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.05,
        "scicode": 0.366,
        "livecodebench": 0.425,
        "coding_index": null,
        "intelligence_index": 18.6,
        "speed": 175.087,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.1114500000000005,
        "Oracle": 4.3307,
        "Explorer": 0.08280000000000001,
        "Librarian": 1.9954500000000004,
        "Designer": 0.2892,
        "Fixer": 0.25145,
        "Builder": 0.1694
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4o mini Realtime (Dec '24)": {
      "id": "4343afb1-c928-44c9-92e2-68fa1195b6f5",
      "name": "GPT-4o mini Realtime (Dec '24)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": null,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.0,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.0,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "o3-mini": {
      "id": "2dad8957-4c16-4e74-bf2d-8b21514e0ae9",
      "name": "o3-mini",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.791,
        "gpqa": 0.748,
        "ifbench": null,
        "aime": 0.77,
        "math_index": null,
        "terminalbench_hard": 0.068,
        "tau2": 0.287,
        "hle": 0.087,
        "scicode": 0.399,
        "livecodebench": 0.717,
        "coding_index": 17.9,
        "intelligence_index": 25.9,
        "speed": 116.202,
        "context_length": 200000,
        "GDPval_AA_ELO": 808,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 245.28694999999996,
        "Oracle": 0.6114499999999999,
        "Explorer": 1.106037540378932,
        "Librarian": 2.8111792339648867,
        "Designer": 243.61889584679298,
        "Fixer": 1.2178,
        "Builder": 2.0119000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "o4-mini (high)": {
      "id": "84b49308-6b93-47aa-a4f6-776ee1a1e8cd",
      "name": "o4-mini (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.832,
        "gpqa": 0.784,
        "ifbench": 0.687,
        "aime": 0.94,
        "math_index": 90.7,
        "terminalbench_hard": 0.152,
        "tau2": 0.556,
        "hle": 0.175,
        "scicode": 0.465,
        "livecodebench": 0.859,
        "coding_index": 25.6,
        "intelligence_index": 33,
        "speed": 111.977,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.7402500000000005,
        "Oracle": 14.27695,
        "Explorer": 1.5717500000000002,
        "Librarian": 3.6016000000000004,
        "Designer": 1.6870000000000003,
        "Fixer": 1.6847250000000003,
        "Builder": 2.8432
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4": {
      "id": "6a7c0e25-1dcb-4b15-8495-a8536a9da051",
      "name": "GPT-4",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": 13.1,
        "intelligence_index": 12.8,
        "speed": 25.633,
        "context_length": 128000,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2800000000000002,
        "Oracle": 0.0,
        "Explorer": 0.6733280258425165,
        "Librarian": 1.3105467097375276,
        "Designer": 0.6611093419475055,
        "Fixer": 0.655,
        "Builder": 1.31
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5.1 (high)": {
      "id": "4dc12a38-b18f-4c43-8e1b-678f8434b5b1",
      "name": "GPT-5.1 (high)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.87,
        "gpqa": 0.873,
        "ifbench": 0.729,
        "aime": null,
        "math_index": 94,
        "terminalbench_hard": 0.455,
        "tau2": 0.819,
        "hle": 0.265,
        "scicode": 0.433,
        "livecodebench": 0.868,
        "coding_index": 44.7,
        "intelligence_index": 47.6,
        "speed": 112.609,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 396.15635,
        "Oracle": 14.63675,
        "Explorer": 2.7220000000000004,
        "Librarian": 5.1248000000000005,
        "Designer": 393.58315,
        "Fixer": 19.223399999999998,
        "Builder": 34.401450000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4o (ChatGPT)": {
      "id": "b4784397-aa28-411b-b011-9c4331bfa9c8",
      "name": "GPT-4o (ChatGPT)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.773,
        "gpqa": 0.511,
        "ifbench": null,
        "aime": 0.103,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.037,
        "scicode": 0.334,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 14.1,
        "speed": 167.822,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6281500000000002,
        "Oracle": 0.35525000000000007,
        "Explorer": 0.07915000000000001,
        "Librarian": 1.5370500000000002,
        "Designer": 0.2474,
        "Fixer": 0.1623,
        "Builder": 0.08975000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-4.5 (Preview)": {
      "id": "5ce30d25-5353-45bb-bef9-6b87480ba3a2",
      "name": "GPT-4.5 (Preview)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 20,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.0,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 2.0,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-5 nano (medium)": {
      "id": "8eb02396-f231-4189-ae15-05f7facebd9b",
      "name": "GPT-5 nano (medium)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": 0.772,
        "gpqa": 0.67,
        "ifbench": 0.659,
        "aime": null,
        "math_index": 78.3,
        "terminalbench_hard": 0.174,
        "tau2": 0.304,
        "hle": 0.076,
        "scicode": 0.338,
        "livecodebench": 0.763,
        "coding_index": 22.9,
        "intelligence_index": 25.7,
        "speed": 131.284,
        "context_length": null,
        "GDPval_AA_ELO": 1303,
        "SWE_bench_Verified": 68.4,
        "SWE_bench_Pro": 41.78
      },
      "roleScores": {
        "Orchestrator": 393.84905,
        "Oracle": 12.161,
        "Explorer": 1.3716,
        "Librarian": 2.8049000000000004,
        "Designer": 392.4018,
        "Fixer": 18.03055,
        "Builder": 32.17700000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "o1-pro": {
      "id": "e8d4100e-165b-4c5d-ac11-ac553590a334",
      "name": "o1-pro",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 25.8,
        "speed": 0,
        "context_length": 200000,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.58,
        "Oracle": 0.0,
        "Explorer": 0.02863754037893193,
        "Librarian": 2.6277292339648866,
        "Designer": 0.009545846792977312,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "GPT-3.5 Turbo (0613)": {
      "id": "8b1a70d1-e05f-426b-9122-023d4629ab47",
      "name": "GPT-3.5 Turbo (0613)",
      "provider": "OpenAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": null,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.0,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.0,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.1 Instruct 70B": {
      "id": "466aecdb-3d96-4191-bc52-b3366db38851",
      "name": "Llama 3.1 Instruct 70B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.676,
        "gpqa": 0.409,
        "ifbench": 0.344,
        "aime": 0.173,
        "math_index": 4,
        "terminalbench_hard": 0.03,
        "tau2": 0.152,
        "hle": 0.046,
        "scicode": 0.267,
        "livecodebench": 0.232,
        "coding_index": 10.9,
        "intelligence_index": 12.2,
        "speed": 39.504,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.4700000000000002,
        "Oracle": 0.9089999999999999,
        "Explorer": 0.6649,
        "Librarian": 1.3848,
        "Designer": 0.78765,
        "Fixer": 0.739425,
        "Builder": 1.2167000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.1 Instruct 8B": {
      "id": "739684ba-0f63-4e2a-b4ee-30741c9e9320",
      "name": "Llama 3.1 Instruct 8B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.476,
        "gpqa": 0.259,
        "ifbench": 0.286,
        "aime": 0.077,
        "math_index": 4.3,
        "terminalbench_hard": 0.008,
        "tau2": 0.164,
        "hle": 0.051,
        "scicode": 0.132,
        "livecodebench": 0.116,
        "coding_index": 4.9,
        "intelligence_index": 11.7,
        "speed": 157.388,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.3524999999999998,
        "Oracle": 0.84005,
        "Explorer": 0.33935000000000004,
        "Librarian": 1.3016999999999999,
        "Designer": 0.41485000000000005,
        "Fixer": 0.37135,
        "Builder": 0.5714000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.2 Instruct 3B": {
      "id": "71e8d48c-1920-4f27-8ea9-1f10becc615a",
      "name": "Llama 3.2 Instruct 3B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.347,
        "gpqa": 0.255,
        "ifbench": 0.262,
        "aime": 0.067,
        "math_index": 3.3,
        "terminalbench_hard": null,
        "tau2": 0.211,
        "hle": 0.052,
        "scicode": 0.052,
        "livecodebench": 0.083,
        "coding_index": null,
        "intelligence_index": 9.7,
        "speed": 45.477,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.13345,
        "Oracle": 0.6731999999999999,
        "Explorer": 0.09005,
        "Librarian": 1.0849499999999999,
        "Designer": 0.1472,
        "Fixer": 0.105075,
        "Builder": 0.0684
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3 Instruct 70B": {
      "id": "aa83359a-d804-4f0b-b5bf-dc637711c26f",
      "name": "Llama 3 Instruct 70B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.574,
        "gpqa": 0.379,
        "ifbench": 0.371,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": 0.008,
        "tau2": 0,
        "hle": 0.044,
        "scicode": 0.189,
        "livecodebench": 0.198,
        "coding_index": 6.8,
        "intelligence_index": 10.2,
        "speed": 36.934,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.23755,
        "Oracle": 0.24910000000000002,
        "Explorer": 0.40280000000000005,
        "Librarian": 1.1563999999999999,
        "Designer": 0.56235,
        "Fixer": 0.5080250000000001,
        "Builder": 0.79485
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3 Instruct 8B": {
      "id": "82879bb8-89fb-4adc-b519-315b8ef30b77",
      "name": "Llama 3 Instruct 8B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.405,
        "gpqa": 0.296,
        "ifbench": 0.246,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": 0,
        "tau2": null,
        "hle": 0.051,
        "scicode": 0.119,
        "livecodebench": 0.096,
        "coding_index": 4,
        "intelligence_index": 8.7,
        "speed": 66.339,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.02685,
        "Oracle": 0.19105,
        "Explorer": 0.24305000000000002,
        "Librarian": 0.9706499999999999,
        "Designer": 0.36445,
        "Fixer": 0.314575,
        "Builder": 0.47655000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.2 Instruct 1B": {
      "id": "80f7860a-7665-4658-9f05-15bccf5f832f",
      "name": "Llama 3.2 Instruct 1B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.2,
        "gpqa": 0.196,
        "ifbench": 0.228,
        "aime": 0,
        "math_index": 0,
        "terminalbench_hard": 0,
        "tau2": 0.123,
        "hle": 0.053,
        "scicode": 0.017,
        "livecodebench": 0.019,
        "coding_index": 0.6,
        "intelligence_index": 9.1,
        "speed": 74.643,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0257,
        "Oracle": 0.12065000000000001,
        "Explorer": 0.0834,
        "Librarian": 0.991,
        "Designer": 0.1371,
        "Fixer": 0.09715,
        "Builder": 0.10385000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 2 Chat 70B": {
      "id": "599da8e0-bd9c-4b38-a127-b50e371fbcf8",
      "name": "Llama 2 Chat 70B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.406,
        "gpqa": 0.327,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.05,
        "scicode": null,
        "livecodebench": 0.098,
        "coding_index": null,
        "intelligence_index": 7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8263,
        "Oracle": 0.2066,
        "Explorer": 0.043100000000000006,
        "Librarian": 0.7759,
        "Designer": 0.14765,
        "Fixer": 0.10435,
        "Builder": 0.0677
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 2 Chat 13B": {
      "id": "6b08a75a-19ee-40b4-be33-133b8ef42f92",
      "name": "Llama 2 Chat 13B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.406,
        "gpqa": 0.321,
        "ifbench": null,
        "aime": 0.017,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.047,
        "scicode": 0.118,
        "livecodebench": 0.098,
        "coding_index": null,
        "intelligence_index": 5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.6251,
        "Oracle": 0.20684999999999998,
        "Explorer": 0.04295,
        "Librarian": 0.575,
        "Designer": 0.14585,
        "Fixer": 0.10640000000000001,
        "Builder": 0.0671
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 2 Chat 7B": {
      "id": "ffd65ef7-fbdb-4145-98ae-b5d01cda770b",
      "name": "Llama 2 Chat 7B",
      "provider": "Meta",
      "benchmarks": {
        "mmlu_pro": 0.164,
        "gpqa": 0.227,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.058,
        "scicode": 0,
        "livecodebench": 0.002,
        "coding_index": null,
        "intelligence_index": 4,
        "speed": 108.629,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.47000000000000003,
        "Oracle": 0.13280000000000003,
        "Explorer": 0.0193,
        "Librarian": 0.442,
        "Designer": 0.08715,
        "Fixer": 0.05075,
        "Builder": 0.031200000000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.0 Pro Experimental (Feb '25)": {
      "id": "c6a47d8a-7517-46e2-8383-329fe7241725",
      "name": "Gemini 2.0 Pro Experimental (Feb '25)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.805,
        "gpqa": 0.622,
        "ifbench": null,
        "aime": 0.36,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.068,
        "scicode": 0.312,
        "livecodebench": 0.347,
        "coding_index": 25.5,
        "intelligence_index": 18.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.0551500000000003,
        "Oracle": 0.46690000000000004,
        "Explorer": 1.3589000000000002,
        "Librarian": 1.9511500000000002,
        "Designer": 1.5580500000000002,
        "Fixer": 1.5086500000000003,
        "Builder": 2.7045
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.0 Flash (experimental)": {
      "id": "fddb72bd-60d3-41af-acc5-3df9a290eb8e",
      "name": "Gemini 2.0 Flash (experimental)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.782,
        "gpqa": 0.636,
        "ifbench": null,
        "aime": 0.3,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.047,
        "scicode": 0.34,
        "livecodebench": 0.21,
        "coding_index": null,
        "intelligence_index": 16.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9245,
        "Oracle": 0.45855,
        "Explorer": 0.08055000000000001,
        "Librarian": 1.8114000000000001,
        "Designer": 0.28099999999999997,
        "Fixer": 0.2136,
        "Builder": 0.1342
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 1.5 Pro (Sep '24)": {
      "id": "2ac96b67-f4f8-4c8c-ac08-c7510faa7bb9",
      "name": "Gemini 1.5 Pro (Sep '24)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.75,
        "gpqa": 0.589,
        "ifbench": null,
        "aime": 0.23,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.049,
        "scicode": 0.295,
        "livecodebench": 0.316,
        "coding_index": 23.6,
        "intelligence_index": 16,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8303,
        "Oracle": 0.41795,
        "Explorer": 1.2574500000000002,
        "Librarian": 1.7272,
        "Designer": 1.4446500000000002,
        "Fixer": 1.398125,
        "Builder": 2.5038000000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.0 Flash-Lite (Preview)": {
      "id": "3de55b83-e02b-412e-8211-315bbebe3e94",
      "name": "Gemini 2.0 Flash-Lite (Preview)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.542,
        "ifbench": null,
        "aime": 0.303,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.044,
        "scicode": 0.247,
        "livecodebench": 0.179,
        "coding_index": null,
        "intelligence_index": 14.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5584000000000002,
        "Oracle": 0.3338,
        "Explorer": 0.0022,
        "Librarian": 1.4632000000000003,
        "Designer": 0.1399,
        "Fixer": 0.114325,
        "Builder": 0.08105000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.0 Flash (Feb '25)": {
      "id": "bcca0e70-7e80-4c07-b1fa-b33bcfb19e51",
      "name": "Gemini 2.0 Flash (Feb '25)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.779,
        "gpqa": 0.623,
        "ifbench": 0.402,
        "aime": 0.33,
        "math_index": 21.7,
        "terminalbench_hard": 0.038,
        "tau2": 0.295,
        "hle": 0.053,
        "scicode": 0.333,
        "livecodebench": 0.334,
        "coding_index": 13.6,
        "intelligence_index": 18.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.18125,
        "Oracle": 3.71305,
        "Explorer": 0.8495,
        "Librarian": 2.05245,
        "Designer": 0.9981000000000001,
        "Fixer": 0.9410500000000002,
        "Builder": 1.5314500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 1.5 Flash (Sep '24)": {
      "id": "41faf421-118b-465b-b170-d200776580d1",
      "name": "Gemini 1.5 Flash (Sep '24)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.68,
        "gpqa": 0.463,
        "ifbench": null,
        "aime": 0.18,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.035,
        "scicode": 0.267,
        "livecodebench": 0.273,
        "coding_index": null,
        "intelligence_index": 13.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5746000000000002,
        "Oracle": 0.33725,
        "Explorer": 0.06975,
        "Librarian": 1.4925000000000002,
        "Designer": 0.22125,
        "Fixer": 0.185075,
        "Builder": 0.12125000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 1.5 Flash-8B": {
      "id": "94229066-9381-4ee1-bf70-a16d63756a6e",
      "name": "Gemini 1.5 Flash-8B",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.569,
        "gpqa": 0.359,
        "ifbench": null,
        "aime": 0.033,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.045,
        "scicode": 0.229,
        "livecodebench": 0.217,
        "coding_index": null,
        "intelligence_index": 11.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.26715,
        "Oracle": 0.24525,
        "Explorer": 0.05915,
        "Librarian": 1.20885,
        "Designer": 0.17959999999999998,
        "Fixer": 0.149025,
        "Builder": 0.0969
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Pro Preview (May' 25)": {
      "id": "073b5329-c4b3-4f1f-8f97-4753aadf4398",
      "name": "Gemini 2.5 Pro Preview (May' 25)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.837,
        "gpqa": 0.822,
        "ifbench": null,
        "aime": 0.843,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.154,
        "scicode": 0.416,
        "livecodebench": 0.77,
        "coding_index": null,
        "intelligence_index": 29.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": 939,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 284.93994999999995,
        "Oracle": 0.671,
        "Explorer": 0.0914,
        "Librarian": 3.12175,
        "Designer": 282.04644999999994,
        "Fixer": 0.33290000000000003,
        "Builder": 0.23954999999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash Preview (Non-reasoning)": {
      "id": "55a3ebf6-6117-4cc1-8596-c6de6e552fd4",
      "name": "Gemini 2.5 Flash Preview (Non-reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.783,
        "gpqa": 0.594,
        "ifbench": null,
        "aime": 0.433,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.05,
        "scicode": 0.233,
        "livecodebench": 0.406,
        "coding_index": null,
        "intelligence_index": 17.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.0162500000000003,
        "Oracle": 0.4644,
        "Explorer": 0.08080000000000001,
        "Librarian": 1.9124500000000002,
        "Designer": 0.27095,
        "Fixer": 0.234125,
        "Builder": 0.15945
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash (Reasoning)": {
      "id": "219ed587-60c5-4a48-9517-8480e08d0ca1",
      "name": "Gemini 2.5 Flash (Reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.832,
        "gpqa": 0.79,
        "ifbench": 0.503,
        "aime": 0.823,
        "math_index": 73.3,
        "terminalbench_hard": 0.136,
        "tau2": 0.316,
        "hle": 0.111,
        "scicode": 0.394,
        "livecodebench": 0.695,
        "coding_index": 22.2,
        "intelligence_index": 26.8,
        "speed": 295.004,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.06985,
        "Oracle": 11.643349999999998,
        "Explorer": 1.3321500000000002,
        "Librarian": 2.9200000000000004,
        "Designer": 1.4937,
        "Fixer": 1.47245,
        "Builder": 2.47
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash Preview (Reasoning)": {
      "id": "68c89ebf-779c-4445-9241-de964cd17355",
      "name": "Gemini 2.5 Flash Preview (Reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.8,
        "gpqa": 0.698,
        "ifbench": null,
        "aime": 0.843,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.116,
        "scicode": 0.359,
        "livecodebench": 0.505,
        "coding_index": null,
        "intelligence_index": 24.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.6896,
        "Oracle": 0.6033999999999999,
        "Explorer": 0.08580000000000002,
        "Librarian": 2.5848,
        "Designer": 0.3061,
        "Fixer": 0.269425,
        "Builder": 0.18555000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Pro Preview (Mar' 25)": {
      "id": "62de31e8-a1a3-429c-b634-a2afccfd9363",
      "name": "Gemini 2.5 Pro Preview (Mar' 25)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.858,
        "gpqa": 0.836,
        "ifbench": null,
        "aime": 0.87,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.171,
        "scicode": 0.395,
        "livecodebench": 0.778,
        "coding_index": 46.7,
        "intelligence_index": 30.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": 939,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 285.0258999999999,
        "Oracle": 0.6863499999999999,
        "Explorer": 2.4293500000000003,
        "Librarian": 3.2100000000000004,
        "Designer": 284.3898,
        "Fixer": 2.6727750000000006,
        "Builder": 4.913200000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash-Lite (Non-reasoning)": {
      "id": "1d81aa1c-64c8-442a-9c41-81b37e407b91",
      "name": "Gemini 2.5 Flash-Lite (Non-reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.724,
        "gpqa": 0.474,
        "ifbench": 0.315,
        "aime": 0.5,
        "math_index": 35.3,
        "terminalbench_hard": 0.023,
        "tau2": 0.19,
        "hle": 0.037,
        "scicode": 0.177,
        "livecodebench": 0.4,
        "coding_index": 7.4,
        "intelligence_index": 12.5,
        "speed": 327.127,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.51965,
        "Oracle": 5.706249999999999,
        "Explorer": 0.50095,
        "Librarian": 1.4202,
        "Designer": 0.6323000000000001,
        "Fixer": 0.6007250000000001,
        "Builder": 0.8993500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.0 Flash-Lite (Feb '25)": {
      "id": "7b269763-ecc0-41ef-aa29-47ef632ac065",
      "name": "Gemini 2.0 Flash-Lite (Feb '25)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.724,
        "gpqa": 0.535,
        "ifbench": null,
        "aime": 0.277,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.036,
        "scicode": 0.25,
        "livecodebench": 0.185,
        "coding_index": null,
        "intelligence_index": 14.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6856,
        "Oracle": 0.39710000000000006,
        "Explorer": 0.0742,
        "Librarian": 1.5894,
        "Designer": 0.24595,
        "Fixer": 0.18665,
        "Builder": 0.11745
      },
      "lastCalculated": "2026-02-14"
    },
    "PALM-2": {
      "id": "515852e7-ba9c-4571-8cf9-82ad6b45f22f",
      "name": "PALM-2",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": 4.6,
        "intelligence_index": 8.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.86,
        "Oracle": 0.0,
        "Explorer": 0.22999999999999998,
        "Librarian": 0.86,
        "Designer": 0.22999999999999998,
        "Fixer": 0.22999999999999998,
        "Builder": 0.45999999999999996
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 1.5 Flash (May '24)": {
      "id": "ac48c49d-9e77-4394-ac4e-d1ee51fd5fee",
      "name": "Gemini 1.5 Flash (May '24)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.574,
        "gpqa": 0.324,
        "ifbench": null,
        "aime": 0.093,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.042,
        "scicode": 0.181,
        "livecodebench": 0.196,
        "coding_index": null,
        "intelligence_index": 10.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2009,
        "Oracle": 0.2401,
        "Explorer": 0.0595,
        "Librarian": 1.1487,
        "Designer": 0.1713,
        "Fixer": 0.139925,
        "Builder": 0.09050000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 1.0 Ultra": {
      "id": "2ae624ca-25b4-4cc8-8970-cdfdd3320691",
      "name": "Gemini 1.0 Ultra",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": 17.6,
        "intelligence_index": 10.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.01,
        "Oracle": 0.0,
        "Explorer": 0.8800000000000001,
        "Librarian": 1.01,
        "Designer": 0.8800000000000001,
        "Fixer": 0.8800000000000001,
        "Builder": 1.7600000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 1.0 Pro": {
      "id": "8ddacd41-bf43-411b-aa30-43ebf0567dd8",
      "name": "Gemini 1.0 Pro",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.431,
        "gpqa": 0.277,
        "ifbench": null,
        "aime": 0.007,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.046,
        "scicode": 0.117,
        "livecodebench": 0.116,
        "coding_index": null,
        "intelligence_index": 8.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9700500000000001,
        "Oracle": 0.18530000000000002,
        "Explorer": 0.045399999999999996,
        "Librarian": 0.9284500000000001,
        "Designer": 0.1385,
        "Fixer": 0.104975,
        "Builder": 0.06665
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 1.5 Pro (May '24)": {
      "id": "16f2578b-1b28-4be3-b371-700c2677bcd6",
      "name": "Gemini 1.5 Pro (May '24)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.657,
        "gpqa": 0.371,
        "ifbench": null,
        "aime": 0.08,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.039,
        "scicode": 0.274,
        "livecodebench": 0.244,
        "coding_index": 19.8,
        "intelligence_index": 12,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.3727500000000001,
        "Oracle": 0.26915,
        "Explorer": 1.0576500000000002,
        "Librarian": 1.3102500000000001,
        "Designer": 1.1852,
        "Fixer": 1.1548,
        "Builder": 2.0865500000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash (Non-reasoning)": {
      "id": "6afbfb62-27e4-435e-9c85-d9fe1b92519e",
      "name": "Gemini 2.5 Flash (Non-reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.809,
        "gpqa": 0.683,
        "ifbench": 0.39,
        "aime": 0.5,
        "math_index": 60.3,
        "terminalbench_hard": 0.121,
        "tau2": 0.149,
        "hle": 0.051,
        "scicode": 0.291,
        "livecodebench": 0.495,
        "coding_index": 17.8,
        "intelligence_index": 20.5,
        "speed": 254.874,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.3813500000000003,
        "Oracle": 9.569949999999999,
        "Explorer": 1.0591000000000002,
        "Librarian": 2.2405500000000003,
        "Designer": 1.2262000000000002,
        "Fixer": 1.1902000000000001,
        "Builder": 1.9825000000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash Preview (Sep '25) (Reasoning)": {
      "id": "c7667559-d9b6-43f1-8cd8-8bdbc78d190b",
      "name": "Gemini 2.5 Flash Preview (Sep '25) (Reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.842,
        "gpqa": 0.793,
        "ifbench": 0.523,
        "aime": null,
        "math_index": 78.3,
        "terminalbench_hard": 0.167,
        "tau2": 0.456,
        "hle": 0.127,
        "scicode": 0.405,
        "livecodebench": 0.713,
        "coding_index": 24.6,
        "intelligence_index": 31.1,
        "speed": 320.355,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.5189500000000002,
        "Oracle": 12.232049999999997,
        "Explorer": 1.5013500000000002,
        "Librarian": 3.3723,
        "Designer": 1.6195500000000003,
        "Fixer": 1.6044750000000003,
        "Builder": 2.7145
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash Preview (Sep '25) (Non-reasoning)": {
      "id": "877fdfc9-2026-477a-af96-e4fd602c0131",
      "name": "Gemini 2.5 Flash Preview (Sep '25) (Non-reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.836,
        "gpqa": 0.766,
        "ifbench": 0.435,
        "aime": null,
        "math_index": 56.7,
        "terminalbench_hard": 0.144,
        "tau2": 0.284,
        "hle": 0.078,
        "scicode": 0.375,
        "livecodebench": 0.625,
        "coding_index": 22.1,
        "intelligence_index": 25.5,
        "speed": 275.763,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.92225,
        "Oracle": 8.975500000000002,
        "Explorer": 1.3211000000000002,
        "Librarian": 2.7707,
        "Designer": 1.4732,
        "Fixer": 1.4498750000000002,
        "Builder": 2.4439
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.0 Flash Thinking Experimental (Jan '25)": {
      "id": "0399e614-5d46-484f-9183-e4f32d74e1c6",
      "name": "Gemini 2.0 Flash Thinking Experimental (Jan '25)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.798,
        "gpqa": 0.701,
        "ifbench": null,
        "aime": 0.5,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.071,
        "scicode": 0.329,
        "livecodebench": 0.321,
        "coding_index": 24.1,
        "intelligence_index": 19.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2199,
        "Oracle": 0.53385,
        "Explorer": 1.28835,
        "Librarian": 2.101,
        "Designer": 1.50705,
        "Fixer": 1.446325,
        "Builder": 2.56815
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemma 3n E4B Instruct Preview (May '25)": {
      "id": "bd2c3517-00d8-4ba5-a989-1f1e52f3ffab",
      "name": "Gemma 3n E4B Instruct Preview (May '25)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.483,
        "gpqa": 0.278,
        "ifbench": null,
        "aime": 0.107,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.049,
        "scicode": 0.086,
        "livecodebench": 0.138,
        "coding_index": null,
        "intelligence_index": 10.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.13805,
        "Oracle": 0.21115000000000003,
        "Explorer": 0.05075,
        "Librarian": 1.09715,
        "Designer": 0.14685,
        "Fixer": 0.11284999999999999,
        "Builder": 0.07265
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.5 Flash-Lite (Reasoning)": {
      "id": "f4e8194a-d0e6-48eb-92be-4307de5aeeec",
      "name": "Gemini 2.5 Flash-Lite (Reasoning)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": 0.759,
        "gpqa": 0.625,
        "ifbench": 0.499,
        "aime": 0.703,
        "math_index": 53.3,
        "terminalbench_hard": 0.045,
        "tau2": 0.184,
        "hle": 0.064,
        "scicode": 0.193,
        "livecodebench": 0.593,
        "coding_index": 9.5,
        "intelligence_index": 17.4,
        "speed": 405.152,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.0721000000000003,
        "Oracle": 8.527199999999999,
        "Explorer": 0.6181000000000001,
        "Librarian": 1.9413500000000001,
        "Designer": 0.8014000000000001,
        "Fixer": 0.772475,
        "Builder": 1.16435
      },
      "lastCalculated": "2026-02-14"
    },
    "Gemini 2.0 Flash Thinking Experimental (Dec '24)": {
      "id": "dfeeb904-e784-4d5c-ad66-9400146b150b",
      "name": "Gemini 2.0 Flash Thinking Experimental (Dec '24)",
      "provider": "Google",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 12.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2300000000000002,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 1.2300000000000002,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 3.5 Sonnet (Oct '24)": {
      "id": "0a603978-03b9-4f47-a273-2f7fd969be85",
      "name": "Claude 3.5 Sonnet (Oct '24)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.772,
        "gpqa": 0.599,
        "ifbench": null,
        "aime": 0.157,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.039,
        "scicode": 0.366,
        "livecodebench": 0.381,
        "coding_index": 30.2,
        "intelligence_index": 15.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8256000000000001,
        "Oracle": 0.41004999999999997,
        "Explorer": 1.58915,
        "Librarian": 1.7175,
        "Designer": 1.77945,
        "Fixer": 1.74335,
        "Builder": 3.17565
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 3.5 Sonnet (June '24)": {
      "id": "aca9c1ad-fc86-49f3-a312-b1e517ea100c",
      "name": "Claude 3.5 Sonnet (June '24)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.751,
        "gpqa": 0.56,
        "ifbench": null,
        "aime": 0.097,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.037,
        "scicode": 0.316,
        "livecodebench": null,
        "coding_index": 26,
        "intelligence_index": 14.2,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.64465,
        "Oracle": 0.37635,
        "Explorer": 1.3769500000000001,
        "Librarian": 1.54375,
        "Designer": 1.5563500000000001,
        "Fixer": 1.467,
        "Builder": 2.69355
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 3 Opus": {
      "id": "7829427f-f0e3-4f6d-a228-5fbf70dacc02",
      "name": "Claude 3 Opus",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.696,
        "gpqa": 0.489,
        "ifbench": null,
        "aime": 0.033,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.031,
        "scicode": 0.233,
        "livecodebench": 0.279,
        "coding_index": 19.5,
        "intelligence_index": 12.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.4522,
        "Oracle": 0.32225,
        "Explorer": 1.0461500000000001,
        "Librarian": 1.3637,
        "Designer": 1.20475,
        "Fixer": 1.1656250000000001,
        "Builder": 2.0755500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 3.5 Haiku": {
      "id": "033e4aa9-a556-4224-87b0-341ed1070257",
      "name": "Claude 3.5 Haiku",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.634,
        "gpqa": 0.408,
        "ifbench": 0.428,
        "aime": 0.033,
        "math_index": null,
        "terminalbench_hard": 0.023,
        "tau2": 0.246,
        "hle": 0.035,
        "scicode": 0.274,
        "livecodebench": 0.314,
        "coding_index": 10.7,
        "intelligence_index": 18.7,
        "speed": 48.121,
        "context_length": null,
        "GDPval_AA_ELO": 782,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 236.7355,
        "Oracle": 0.27574999999999994,
        "Explorer": 0.6708500000000001,
        "Librarian": 2.043,
        "Designer": 235.3784,
        "Fixer": 0.7434000000000001,
        "Builder": 1.211
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 3 Sonnet": {
      "id": "b2e68f0a-8f66-4e4c-9821-2b786cea601b",
      "name": "Claude 3 Sonnet",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.579,
        "gpqa": 0.4,
        "ifbench": null,
        "aime": 0.047,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.038,
        "scicode": 0.229,
        "livecodebench": 0.175,
        "coding_index": null,
        "intelligence_index": 10.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.19685,
        "Oracle": 0.2692,
        "Explorer": 0.0598,
        "Librarian": 1.12825,
        "Designer": 0.19065000000000001,
        "Fixer": 0.149875,
        "Builder": 0.0952
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 3 Haiku": {
      "id": "1fc54cef-d179-48b1-a27d-046874e9b208",
      "name": "Claude 3 Haiku",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": 0.01,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": 0.186,
        "livecodebench": 0.154,
        "coding_index": null,
        "intelligence_index": 9.3,
        "speed": 112.421,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9300000000000002,
        "Oracle": 0.002,
        "Explorer": 0.0,
        "Librarian": 0.9300000000000002,
        "Designer": 0.0,
        "Fixer": 0.02775,
        "Builder": 0.0231
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude Instant": {
      "id": "83cb898e-05d9-4e4b-9de3-2d305014d923",
      "name": "Claude Instant",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.434,
        "gpqa": 0.33,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.038,
        "scicode": null,
        "livecodebench": 0.109,
        "coding_index": 7.8,
        "intelligence_index": 7.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8711000000000001,
        "Oracle": 0.21030000000000001,
        "Explorer": 0.4353,
        "Librarian": 0.8165000000000001,
        "Designer": 0.5414,
        "Fixer": 0.49925,
        "Builder": 0.8510500000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4 Opus (Non-reasoning)": {
      "id": "504412c2-2ada-499b-aebf-7e0a35c9d286",
      "name": "Claude 4 Opus (Non-reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.86,
        "gpqa": 0.701,
        "ifbench": 0.433,
        "aime": 0.563,
        "math_index": 36.3,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.059,
        "scicode": 0.409,
        "livecodebench": 0.542,
        "coding_index": null,
        "intelligence_index": 22.2,
        "speed": 39.974,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.5541500000000004,
        "Oracle": 5.99705,
        "Explorer": 0.08895,
        "Librarian": 2.41,
        "Designer": 0.35345000000000004,
        "Fixer": 0.304325,
        "Builder": 0.21605
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 3.7 Sonnet (Reasoning)": {
      "id": "13358187-4584-479c-ab43-5bcdf8f297a4",
      "name": "Claude 3.7 Sonnet (Reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.837,
        "gpqa": 0.772,
        "ifbench": 0.483,
        "aime": 0.487,
        "math_index": 56.3,
        "terminalbench_hard": 0.212,
        "tau2": 0.547,
        "hle": 0.103,
        "scicode": 0.403,
        "livecodebench": 0.473,
        "coding_index": 27.6,
        "intelligence_index": 34.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": 1073,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 325.76709999999997,
        "Oracle": 9.017249999999999,
        "Explorer": 1.6904000000000001,
        "Librarian": 3.71945,
        "Designer": 323.6571499999999,
        "Fixer": 1.7195500000000004,
        "Builder": 2.9741500000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4.1 Opus (Non-reasoning)": {
      "id": "f2f60e3a-e5f5-4471-acd2-9f2f29c76007",
      "name": "Claude 4.1 Opus (Non-reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 23.6,
        "speed": 38.7,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.3600000000000003,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 2.3600000000000003,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4 Sonnet (Reasoning)": {
      "id": "a7564055-f8ba-4c4b-9e2d-060f61263645",
      "name": "Claude 4 Sonnet (Reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.842,
        "gpqa": 0.777,
        "ifbench": 0.547,
        "aime": 0.773,
        "math_index": 74.3,
        "terminalbench_hard": 0.311,
        "tau2": 0.646,
        "hle": 0.096,
        "scicode": 0.4,
        "livecodebench": 0.655,
        "coding_index": 34.1,
        "intelligence_index": 38.6,
        "speed": 79.847,
        "context_length": null,
        "GDPval_AA_ELO": 1159,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 351.98834999999997,
        "Oracle": 11.777099999999999,
        "Explorer": 2.0799000000000003,
        "Librarian": 4.134400000000001,
        "Designer": 349.78985,
        "Fixer": 2.0886,
        "Builder": 3.6554000000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4 Sonnet (Non-reasoning)": {
      "id": "d034dafe-463d-4c50-956f-84fca657b26f",
      "name": "Claude 4 Sonnet (Non-reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.837,
        "gpqa": 0.683,
        "ifbench": 0.454,
        "aime": 0.407,
        "math_index": 38,
        "terminalbench_hard": 0.273,
        "tau2": 0.523,
        "hle": 0.04,
        "scicode": 0.373,
        "livecodebench": 0.449,
        "coding_index": 30.6,
        "intelligence_index": 33,
        "speed": 71.498,
        "context_length": null,
        "GDPval_AA_ELO": 1159,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 351.38255,
        "Oracle": 6.208600000000001,
        "Explorer": 1.8556500000000002,
        "Librarian": 3.53525,
        "Designer": 349.5756999999999,
        "Fixer": 1.8559000000000003,
        "Builder": 3.2602
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4 Opus (Reasoning)": {
      "id": "8a4a5ead-7789-4389-8400-30e9d20370b7",
      "name": "Claude 4 Opus (Reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.873,
        "gpqa": 0.796,
        "ifbench": 0.537,
        "aime": 0.757,
        "math_index": 73.3,
        "terminalbench_hard": 0.311,
        "tau2": 0.705,
        "hle": 0.117,
        "scicode": 0.398,
        "livecodebench": 0.636,
        "coding_index": 34,
        "intelligence_index": 27.4,
        "speed": 45.009,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.1812000000000005,
        "Oracle": 11.637550000000001,
        "Explorer": 2.0938000000000003,
        "Librarian": 3.03025,
        "Designer": 2.0953500000000003,
        "Fixer": 2.087625,
        "Builder": 3.6455000000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 4.1 Opus (Reasoning)": {
      "id": "ccbfa8c3-a762-480b-aade-34fb9697f98c",
      "name": "Claude 4.1 Opus (Reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.88,
        "gpqa": 0.809,
        "ifbench": 0.554,
        "aime": null,
        "math_index": 80.3,
        "terminalbench_hard": 0.343,
        "tau2": 0.714,
        "hle": 0.119,
        "scicode": 0.409,
        "livecodebench": 0.654,
        "coding_index": 36.5,
        "intelligence_index": 31.9,
        "speed": 50.341,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.6383,
        "Oracle": 12.54345,
        "Explorer": 2.2346500000000002,
        "Librarian": 3.4845,
        "Designer": 2.2265500000000005,
        "Fixer": 2.2225250000000005,
        "Builder": 3.9007000000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 3.7 Sonnet (Non-reasoning)": {
      "id": "d925845d-39ad-4de3-8495-f176b79828c0",
      "name": "Claude 3.7 Sonnet (Non-reasoning)",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.803,
        "gpqa": 0.656,
        "ifbench": 0.44,
        "aime": 0.223,
        "math_index": 21,
        "terminalbench_hard": 0.212,
        "tau2": 0.5,
        "hle": 0.048,
        "scicode": 0.376,
        "livecodebench": 0.394,
        "coding_index": 26.7,
        "intelligence_index": 30.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": 1073,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 325.34764999999993,
        "Oracle": 3.6052999999999997,
        "Explorer": 1.6275,
        "Librarian": 3.30885,
        "Designer": 323.5682499999999,
        "Fixer": 1.6379000000000001,
        "Builder": 2.8568499999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 2.0": {
      "id": "ddc748d0-6a9b-466b-8d6c-68417980d56d",
      "name": "Claude 2.0",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.486,
        "gpqa": 0.344,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": 0.194,
        "livecodebench": 0.171,
        "coding_index": 12.9,
        "intelligence_index": 9.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0517,
        "Oracle": 0.2206,
        "Explorer": 0.6936,
        "Librarian": 0.9829,
        "Designer": 0.8039000000000001,
        "Fixer": 0.7757000000000001,
        "Builder": 1.37435
      },
      "lastCalculated": "2026-02-14"
    },
    "Claude 2.1": {
      "id": "9e141c0d-fc82-4e07-bb2e-fe0003bc030b",
      "name": "Claude 2.1",
      "provider": "Anthropic",
      "benchmarks": {
        "mmlu_pro": 0.495,
        "gpqa": 0.319,
        "ifbench": null,
        "aime": 0.033,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.042,
        "scicode": 0.184,
        "livecodebench": 0.195,
        "coding_index": 14,
        "intelligence_index": 9.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0680500000000002,
        "Oracle": 0.2177,
        "Explorer": 0.7516,
        "Librarian": 1.0168500000000003,
        "Designer": 0.8582000000000001,
        "Fixer": 0.8312,
        "Builder": 1.4859000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Large 2 (Nov '24)": {
      "id": "50f92d5f-f413-4c97-8dab-331101622a28",
      "name": "Mistral Large 2 (Nov '24)",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.697,
        "gpqa": 0.486,
        "ifbench": 0.312,
        "aime": 0.11,
        "math_index": 14,
        "terminalbench_hard": 0.061,
        "tau2": 0.307,
        "hle": 0.04,
        "scicode": 0.292,
        "livecodebench": 0.293,
        "coding_index": 13.8,
        "intelligence_index": 15.1,
        "speed": 42.287,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7892499999999998,
        "Oracle": 2.4367,
        "Explorer": 0.8628500000000001,
        "Librarian": 1.6884499999999998,
        "Designer": 0.95125,
        "Fixer": 0.913225,
        "Builder": 1.5230000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Large 2 (Jul '24)": {
      "id": "1b05e346-e86a-4a20-8feb-7da8c65a99aa",
      "name": "Mistral Large 2 (Jul '24)",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.683,
        "gpqa": 0.472,
        "ifbench": 0.316,
        "aime": 0.093,
        "math_index": 0,
        "terminalbench_hard": null,
        "tau2": 0.33,
        "hle": 0.032,
        "scicode": 0.271,
        "livecodebench": 0.267,
        "coding_index": null,
        "intelligence_index": 13,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5772499999999998,
        "Oracle": 0.3245,
        "Explorer": 0.1524,
        "Librarian": 1.47665,
        "Designer": 0.25525,
        "Fixer": 0.20997500000000002,
        "Builder": 0.13720000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Pixtral Large": {
      "id": "de0beaf0-c951-487a-8eb4-3dd12e74122c",
      "name": "Pixtral Large",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.701,
        "gpqa": 0.505,
        "ifbench": 0.345,
        "aime": 0.07,
        "math_index": 2.3,
        "terminalbench_hard": null,
        "tau2": 0.365,
        "hle": 0.036,
        "scicode": 0.292,
        "livecodebench": 0.261,
        "coding_index": null,
        "intelligence_index": 14,
        "speed": 47.252,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6944000000000001,
        "Oracle": 0.6834,
        "Explorer": 0.16315,
        "Librarian": 1.58695,
        "Designer": 0.26949999999999996,
        "Fixer": 0.21867499999999998,
        "Builder": 0.14195000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Small 3": {
      "id": "e5dd499f-c330-45ec-9ff0-a99209c82af7",
      "name": "Mistral Small 3",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.652,
        "gpqa": 0.462,
        "ifbench": 0.264,
        "aime": 0.08,
        "math_index": 4.3,
        "terminalbench_hard": null,
        "tau2": 0.196,
        "hle": 0.041,
        "scicode": 0.236,
        "livecodebench": 0.252,
        "coding_index": null,
        "intelligence_index": 12.7,
        "speed": 227.325,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5194,
        "Oracle": 0.9592499999999999,
        "Explorer": 0.11625,
        "Librarian": 1.4261000000000001,
        "Designer": 0.2438,
        "Fixer": 0.19629999999999997,
        "Builder": 0.12980000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Small (Sep '24)": {
      "id": "7c045ca0-b331-488d-af31-df0fd331dfd1",
      "name": "Mistral Small (Sep '24)",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.529,
        "gpqa": 0.381,
        "ifbench": null,
        "aime": 0.063,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.043,
        "scicode": 0.156,
        "livecodebench": 0.141,
        "coding_index": null,
        "intelligence_index": 10.2,
        "speed": 101.472,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.17555,
        "Oracle": 0.25815,
        "Explorer": 0.05505,
        "Librarian": 1.11225,
        "Designer": 0.1789,
        "Fixer": 0.13509999999999997,
        "Builder": 0.0857
      },
      "lastCalculated": "2026-02-14"
    },
    "Mixtral 8x22B Instruct": {
      "id": "ca6c1412-f3c1-4391-9231-f83a702aa7af",
      "name": "Mixtral 8x22B Instruct",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.537,
        "gpqa": 0.332,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.041,
        "scicode": 0.188,
        "livecodebench": 0.148,
        "coding_index": null,
        "intelligence_index": 9.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.1269500000000001,
        "Oracle": 0.22175,
        "Explorer": 0.05575000000000001,
        "Librarian": 1.07285,
        "Designer": 0.16765,
        "Fixer": 0.13040000000000002,
        "Builder": 0.08225
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Small (Feb '24)": {
      "id": "35d602fc-b8b8-4698-9f4d-f2ce11ca50e4",
      "name": "Mistral Small (Feb '24)",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.419,
        "gpqa": 0.302,
        "ifbench": null,
        "aime": 0.007,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.044,
        "scicode": 0.134,
        "livecodebench": 0.111,
        "coding_index": null,
        "intelligence_index": 9,
        "speed": 109.453,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.02325,
        "Oracle": 0.1965,
        "Explorer": 0.0441,
        "Librarian": 0.97605,
        "Designer": 0.14274999999999996,
        "Fixer": 0.1072,
        "Builder": 0.0678
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Large (Feb '24)": {
      "id": "5e4e4590-a77e-4b66-95f8-f3960a1a7c68",
      "name": "Mistral Large (Feb '24)",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.515,
        "gpqa": 0.351,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.034,
        "scicode": 0.208,
        "livecodebench": 0.178,
        "coding_index": null,
        "intelligence_index": 9.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.13745,
        "Oracle": 0.2287,
        "Explorer": 0.053200000000000004,
        "Librarian": 1.07745,
        "Designer": 0.1684,
        "Fixer": 0.13605,
        "Builder": 0.08754999999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Mixtral 8x7B Instruct": {
      "id": "3edcb2ed-6981-4f88-a556-563f7f8f00aa",
      "name": "Mixtral 8x7B Instruct",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.387,
        "gpqa": 0.292,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.045,
        "scicode": 0.028,
        "livecodebench": 0.066,
        "coding_index": null,
        "intelligence_index": 7.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.88645,
        "Oracle": 0.18695,
        "Explorer": 0.04095000000000001,
        "Librarian": 0.84155,
        "Designer": 0.13555,
        "Fixer": 0.09310000000000002,
        "Builder": 0.05845
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral 7B Instruct": {
      "id": "217b34ec-5920-4fc1-8886-6a70a324837d",
      "name": "Mistral 7B Instruct",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.245,
        "gpqa": 0.177,
        "ifbench": 0.199,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": 0,
        "hle": 0.043,
        "scicode": 0.024,
        "livecodebench": 0.046,
        "coding_index": null,
        "intelligence_index": 7.4,
        "speed": 164.057,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8420000000000002,
        "Oracle": 0.11514999999999999,
        "Explorer": 0.02665,
        "Librarian": 0.8095500000000001,
        "Designer": 0.10519999999999999,
        "Fixer": 0.06849999999999999,
        "Builder": 0.046799999999999994
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Small 3.1": {
      "id": "24ac5b00-5f03-4c47-8e37-522d1195383e",
      "name": "Mistral Small 3.1",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.659,
        "gpqa": 0.454,
        "ifbench": 0.299,
        "aime": 0.093,
        "math_index": 3.7,
        "terminalbench_hard": 0.076,
        "tau2": 0.251,
        "hle": 0.048,
        "scicode": 0.265,
        "livecodebench": 0.212,
        "coding_index": 13.9,
        "intelligence_index": 14,
        "speed": 108.049,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6596000000000002,
        "Oracle": 0.8689,
        "Explorer": 0.85645,
        "Librarian": 1.5682500000000001,
        "Designer": 0.94205,
        "Fixer": 0.8962500000000001,
        "Builder": 1.5151000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Medium": {
      "id": "1f05af98-1ec6-4506-a0b8-57a8c9b63878",
      "name": "Mistral Medium",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.491,
        "gpqa": 0.349,
        "ifbench": null,
        "aime": 0.037,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.034,
        "scicode": 0.118,
        "livecodebench": 0.099,
        "coding_index": null,
        "intelligence_index": 9,
        "speed": 91.498,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.04345,
        "Oracle": 0.2327,
        "Explorer": 0.050800000000000005,
        "Librarian": 0.98385,
        "Designer": 0.1643,
        "Fixer": 0.11925,
        "Builder": 0.0743
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Medium 3": {
      "id": "59e22326-1bca-4432-a5fa-147fbe8854e7",
      "name": "Mistral Medium 3",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.76,
        "gpqa": 0.578,
        "ifbench": 0.393,
        "aime": 0.44,
        "math_index": 30.3,
        "terminalbench_hard": 0.038,
        "tau2": 0.243,
        "hle": 0.043,
        "scicode": 0.331,
        "livecodebench": 0.4,
        "coding_index": 13.6,
        "intelligence_index": 18.7,
        "speed": 82.205,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.18285,
        "Oracle": 5.00015,
        "Explorer": 0.8341000000000001,
        "Librarian": 2.0605,
        "Designer": 0.9821,
        "Fixer": 0.9405000000000001,
        "Builder": 1.5354500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Devstral Small (Jul '25)": {
      "id": "9eae4ec4-61b8-48bc-9843-3edd506ae933",
      "name": "Devstral Small (Jul '25)",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.622,
        "gpqa": 0.414,
        "ifbench": 0.346,
        "aime": 0.003,
        "math_index": 29.3,
        "terminalbench_hard": 0.061,
        "tau2": 0.284,
        "hle": 0.037,
        "scicode": 0.243,
        "livecodebench": 0.254,
        "coding_index": 12.1,
        "intelligence_index": 15.2,
        "speed": 235.565,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7764,
        "Oracle": 4.66665,
        "Explorer": 0.76445,
        "Librarian": 1.6874,
        "Designer": 0.8401,
        "Fixer": 0.803975,
        "Builder": 1.3379
      },
      "lastCalculated": "2026-02-14"
    },
    "Magistral Medium 1": {
      "id": "660965b2-66d2-49ee-a6b9-79a6ac47d3c0",
      "name": "Magistral Medium 1",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.753,
        "gpqa": 0.679,
        "ifbench": 0.251,
        "aime": 0.7,
        "math_index": 40.3,
        "terminalbench_hard": 0.091,
        "tau2": 0.231,
        "hle": 0.095,
        "scicode": 0.297,
        "livecodebench": 0.527,
        "coding_index": 16,
        "intelligence_index": 18.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.1795,
        "Oracle": 6.604549999999999,
        "Explorer": 0.9742000000000001,
        "Librarian": 2.05965,
        "Designer": 1.1173000000000002,
        "Fixer": 1.09105,
        "Builder": 1.7971500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Devstral Medium": {
      "id": "aba82268-2bb7-4a0f-80be-9b7722e2145b",
      "name": "Devstral Medium",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.708,
        "gpqa": 0.492,
        "ifbench": 0.299,
        "aime": 0.067,
        "math_index": 4.7,
        "terminalbench_hard": 0.091,
        "tau2": 0.199,
        "hle": 0.038,
        "scicode": 0.294,
        "livecodebench": 0.337,
        "coding_index": 15.9,
        "intelligence_index": 18.6,
        "speed": 115.6,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.12935,
        "Oracle": 1.0371,
        "Explorer": 0.9538500000000001,
        "Librarian": 2.0274,
        "Designer": 1.0579,
        "Fixer": 1.026525,
        "Builder": 1.7401000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Devstral Small (May '25)": {
      "id": "cc1fa238-1a76-486d-a997-22309275eadd",
      "name": "Devstral Small (May '25)",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.632,
        "gpqa": 0.434,
        "ifbench": 0.316,
        "aime": 0.067,
        "math_index": null,
        "terminalbench_hard": 0.061,
        "tau2": 0.38,
        "hle": 0.04,
        "scicode": 0.245,
        "livecodebench": 0.258,
        "coding_index": 12.2,
        "intelligence_index": 18,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.0669999999999997,
        "Oracle": 0.2956,
        "Explorer": 0.7946,
        "Librarian": 1.9764000000000002,
        "Designer": 0.8489,
        "Fixer": 0.8145249999999999,
        "Builder": 1.3495000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Mistral Saba": {
      "id": "7a7b52f6-fdef-4dae-9203-58c710ccc81d",
      "name": "Mistral Saba",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.611,
        "gpqa": 0.424,
        "ifbench": null,
        "aime": 0.13,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.041,
        "scicode": 0.241,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 12.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.38645,
        "Oracle": 0.30115,
        "Explorer": 0.06315,
        "Librarian": 1.31395,
        "Designer": 0.20174999999999998,
        "Fixer": 0.13072499999999998,
        "Builder": 0.07295
      },
      "lastCalculated": "2026-02-14"
    },
    "Magistral Small 1": {
      "id": "0fec07d5-a9b2-407a-b5f8-5bf10bd86b59",
      "name": "Magistral Small 1",
      "provider": "Mistral",
      "benchmarks": {
        "mmlu_pro": 0.746,
        "gpqa": 0.641,
        "ifbench": 0.248,
        "aime": 0.713,
        "math_index": 41.3,
        "terminalbench_hard": 0.045,
        "tau2": 0.266,
        "hle": 0.072,
        "scicode": 0.241,
        "livecodebench": 0.514,
        "coding_index": 11.1,
        "intelligence_index": 16.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9839,
        "Oracle": 6.736299999999999,
        "Explorer": 0.7177,
        "Librarian": 1.8649,
        "Designer": 0.8591500000000001,
        "Fixer": 0.8324250000000001,
        "Builder": 1.3009
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek R1 Distill Qwen 32B": {
      "id": "df95f83f-5ebb-466a-9d2d-b95efc8c012c",
      "name": "DeepSeek R1 Distill Qwen 32B",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.739,
        "gpqa": 0.615,
        "ifbench": 0.229,
        "aime": 0.687,
        "math_index": 63,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.055,
        "scicode": 0.376,
        "livecodebench": 0.27,
        "coding_index": null,
        "intelligence_index": 17.2,
        "speed": 50.643,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9882000000000002,
        "Oracle": 9.97155,
        "Explorer": 0.07665000000000001,
        "Librarian": 1.87025,
        "Designer": 0.29300000000000004,
        "Fixer": 0.2275,
        "Builder": 0.1504
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3 (Dec '24)": {
      "id": "43fc5506-c5ed-4dee-9b85-962bf7ae3986",
      "name": "DeepSeek V3 (Dec '24)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.752,
        "gpqa": 0.557,
        "ifbench": 0.348,
        "aime": 0.253,
        "math_index": 26,
        "terminalbench_hard": 0.068,
        "tau2": 0.228,
        "hle": 0.036,
        "scicode": 0.354,
        "livecodebench": 0.359,
        "coding_index": 16.4,
        "intelligence_index": 16.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9391999999999998,
        "Oracle": 4.3061,
        "Explorer": 0.9812,
        "Librarian": 1.8211999999999997,
        "Designer": 1.11045,
        "Fixer": 1.07135,
        "Builder": 1.80455
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek R1 Distill Qwen 14B": {
      "id": "b26ff709-1773-4595-ae44-78e0a5bac29c",
      "name": "DeepSeek R1 Distill Qwen 14B",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.74,
        "gpqa": 0.484,
        "ifbench": 0.221,
        "aime": 0.667,
        "math_index": 55.7,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.044,
        "scicode": 0.239,
        "livecodebench": 0.376,
        "coding_index": null,
        "intelligence_index": 15.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.82095,
        "Oracle": 8.806600000000001,
        "Explorer": 0.07619999999999999,
        "Librarian": 1.7263000000000002,
        "Designer": 0.25849999999999995,
        "Fixer": 0.22002500000000003,
        "Builder": 0.15285
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek-V2.5 (Dec '24)": {
      "id": "bc4579d2-9c46-46c3-ace0-454039bf21bb",
      "name": "DeepSeek-V2.5 (Dec '24)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 12.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.25,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 1.25,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek-Coder-V2": {
      "id": "8f0a75d6-8d00-4c2e-bcd4-8e88a570a93c",
      "name": "DeepSeek-Coder-V2",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 10.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.06,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 1.06,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek R1 Distill Llama 8B": {
      "id": "0e49fe2d-dd3c-4ae5-b56f-a1c89e14b89e",
      "name": "DeepSeek R1 Distill Llama 8B",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.543,
        "gpqa": 0.302,
        "ifbench": 0.176,
        "aime": 0.333,
        "math_index": 41.3,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.042,
        "scicode": 0.119,
        "livecodebench": 0.233,
        "coding_index": null,
        "intelligence_index": 12.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.37825,
        "Oracle": 6.468999999999999,
        "Explorer": 0.056400000000000006,
        "Librarian": 1.32165,
        "Designer": 0.17875000000000002,
        "Fixer": 0.146325,
        "Builder": 0.10110000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek LLM 67B Chat (V1)": {
      "id": "7764d514-694f-444c-8d60-bdc6e24e223f",
      "name": "DeepSeek LLM 67B Chat (V1)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 8.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8400000000000001,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.8400000000000001,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek R1 Distill Qwen 1.5B": {
      "id": "444cdb1e-bab8-42cd-938c-b2d7a93e2da1",
      "name": "DeepSeek R1 Distill Qwen 1.5B",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.269,
        "gpqa": 0.098,
        "ifbench": 0.132,
        "aime": 0.177,
        "math_index": 22,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.033,
        "scicode": 0.066,
        "livecodebench": 0.07,
        "coding_index": null,
        "intelligence_index": 9.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9897500000000001,
        "Oracle": 3.41295,
        "Explorer": 0.028550000000000002,
        "Librarian": 0.97345,
        "Designer": 0.08135,
        "Fixer": 0.06035000000000001,
        "Builder": 0.040350000000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3 0324": {
      "id": "75e1c197-f239-4361-a9d6-66dccfead236",
      "name": "DeepSeek V3 0324",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.819,
        "gpqa": 0.655,
        "ifbench": 0.41,
        "aime": 0.52,
        "math_index": 41,
        "terminalbench_hard": 0.152,
        "tau2": 0.471,
        "hle": 0.052,
        "scicode": 0.358,
        "livecodebench": 0.405,
        "coding_index": 22,
        "intelligence_index": 21.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.54245,
        "Oracle": 6.6659999999999995,
        "Explorer": 1.36305,
        "Librarian": 2.40655,
        "Designer": 1.4328,
        "Fixer": 1.3973250000000002,
        "Builder": 2.3877000000000006
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.1 (Reasoning)": {
      "id": "198b717f-42c8-4ab7-a699-ae9373d669d3",
      "name": "DeepSeek V3.1 (Reasoning)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.851,
        "gpqa": 0.779,
        "ifbench": 0.415,
        "aime": null,
        "math_index": 89.7,
        "terminalbench_hard": 0.25,
        "tau2": 0.374,
        "hle": 0.13,
        "scicode": 0.391,
        "livecodebench": 0.784,
        "coding_index": 29.7,
        "intelligence_index": 27.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.1431,
        "Oracle": 13.936100000000001,
        "Explorer": 1.7701000000000002,
        "Librarian": 3.0055500000000004,
        "Designer": 1.8619,
        "Fixer": 1.8694250000000001,
        "Builder": 3.2288
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.1 (Non-reasoning)": {
      "id": "fb65266f-5a7d-403c-85d5-ccdf0d1ca838",
      "name": "DeepSeek V3.1 (Non-reasoning)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.833,
        "gpqa": 0.735,
        "ifbench": 0.378,
        "aime": null,
        "math_index": 49.7,
        "terminalbench_hard": 0.242,
        "tau2": 0.348,
        "hle": 0.063,
        "scicode": 0.367,
        "livecodebench": 0.577,
        "coding_index": 28.4,
        "intelligence_index": 28,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.1634500000000005,
        "Oracle": 7.90895,
        "Explorer": 1.6902499999999998,
        "Librarian": 3.0164500000000003,
        "Designer": 1.7728,
        "Fixer": 1.7610749999999997,
        "Builder": 3.0606
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek R1 (Jan '25)": {
      "id": "0e34f05c-387e-4968-be15-ccec4a55d8c1",
      "name": "DeepSeek R1 (Jan '25)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.844,
        "gpqa": 0.708,
        "ifbench": 0.39,
        "aime": 0.683,
        "math_index": 68,
        "terminalbench_hard": 0.061,
        "tau2": 0.114,
        "hle": 0.093,
        "scicode": 0.357,
        "livecodebench": 0.617,
        "coding_index": 15.9,
        "intelligence_index": 18.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2181,
        "Oracle": 10.77965,
        "Explorer": 0.9369500000000001,
        "Librarian": 2.0849,
        "Designer": 1.1469,
        "Fixer": 1.115525,
        "Builder": 1.81505
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.1 Terminus (Reasoning)": {
      "id": "0a7dda4d-cc9c-4a90-abc1-abb5772c901b",
      "name": "DeepSeek V3.1 Terminus (Reasoning)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.851,
        "gpqa": 0.792,
        "ifbench": 0.57,
        "aime": null,
        "math_index": 89.7,
        "terminalbench_hard": 0.303,
        "tau2": 0.371,
        "hle": 0.152,
        "scicode": 0.406,
        "livecodebench": 0.798,
        "coding_index": 33.7,
        "intelligence_index": 33.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.78865,
        "Oracle": 13.943700000000002,
        "Explorer": 1.9916500000000004,
        "Librarian": 3.64735,
        "Designer": 2.08285,
        "Fixer": 2.086825,
        "Builder": 3.6399500000000007
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.1 Terminus (Non-reasoning)": {
      "id": "dfb9292d-bc7c-4425-a260-4256217e709f",
      "name": "DeepSeek V3.1 Terminus (Non-reasoning)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.836,
        "gpqa": 0.751,
        "ifbench": 0.412,
        "aime": null,
        "math_index": 53.7,
        "terminalbench_hard": 0.318,
        "tau2": 0.371,
        "hle": 0.084,
        "scicode": 0.321,
        "livecodebench": 0.529,
        "coding_index": 31.9,
        "intelligence_index": 28.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.2144999999999997,
        "Oracle": 8.518300000000002,
        "Explorer": 1.90275,
        "Librarian": 3.0688999999999997,
        "Designer": 1.9577499999999999,
        "Fixer": 1.9403,
        "Builder": 3.4068499999999995
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.2 Exp (Non-reasoning)": {
      "id": "07c35e00-2b12-44c8-91cc-408629cd569e",
      "name": "DeepSeek V3.2 Exp (Non-reasoning)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.836,
        "gpqa": 0.738,
        "ifbench": 0.431,
        "aime": null,
        "math_index": 57.7,
        "terminalbench_hard": 0.25,
        "tau2": 0.339,
        "hle": 0.086,
        "scicode": 0.399,
        "livecodebench": 0.554,
        "coding_index": 30,
        "intelligence_index": 28.3,
        "speed": 37.424,
        "context_length": null,
        "GDPval_AA_ELO": 1195,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 361.70155,
        "Oracle": 9.1119,
        "Explorer": 1.77265,
        "Librarian": 3.0582,
        "Designer": 360.3616,
        "Fixer": 1.8424,
        "Builder": 3.2202499999999996
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek V3.2 Exp (Reasoning)": {
      "id": "af134350-8ba3-4629-b56b-00bd6dcf60c4",
      "name": "DeepSeek V3.2 Exp (Reasoning)",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.85,
        "gpqa": 0.797,
        "ifbench": 0.541,
        "aime": null,
        "math_index": 87.7,
        "terminalbench_hard": 0.311,
        "tau2": 0.339,
        "hle": 0.138,
        "scicode": 0.377,
        "livecodebench": 0.789,
        "coding_index": 33.3,
        "intelligence_index": 32.9,
        "speed": 37.347,
        "context_length": null,
        "GDPval_AA_ELO": 1195,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 362.19195,
        "Oracle": 13.6454,
        "Explorer": 1.96605,
        "Librarian": 3.5469,
        "Designer": 360.55965000000003,
        "Fixer": 2.0639499999999997,
        "Builder": 3.5976
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek-V2-Chat": {
      "id": "2d19c2d1-062d-436e-b2c2-3d3ecad34acc",
      "name": "DeepSeek-V2-Chat",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 9.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.91,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.91,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek Coder V2 Lite Instruct": {
      "id": "c7327e6e-b27f-4b1b-859d-159a34e0ba1c",
      "name": "DeepSeek Coder V2 Lite Instruct",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": 0.429,
        "gpqa": 0.319,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.053,
        "scicode": 0.139,
        "livecodebench": 0.158,
        "coding_index": null,
        "intelligence_index": 8.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9781500000000001,
        "Oracle": 0.20505,
        "Explorer": 0.04555,
        "Librarian": 0.93025,
        "Designer": 0.1494,
        "Fixer": 0.117925,
        "Builder": 0.07705000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "DeepSeek-V2.5": {
      "id": "8a24865b-90d9-4e2b-a2fd-6851c2e9d627",
      "name": "DeepSeek-V2.5",
      "provider": "DeepSeek",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 12.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2300000000000002,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 1.2300000000000002,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Sonar Reasoning Pro": {
      "id": "1edc272c-d799-44d6-909a-bf3c1909a3a0",
      "name": "Sonar Reasoning Pro",
      "provider": "Perplexity",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": 0.79,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 24.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.4600000000000004,
        "Oracle": 0.15800000000000003,
        "Explorer": 0.0,
        "Librarian": 2.4600000000000004,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Sonar": {
      "id": "5ec4a0db-da66-4e46-9682-fceeed755ef8",
      "name": "Sonar",
      "provider": "Perplexity",
      "benchmarks": {
        "mmlu_pro": 0.689,
        "gpqa": 0.471,
        "ifbench": null,
        "aime": 0.487,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.073,
        "scicode": 0.229,
        "livecodebench": 0.295,
        "coding_index": null,
        "intelligence_index": 15.5,
        "speed": 101.368,
        "context_length": 200000,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.74755,
        "Oracle": 0.40545,
        "Explorer": 0.10118754037893193,
        "Librarian": 1.7229792339648866,
        "Designer": 0.23794584679297728,
        "Fixer": 0.189525,
        "Builder": 0.1258
      },
      "lastCalculated": "2026-02-14"
    },
    "Sonar Reasoning": {
      "id": "04751bd4-0c5d-416b-a5f2-83727c5bfcda",
      "name": "Sonar Reasoning",
      "provider": "Perplexity",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.623,
        "ifbench": null,
        "aime": 0.77,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 17.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9146,
        "Oracle": 0.4655,
        "Explorer": 0.0,
        "Librarian": 1.79,
        "Designer": 0.15575,
        "Fixer": 0.09344999999999999,
        "Builder": 0.0623
      },
      "lastCalculated": "2026-02-14"
    },
    "Sonar Pro": {
      "id": "3435db18-9227-45a5-8e79-9546b14b5aaa",
      "name": "Sonar Pro",
      "provider": "Perplexity",
      "benchmarks": {
        "mmlu_pro": 0.755,
        "gpqa": 0.578,
        "ifbench": null,
        "aime": 0.29,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.079,
        "scicode": 0.226,
        "livecodebench": 0.275,
        "coding_index": null,
        "intelligence_index": 15.2,
        "speed": 119.304,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.74885,
        "Oracle": 0.42645,
        "Explorer": 0.07945,
        "Librarian": 1.65695,
        "Designer": 0.26565,
        "Fixer": 0.20909999999999998,
        "Builder": 0.1368
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok Beta": {
      "id": "a04f5b78-f397-4fd8-a2b1-00dcab50324c",
      "name": "Grok Beta",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.703,
        "gpqa": 0.471,
        "ifbench": null,
        "aime": 0.103,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.047,
        "scicode": 0.295,
        "livecodebench": 0.241,
        "coding_index": null,
        "intelligence_index": 13.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5296500000000002,
        "Oracle": 0.32875000000000004,
        "Explorer": 0.07265,
        "Librarian": 1.4495500000000001,
        "Designer": 0.2279,
        "Fixer": 0.18447499999999997,
        "Builder": 0.11839999999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 3": {
      "id": "2443ac9e-a3db-423d-accb-8963f6fb0a53",
      "name": "Grok 3",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.799,
        "gpqa": 0.693,
        "ifbench": 0.469,
        "aime": 0.33,
        "math_index": 58,
        "terminalbench_hard": 0.114,
        "tau2": 0.488,
        "hle": 0.051,
        "scicode": 0.368,
        "livecodebench": 0.425,
        "coding_index": 19.8,
        "intelligence_index": 25,
        "speed": 66.369,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.8775999999999997,
        "Oracle": 9.194949999999999,
        "Explorer": 1.24005,
        "Librarian": 2.7308499999999998,
        "Designer": 1.3351000000000002,
        "Fixer": 1.2938500000000002,
        "Builder": 2.1764500000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 2 (Dec '24)": {
      "id": "291a510a-dcc0-40df-8a80-b3aa31900a6c",
      "name": "Grok 2 (Dec '24)",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.709,
        "gpqa": 0.51,
        "ifbench": null,
        "aime": 0.133,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.038,
        "scicode": 0.285,
        "livecodebench": 0.267,
        "coding_index": null,
        "intelligence_index": 13.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5983500000000002,
        "Oracle": 0.35440000000000005,
        "Explorer": 0.0728,
        "Librarian": 1.5077500000000001,
        "Designer": 0.23765,
        "Fixer": 0.194575,
        "Builder": 0.1265
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 4 Fast (Non-reasoning)": {
      "id": "2dbb6dc7-8c40-4b6d-af9c-cf805f83b79a",
      "name": "Grok 4 Fast (Non-reasoning)",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.73,
        "gpqa": 0.606,
        "ifbench": 0.377,
        "aime": null,
        "math_index": 41.3,
        "terminalbench_hard": 0.121,
        "tau2": 0.637,
        "hle": 0.05,
        "scicode": 0.329,
        "livecodebench": 0.401,
        "coding_index": 19,
        "intelligence_index": 22.6,
        "speed": 135.391,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.6109500000000003,
        "Oracle": 6.5735,
        "Explorer": 1.2331500000000002,
        "Librarian": 2.4859,
        "Designer": 1.2537,
        "Fixer": 1.22915,
        "Builder": 2.0761000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 4 Fast (Reasoning)": {
      "id": "573bbd93-114c-4b71-9ede-a73a7d4bdf84",
      "name": "Grok 4 Fast (Reasoning)",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": 0.85,
        "gpqa": 0.847,
        "ifbench": 0.505,
        "aime": null,
        "math_index": 89.7,
        "terminalbench_hard": 0.189,
        "tau2": 0.658,
        "hle": 0.17,
        "scicode": 0.442,
        "livecodebench": 0.832,
        "coding_index": 27.4,
        "intelligence_index": 34.9,
        "speed": 176.126,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.92845,
        "Oracle": 13.972000000000001,
        "Explorer": 1.7036000000000002,
        "Librarian": 3.7848,
        "Designer": 1.77675,
        "Fixer": 1.7785000000000002,
        "Builder": 3.0172500000000007
      },
      "lastCalculated": "2026-02-14"
    },
    "Grok 3 Reasoning Beta": {
      "id": "ec3b22e6-48ac-416a-b4ae-55565a4f3046",
      "name": "Grok 3 Reasoning Beta",
      "provider": "xAI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 21.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.16,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 2.16,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "OpenChat 3.5 (1210)": {
      "id": "ec60e57e-76d3-42e3-a0e3-80662225a639",
      "name": "OpenChat 3.5 (1210)",
      "provider": "OpenChat",
      "benchmarks": {
        "mmlu_pro": 0.31,
        "gpqa": 0.23,
        "ifbench": null,
        "aime": 0,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.048,
        "scicode": null,
        "livecodebench": 0.115,
        "coding_index": null,
        "intelligence_index": 8.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9225000000000001,
        "Oracle": 0.14840000000000003,
        "Explorer": 0.0334,
        "Librarian": 0.8909,
        "Designer": 0.10880000000000001,
        "Fixer": 0.08275,
        "Builder": 0.05575000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova Pro": {
      "id": "546ec53f-273c-4af7-b13f-b88c41f45905",
      "name": "Nova Pro",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.691,
        "gpqa": 0.499,
        "ifbench": 0.381,
        "aime": 0.107,
        "math_index": 7,
        "terminalbench_hard": 0.061,
        "tau2": 0.14,
        "hle": 0.034,
        "scicode": 0.208,
        "livecodebench": 0.233,
        "coding_index": 11,
        "intelligence_index": 13.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6246,
        "Oracle": 1.3917,
        "Explorer": 0.6802,
        "Librarian": 1.5159500000000001,
        "Designer": 0.8199000000000001,
        "Fixer": 0.76275,
        "Builder": 1.2384500000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Nova Lite": {
      "id": "5c3dd927-48a3-4f3c-8045-9b135f62dfbb",
      "name": "Nova Lite",
      "provider": "Amazon",
      "benchmarks": {
        "mmlu_pro": 0.59,
        "gpqa": 0.433,
        "ifbench": 0.341,
        "aime": 0.107,
        "math_index": 7,
        "terminalbench_hard": 0.008,
        "tau2": 0.175,
        "hle": 0.046,
        "scicode": 0.139,
        "livecodebench": 0.167,
        "coding_index": 5.1,
        "intelligence_index": 12.4,
        "speed": 213.667,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.4837500000000003,
        "Oracle": 1.3492,
        "Explorer": 0.36324999999999996,
        "Librarian": 1.3939000000000004,
        "Designer": 0.49045,
        "Fixer": 0.4297,
        "Builder": 0.6249
      },
      "lastCalculated": "2026-02-14"
    },
    "Phi-3 Mini Instruct 3.8B": {
      "id": "ded8d96e-835f-4359-947a-a4c3bb78e983",
      "name": "Phi-3 Mini Instruct 3.8B",
      "provider": "Microsoft Azure",
      "benchmarks": {
        "mmlu_pro": 0.435,
        "gpqa": 0.319,
        "ifbench": 0.239,
        "aime": 0.04,
        "math_index": 0.3,
        "terminalbench_hard": 0,
        "tau2": 0,
        "hle": 0.044,
        "scicode": 0.09,
        "livecodebench": 0.116,
        "coding_index": 3,
        "intelligence_index": 10.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.1749,
        "Oracle": 0.2582,
        "Explorer": 0.19570000000000004,
        "Librarian": 1.11235,
        "Designer": 0.32330000000000003,
        "Fixer": 0.27295,
        "Builder": 0.383
      },
      "lastCalculated": "2026-02-14"
    },
    "LFM 40B": {
      "id": "1299b9a8-af50-4742-a58b-24ff7eb48f9f",
      "name": "LFM 40B",
      "provider": "Liquid AI",
      "benchmarks": {
        "mmlu_pro": 0.425,
        "gpqa": 0.327,
        "ifbench": null,
        "aime": 0.023,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.049,
        "scicode": 0.071,
        "livecodebench": 0.096,
        "coding_index": null,
        "intelligence_index": 8.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.00915,
        "Oracle": 0.21305000000000002,
        "Explorer": 0.044950000000000004,
        "Librarian": 0.9584500000000001,
        "Designer": 0.1504,
        "Fixer": 0.10772500000000002,
        "Builder": 0.06835000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "LFM2 1.2B": {
      "id": "0faadeeb-320c-45cf-9c76-5f8768f342e6",
      "name": "LFM2 1.2B",
      "provider": "Liquid AI",
      "benchmarks": {
        "mmlu_pro": 0.257,
        "gpqa": 0.228,
        "ifbench": 0.22,
        "aime": null,
        "math_index": 3.3,
        "terminalbench_hard": 0,
        "tau2": 0.126,
        "hle": 0.057,
        "scicode": 0.025,
        "livecodebench": 0.02,
        "coding_index": 0.8,
        "intelligence_index": 6.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.7697500000000002,
        "Oracle": 0.6375500000000001,
        "Explorer": 0.10005,
        "Librarian": 0.7302500000000001,
        "Designer": 0.16325,
        "Fixer": 0.11767500000000002,
        "Builder": 0.12965000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Solar Mini": {
      "id": "d97713f2-afa6-4f8d-b2f3-ac89a24c4d6c",
      "name": "Solar Mini",
      "provider": "Upstage",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": 0.202,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 8,
        "speed": 81.887,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8202,
        "Oracle": 0.0,
        "Explorer": 0.0505,
        "Librarian": 0.8202,
        "Designer": 0.0,
        "Fixer": 0.005050000000000001,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Solar Pro 2 (Preview) (Reasoning)": {
      "id": "8e78cf7a-5b76-4beb-beba-b99c6233b208",
      "name": "Solar Pro 2 (Preview) (Reasoning)",
      "provider": "Upstage",
      "benchmarks": {
        "mmlu_pro": 0.768,
        "gpqa": 0.578,
        "ifbench": null,
        "aime": 0.663,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.057,
        "scicode": 0.164,
        "livecodebench": 0.462,
        "coding_index": null,
        "intelligence_index": 18.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.1108000000000002,
        "Oracle": 0.50125,
        "Explorer": 0.07965000000000001,
        "Librarian": 2.0123,
        "Designer": 0.26539999999999997,
        "Fixer": 0.23689999999999997,
        "Builder": 0.16549999999999998
      },
      "lastCalculated": "2026-02-14"
    },
    "Solar Pro 2 (Preview) (Non-reasoning)": {
      "id": "432d6c36-8825-47f3-b4eb-58529cea346b",
      "name": "Solar Pro 2 (Preview) (Non-reasoning)",
      "provider": "Upstage",
      "benchmarks": {
        "mmlu_pro": 0.725,
        "gpqa": 0.544,
        "ifbench": null,
        "aime": 0.297,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.038,
        "scicode": 0.272,
        "livecodebench": 0.385,
        "coding_index": null,
        "intelligence_index": 16,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8175500000000002,
        "Oracle": 0.40580000000000005,
        "Explorer": 0.0744,
        "Librarian": 1.72015,
        "Designer": 0.24855000000000002,
        "Fixer": 0.21864999999999998,
        "Builder": 0.1484
      },
      "lastCalculated": "2026-02-14"
    },
    "DBRX Instruct": {
      "id": "1cb96708-f6c1-4668-9804-5db6ecac01ed",
      "name": "DBRX Instruct",
      "provider": "Databricks",
      "benchmarks": {
        "mmlu_pro": 0.397,
        "gpqa": 0.331,
        "ifbench": null,
        "aime": 0.03,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.066,
        "scicode": 0.118,
        "livecodebench": 0.093,
        "coding_index": null,
        "intelligence_index": 8.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9557500000000001,
        "Oracle": 0.21450000000000002,
        "Explorer": 0.043000000000000003,
        "Librarian": 0.9093500000000001,
        "Designer": 0.1489,
        "Fixer": 0.10625,
        "Builder": 0.0669
      },
      "lastCalculated": "2026-02-14"
    },
    "MiniMax M1 80k": {
      "id": "9ca246a7-cf13-42c9-9182-5b5ad6b79026",
      "name": "MiniMax M1 80k",
      "provider": "MiniMax",
      "benchmarks": {
        "mmlu_pro": 0.816,
        "gpqa": 0.697,
        "ifbench": 0.418,
        "aime": 0.847,
        "math_index": 61,
        "terminalbench_hard": 0.03,
        "tau2": 0.342,
        "hle": 0.082,
        "scicode": 0.374,
        "livecodebench": 0.711,
        "coding_index": 14.5,
        "intelligence_index": 24.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 36.81
      },
      "roleScores": {
        "Orchestrator": 2.7887,
        "Oracle": 9.753599999999999,
        "Explorer": 0.9082000000000001,
        "Librarian": 2.6529999999999996,
        "Designer": 1.07165,
        "Fixer": 6.5811,
        "Builder": 12.73105
      },
      "lastCalculated": "2026-02-14"
    },
    "MiniMax-M2": {
      "id": "f74ea286-cd29-4eb4-af14-1389b19c21e5",
      "name": "MiniMax-M2",
      "provider": "MiniMax",
      "benchmarks": {
        "mmlu_pro": 0.82,
        "gpqa": 0.777,
        "ifbench": 0.723,
        "aime": null,
        "math_index": 78.3,
        "terminalbench_hard": 0.258,
        "tau2": 0.868,
        "hle": 0.125,
        "scicode": 0.361,
        "livecodebench": 0.826,
        "coding_index": 29.2,
        "intelligence_index": 36,
        "speed": 78.483,
        "context_length": 204800,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 36.81
      },
      "roleScores": {
        "Orchestrator": 4.07365,
        "Oracle": 12.22175,
        "Explorer": 1.8977748413480264,
        "Librarian": 3.968474735580044,
        "Designer": 1.8718249471160087,
        "Fixer": 7.396625000000001,
        "Builder": 14.241750000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "MiniMax M1 40k": {
      "id": "385376b1-9815-47dd-83cc-85aac34f247d",
      "name": "MiniMax M1 40k",
      "provider": "MiniMax",
      "benchmarks": {
        "mmlu_pro": 0.808,
        "gpqa": 0.682,
        "ifbench": 0.412,
        "aime": 0.813,
        "math_index": 13.7,
        "terminalbench_hard": 0.023,
        "tau2": 0.316,
        "hle": 0.075,
        "scicode": 0.378,
        "livecodebench": 0.657,
        "coding_index": 14.1,
        "intelligence_index": 20.9,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 36.81
      },
      "roleScores": {
        "Orchestrator": 2.441,
        "Oracle": 2.64315,
        "Explorer": 0.87775,
        "Librarian": 2.3064999999999998,
        "Designer": 1.0454,
        "Fixer": 6.548400000000001,
        "Builder": 12.68075
      },
      "lastCalculated": "2026-02-14"
    },
    "Kimi K2 Thinking": {
      "id": "bddebfd3-0a8d-47f5-b722-bc4c2ca5a5dc",
      "name": "Kimi K2 Thinking",
      "provider": "Kimi",
      "benchmarks": {
        "mmlu_pro": 0.848,
        "gpqa": 0.838,
        "ifbench": 0.681,
        "aime": null,
        "math_index": 94.7,
        "terminalbench_hard": 0.311,
        "tau2": 0.93,
        "hle": 0.223,
        "scicode": 0.424,
        "livecodebench": 0.853,
        "coding_index": 34.8,
        "intelligence_index": 40.7,
        "speed": 87.657,
        "context_length": null,
        "GDPval_AA_ELO": 1017,
        "SWE_bench_Verified": 59.8,
        "SWE_bench_Pro": 27.67
      },
      "roleScores": {
        "Orchestrator": 309.65995,
        "Oracle": 14.71995,
        "Explorer": 2.19285,
        "Librarian": 4.4252,
        "Designer": 307.26709999999997,
        "Fixer": 15.29795,
        "Builder": 27.019199999999998
      },
      "lastCalculated": "2026-02-14"
    },
    "Kimi K2": {
      "id": "441734a9-8901-4850-9bae-b474c370291f",
      "name": "Kimi K2",
      "provider": "Kimi",
      "benchmarks": {
        "mmlu_pro": 0.824,
        "gpqa": 0.766,
        "ifbench": 0.415,
        "aime": 0.693,
        "math_index": 57,
        "terminalbench_hard": 0.159,
        "tau2": 0.611,
        "hle": 0.07,
        "scicode": 0.345,
        "livecodebench": 0.556,
        "coding_index": 22.1,
        "intelligence_index": 26.2,
        "speed": 38.58,
        "context_length": null,
        "GDPval_AA_ELO": 1017,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 27.67
      },
      "roleScores": {
        "Orchestrator": 308.12015,
        "Oracle": 9.157499999999999,
        "Explorer": 1.4072500000000001,
        "Librarian": 2.8672000000000004,
        "Designer": 306.5686,
        "Fixer": 5.59675,
        "Builder": 10.732949999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Kimi K2 0905": {
      "id": "66445f84-b2e3-4202-afdc-92ba0f0e5f36",
      "name": "Kimi K2 0905",
      "provider": "Kimi",
      "benchmarks": {
        "mmlu_pro": 0.819,
        "gpqa": 0.767,
        "ifbench": 0.417,
        "aime": null,
        "math_index": 57.3,
        "terminalbench_hard": 0.235,
        "tau2": 0.734,
        "hle": 0.063,
        "scicode": 0.307,
        "livecodebench": 0.61,
        "coding_index": 25.9,
        "intelligence_index": 30.8,
        "speed": 61.826,
        "context_length": null,
        "GDPval_AA_ELO": 1017,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": 27.67
      },
      "roleScores": {
        "Orchestrator": 308.59219999999993,
        "Oracle": 9.063549999999998,
        "Explorer": 1.6575499999999999,
        "Librarian": 3.33685,
        "Designer": 306.7576,
        "Fixer": 5.804325,
        "Builder": 11.121
      },
      "lastCalculated": "2026-02-14"
    },
    "Llama 3.1 Tulu3 405B": {
      "id": "f73f4711-9c61-40a7-a258-b71c14727f53",
      "name": "Llama 3.1 Tulu3 405B",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": 0.716,
        "gpqa": 0.516,
        "ifbench": null,
        "aime": 0.133,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.035,
        "scicode": 0.302,
        "livecodebench": 0.291,
        "coding_index": null,
        "intelligence_index": 14.1,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6206,
        "Oracle": 0.35795,
        "Explorer": 0.07335,
        "Librarian": 1.5279,
        "Designer": 0.2399,
        "Fixer": 0.2002,
        "Builder": 0.13105
      },
      "lastCalculated": "2026-02-14"
    },
    "OLMo 2 7B": {
      "id": "f818a7bb-6f23-4b24-8d52-6b9c1a5ca628",
      "name": "OLMo 2 7B",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": 0.282,
        "gpqa": 0.288,
        "ifbench": 0.244,
        "aime": null,
        "math_index": 0.7,
        "terminalbench_hard": 0,
        "tau2": 0,
        "hle": 0.055,
        "scicode": 0.037,
        "livecodebench": 0.041,
        "coding_index": 1.2,
        "intelligence_index": 9.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0665,
        "Oracle": 0.27995,
        "Explorer": 0.09095,
        "Librarian": 1.0132,
        "Designer": 0.2042,
        "Fixer": 0.150675,
        "Builder": 0.18124999999999997
      },
      "lastCalculated": "2026-02-14"
    },
    "Olmo 3 32B Think": {
      "id": "c8a3fa87-735e-49a9-afb1-270c5e9f53f7",
      "name": "Olmo 3 32B Think",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": 0.759,
        "gpqa": 0.61,
        "ifbench": 0.491,
        "aime": null,
        "math_index": 73.7,
        "terminalbench_hard": 0.015,
        "tau2": 0,
        "hle": 0.059,
        "scicode": 0.286,
        "livecodebench": 0.672,
        "coding_index": 10.5,
        "intelligence_index": 12,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5095000000000003,
        "Oracle": 11.43885,
        "Explorer": 0.60985,
        "Librarian": 1.3806500000000002,
        "Designer": 0.84635,
        "Fixer": 0.8264,
        "Builder": 1.2743
      },
      "lastCalculated": "2026-02-14"
    },
    "OLMo 2 32B": {
      "id": "54442579-2a4d-40cc-b264-bc4ff29e311a",
      "name": "OLMo 2 32B",
      "provider": "Allen Institute for AI",
      "benchmarks": {
        "mmlu_pro": 0.511,
        "gpqa": 0.328,
        "ifbench": 0.381,
        "aime": null,
        "math_index": 3.3,
        "terminalbench_hard": 0,
        "tau2": 0,
        "hle": 0.037,
        "scicode": 0.08,
        "livecodebench": 0.068,
        "coding_index": 2.7,
        "intelligence_index": 10.6,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2594,
        "Oracle": 0.71195,
        "Explorer": 0.18795,
        "Librarian": 1.18585,
        "Designer": 0.33545,
        "Fixer": 0.26655000000000006,
        "Builder": 0.35760000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Granite 3.3 8B (Non-reasoning)": {
      "id": "2cff73da-4855-403c-afc9-5540feadcc15",
      "name": "Granite 3.3 8B (Non-reasoning)",
      "provider": "IBM",
      "benchmarks": {
        "mmlu_pro": 0.468,
        "gpqa": 0.338,
        "ifbench": 0.224,
        "aime": 0.047,
        "math_index": 6.7,
        "terminalbench_hard": 0,
        "tau2": 0.105,
        "hle": 0.042,
        "scicode": 0.101,
        "livecodebench": 0.127,
        "coding_index": 3.4,
        "intelligence_index": 10.8,
        "speed": 542.607,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2619,
        "Oracle": 1.2322999999999997,
        "Explorer": 0.24515000000000003,
        "Librarian": 1.1957,
        "Designer": 0.35130000000000006,
        "Fixer": 0.30290000000000006,
        "Builder": 0.42745
      },
      "lastCalculated": "2026-02-14"
    },
    "Reka Flash (Sep '24)": {
      "id": "a971b0c0-4c0f-484a-b018-e36b5be3409e",
      "name": "Reka Flash (Sep '24)",
      "provider": "Reka AI",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 12,
        "speed": 69.36,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2000000000000002,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 1.2000000000000002,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Hermes 3 - Llama-3.1 70B": {
      "id": "1dcea4f7-7e8b-49f8-abe2-5860ff9f349e",
      "name": "Hermes 3 - Llama-3.1 70B",
      "provider": "Nous Research",
      "benchmarks": {
        "mmlu_pro": 0.571,
        "gpqa": 0.401,
        "ifbench": null,
        "aime": 0.023,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.041,
        "scicode": 0.231,
        "livecodebench": 0.188,
        "coding_index": null,
        "intelligence_index": 10.6,
        "speed": 35.407,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.22585,
        "Oracle": 0.26425,
        "Explorer": 0.05915,
        "Librarian": 1.15795,
        "Designer": 0.19,
        "Fixer": 0.151225,
        "Builder": 0.09684999999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.5 (Reasoning)": {
      "id": "1cf439b8-0cfd-47b2-9de2-9a2157e6762b",
      "name": "GLM-4.5 (Reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.835,
        "gpqa": 0.782,
        "ifbench": 0.441,
        "aime": 0.873,
        "math_index": 73.7,
        "terminalbench_hard": 0.22,
        "tau2": 0.43,
        "hle": 0.122,
        "scicode": 0.348,
        "livecodebench": 0.738,
        "coding_index": 26.3,
        "intelligence_index": 26.2,
        "speed": 46.075,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.0108,
        "Oracle": 11.7102,
        "Explorer": 1.6001000000000003,
        "Librarian": 2.86895,
        "Designer": 1.69205,
        "Fixer": 1.6900000000000002,
        "Builder": 2.8827000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.6 (Reasoning)": {
      "id": "6a5d56e1-bb68-4205-8d9b-26b97888bc84",
      "name": "GLM-4.6 (Reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.829,
        "gpqa": 0.78,
        "ifbench": 0.434,
        "aime": null,
        "math_index": 86,
        "terminalbench_hard": 0.25,
        "tau2": 0.705,
        "hle": 0.133,
        "scicode": 0.384,
        "livecodebench": 0.695,
        "coding_index": 29.5,
        "intelligence_index": 32.5,
        "speed": 76.834,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.66595,
        "Oracle": 13.379550000000002,
        "Explorer": 1.8408,
        "Librarian": 3.52815,
        "Designer": 1.85105,
        "Fixer": 1.853075,
        "Builder": 3.1954000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.5V (Reasoning)": {
      "id": "3068def4-7270-4c06-a320-6f6a5623d564",
      "name": "GLM-4.5V (Reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.788,
        "gpqa": 0.684,
        "ifbench": 0.342,
        "aime": null,
        "math_index": 73,
        "terminalbench_hard": 0.053,
        "tau2": 0.225,
        "hle": 0.059,
        "scicode": 0.221,
        "livecodebench": 0.604,
        "coding_index": 10.9,
        "intelligence_index": 14.9,
        "speed": 52.989,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8188,
        "Oracle": 11.37375,
        "Explorer": 0.7042,
        "Librarian": 1.6826,
        "Designer": 0.8743000000000001,
        "Fixer": 0.85055,
        "Builder": 1.3055
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.6 (Non-reasoning)": {
      "id": "946e7aab-db1c-4c3f-b0b3-7720d0cff187",
      "name": "GLM-4.6 (Non-reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.784,
        "gpqa": 0.632,
        "ifbench": 0.367,
        "aime": null,
        "math_index": 44.3,
        "terminalbench_hard": 0.288,
        "tau2": 0.769,
        "hle": 0.052,
        "scicode": 0.331,
        "livecodebench": 0.561,
        "coding_index": 30.2,
        "intelligence_index": 30.1,
        "speed": 57.501,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.3859500000000007,
        "Oracle": 7.042,
        "Explorer": 1.89845,
        "Librarian": 3.2568000000000006,
        "Designer": 1.8275000000000001,
        "Fixer": 1.842,
        "Builder": 3.2249000000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "GLM-4.5V (Non-reasoning)": {
      "id": "0081ab31-d10a-44a0-a10d-eee5533fec65",
      "name": "GLM-4.5V (Non-reasoning)",
      "provider": "Z AI",
      "benchmarks": {
        "mmlu_pro": 0.751,
        "gpqa": 0.573,
        "ifbench": 0.286,
        "aime": null,
        "math_index": 15.3,
        "terminalbench_hard": 0.068,
        "tau2": 0.196,
        "hle": 0.036,
        "scicode": 0.188,
        "livecodebench": 0.352,
        "coding_index": 10.8,
        "intelligence_index": 12.5,
        "speed": 51.733,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.53975,
        "Oracle": 2.6584,
        "Explorer": 0.6931,
        "Librarian": 1.42165,
        "Designer": 0.8281000000000001,
        "Fixer": 0.7845500000000001,
        "Builder": 1.2419499999999999
      },
      "lastCalculated": "2026-02-14"
    },
    "Command-R+ (Apr '24)": {
      "id": "76361085-f5dc-49ec-b069-fe56ca885933",
      "name": "Command-R+ (Apr '24)",
      "provider": "Cohere",
      "benchmarks": {
        "mmlu_pro": 0.432,
        "gpqa": 0.323,
        "ifbench": null,
        "aime": 0.007,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.045,
        "scicode": 0.118,
        "livecodebench": 0.122,
        "coding_index": null,
        "intelligence_index": 8.3,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.9594,
        "Oracle": 0.20835,
        "Explorer": 0.045450000000000004,
        "Librarian": 0.9083000000000001,
        "Designer": 0.15005000000000002,
        "Fixer": 0.1129,
        "Builder": 0.07220000000000001
      },
      "lastCalculated": "2026-02-14"
    },
    "Command-R (Mar '24)": {
      "id": "abe9f0c7-f4f6-430d-ba42-f45afdd4841b",
      "name": "Command-R (Mar '24)",
      "provider": "Cohere",
      "benchmarks": {
        "mmlu_pro": 0.338,
        "gpqa": 0.284,
        "ifbench": null,
        "aime": 0.007,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.048,
        "scicode": 0.062,
        "livecodebench": 0.048,
        "coding_index": null,
        "intelligence_index": 7.4,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8475000000000001,
        "Oracle": 0.1796,
        "Explorer": 0.0362,
        "Librarian": 0.8051000000000001,
        "Designer": 0.1265,
        "Fixer": 0.08514999999999999,
        "Builder": 0.052500000000000005
      },
      "lastCalculated": "2026-02-14"
    },
    "Apriel-v1.5-15B-Thinker": {
      "id": "ac1031bc-c53e-4af7-9c6e-2005e0ff44fa",
      "name": "Apriel-v1.5-15B-Thinker",
      "provider": "ServiceNow",
      "benchmarks": {
        "mmlu_pro": 0.773,
        "gpqa": 0.713,
        "ifbench": 0.617,
        "aime": null,
        "math_index": 87.5,
        "terminalbench_hard": 0.106,
        "tau2": 0.684,
        "hle": 0.12,
        "scicode": 0.348,
        "livecodebench": 0.728,
        "coding_index": 18.7,
        "intelligence_index": 28.3,
        "speed": 147.325,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 3.2495000000000003,
        "Oracle": 13.5648,
        "Explorer": 1.2317,
        "Librarian": 3.11205,
        "Designer": 1.3029000000000002,
        "Fixer": 1.2956999999999999,
        "Builder": 2.12
      },
      "lastCalculated": "2026-02-14"
    },
    "Jamba 1.5 Large": {
      "id": "b4ddb4c8-1400-44ab-8c2b-e2472088e7ff",
      "name": "Jamba 1.5 Large",
      "provider": "AI21 Labs",
      "benchmarks": {
        "mmlu_pro": 0.572,
        "gpqa": 0.427,
        "ifbench": null,
        "aime": 0.047,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.04,
        "scicode": 0.163,
        "livecodebench": 0.143,
        "coding_index": null,
        "intelligence_index": 10.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.2412,
        "Oracle": 0.2821,
        "Explorer": 0.0592,
        "Librarian": 1.1678,
        "Designer": 0.19655,
        "Fixer": 0.146775,
        "Builder": 0.09275
      },
      "lastCalculated": "2026-02-14"
    },
    "Jamba 1.6 Mini": {
      "id": "e8ffd75b-766f-4551-8c52-6e54706220eb",
      "name": "Jamba 1.6 Mini",
      "provider": "AI21 Labs",
      "benchmarks": {
        "mmlu_pro": 0.367,
        "gpqa": 0.3,
        "ifbench": null,
        "aime": 0.033,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.046,
        "scicode": 0.101,
        "livecodebench": 0.071,
        "coding_index": null,
        "intelligence_index": 7.9,
        "speed": 126.867,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.90505,
        "Oracle": 0.1956,
        "Explorer": 0.03900000000000001,
        "Librarian": 0.85885,
        "Designer": 0.13465,
        "Fixer": 0.094875,
        "Builder": 0.059
      },
      "lastCalculated": "2026-02-14"
    },
    "Jamba 1.5 Mini": {
      "id": "540ebc58-a2d8-4dc9-ba6b-973efa52fab1",
      "name": "Jamba 1.5 Mini",
      "provider": "AI21 Labs",
      "benchmarks": {
        "mmlu_pro": 0.371,
        "gpqa": 0.302,
        "ifbench": null,
        "aime": 0.01,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.051,
        "scicode": 0.08,
        "livecodebench": 0.062,
        "coding_index": null,
        "intelligence_index": 8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.91605,
        "Oracle": 0.19265,
        "Explorer": 0.039650000000000005,
        "Librarian": 0.87095,
        "Designer": 0.13624999999999998,
        "Fixer": 0.0937,
        "Builder": 0.058050000000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "Jamba 1.6 Large": {
      "id": "92b19c88-fa87-4595-957e-fe9aa5fa5ad4",
      "name": "Jamba 1.6 Large",
      "provider": "AI21 Labs",
      "benchmarks": {
        "mmlu_pro": 0.565,
        "gpqa": 0.387,
        "ifbench": null,
        "aime": 0.047,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.04,
        "scicode": 0.184,
        "livecodebench": 0.172,
        "coding_index": null,
        "intelligence_index": 10.6,
        "speed": 46.151,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.22215,
        "Oracle": 0.26139999999999997,
        "Explorer": 0.058499999999999996,
        "Librarian": 1.15675,
        "Designer": 0.1855,
        "Fixer": 0.14494999999999997,
        "Builder": 0.09275
      },
      "lastCalculated": "2026-02-14"
    },
    "Arctic Instruct": {
      "id": "b3735511-c6ff-4928-8d72-2181444a4eb3",
      "name": "Arctic Instruct",
      "provider": "Snowflake",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 8.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8800000000000001,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.8800000000000001,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen2.5 Max": {
      "id": "b9dc72c6-7bea-4936-a55a-4b0c835fc755",
      "name": "Qwen2.5 Max",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.762,
        "gpqa": 0.587,
        "ifbench": null,
        "aime": 0.233,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.045,
        "scicode": 0.337,
        "livecodebench": 0.359,
        "coding_index": null,
        "intelligence_index": 16.3,
        "speed": 40.615,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.8617000000000001,
        "Oracle": 0.4185499999999999,
        "Explorer": 0.07845,
        "Librarian": 1.7578,
        "Designer": 0.26555,
        "Fixer": 0.22652499999999995,
        "Builder": 0.15065
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen2.5 Instruct 72B": {
      "id": "b4f7d7a4-869a-4ee7-b17a-4046cd1e79fd",
      "name": "Qwen2.5 Instruct 72B",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.72,
        "gpqa": 0.491,
        "ifbench": 0.369,
        "aime": 0.16,
        "math_index": 14,
        "terminalbench_hard": 0.045,
        "tau2": 0.345,
        "hle": 0.042,
        "scicode": 0.267,
        "livecodebench": 0.276,
        "coding_index": 11.9,
        "intelligence_index": 15.6,
        "speed": 45.597,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.85605,
        "Oracle": 2.4516,
        "Explorer": 0.7733500000000001,
        "Librarian": 1.752,
        "Designer": 0.8668500000000001,
        "Fixer": 0.8203,
        "Builder": 1.3349500000000003
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen2.5 Coder Instruct 32B": {
      "id": "04586102-6a28-48f8-a82e-85775d7ed779",
      "name": "Qwen2.5 Coder Instruct 32B",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.635,
        "gpqa": 0.417,
        "ifbench": null,
        "aime": 0.12,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.038,
        "scicode": 0.271,
        "livecodebench": 0.295,
        "coding_index": null,
        "intelligence_index": 12.9,
        "speed": 30.41,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.46865,
        "Oracle": 0.2979,
        "Explorer": 0.0654,
        "Librarian": 1.39665,
        "Designer": 0.2033,
        "Fixer": 0.177075,
        "Builder": 0.1177
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen2.5 Turbo": {
      "id": "352f834f-a03c-4117-8a29-c3ccd8a568ce",
      "name": "Qwen2.5 Turbo",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.633,
        "gpqa": 0.41,
        "ifbench": null,
        "aime": 0.12,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.042,
        "scicode": 0.153,
        "livecodebench": 0.163,
        "coding_index": null,
        "intelligence_index": 12,
        "speed": 72.511,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.3769500000000001,
        "Oracle": 0.2944,
        "Explorer": 0.06540000000000001,
        "Librarian": 1.3075500000000002,
        "Designer": 0.20165,
        "Fixer": 0.153075,
        "Builder": 0.09710000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen2 Instruct 72B": {
      "id": "7656c62b-5345-435b-bf12-b6ce2ca0d58d",
      "name": "Qwen2 Instruct 72B",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.622,
        "gpqa": 0.371,
        "ifbench": null,
        "aime": 0.147,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.037,
        "scicode": 0.229,
        "livecodebench": 0.159,
        "coding_index": null,
        "intelligence_index": 11.7,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.3375,
        "Oracle": 0.27895000000000003,
        "Explorer": 0.06405000000000001,
        "Librarian": 1.2744,
        "Designer": 0.18975,
        "Fixer": 0.147425,
        "Builder": 0.09205
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 235B A22B (Reasoning)": {
      "id": "bbe6d782-e630-48d5-b11c-3ce37f373f1e",
      "name": "Qwen3 235B A22B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.828,
        "gpqa": 0.7,
        "ifbench": 0.387,
        "aime": 0.84,
        "math_index": 82,
        "terminalbench_hard": 0.061,
        "tau2": 0.24,
        "hle": 0.117,
        "scicode": 0.399,
        "livecodebench": 0.622,
        "coding_index": 17.4,
        "intelligence_index": 19.8,
        "speed": 58.746,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.3262500000000004,
        "Oracle": 12.90665,
        "Explorer": 1.04305,
        "Librarian": 2.2020000000000004,
        "Designer": 1.2196,
        "Fixer": 1.192525,
        "Builder": 1.96405
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 32B (Reasoning)": {
      "id": "b00ecd62-a53f-4aed-b833-3e9d6b0170ba",
      "name": "Qwen3 32B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.798,
        "gpqa": 0.668,
        "ifbench": 0.363,
        "aime": 0.807,
        "math_index": 73,
        "terminalbench_hard": 0.03,
        "tau2": 0.298,
        "hle": 0.083,
        "scicode": 0.354,
        "livecodebench": 0.546,
        "coding_index": 13.8,
        "intelligence_index": 16.5,
        "speed": 97.015,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.9875500000000004,
        "Oracle": 11.529349999999999,
        "Explorer": 0.86045,
        "Librarian": 1.8607000000000002,
        "Designer": 1.0213,
        "Fixer": 0.9893500000000001,
        "Builder": 1.58675
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 30B A3B (Reasoning)": {
      "id": "3e6cf518-a1f4-42d3-8fcf-827c9bd8e6d5",
      "name": "Qwen3 30B A3B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.777,
        "gpqa": 0.616,
        "ifbench": 0.415,
        "aime": 0.753,
        "math_index": 72.3,
        "terminalbench_hard": 0.023,
        "tau2": 0.26,
        "hle": 0.066,
        "scicode": 0.285,
        "livecodebench": 0.506,
        "coding_index": 11,
        "intelligence_index": 15.3,
        "speed": 74.395,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.858,
        "Oracle": 11.384599999999999,
        "Explorer": 0.7052,
        "Librarian": 1.7338500000000003,
        "Designer": 0.86865,
        "Fixer": 0.832675,
        "Builder": 1.2971000000000004
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 32B (Non-reasoning)": {
      "id": "bf60740e-6aa5-422f-ba49-ef6e9d171205",
      "name": "Qwen3 32B (Non-reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.727,
        "gpqa": 0.535,
        "ifbench": 0.315,
        "aime": 0.303,
        "math_index": 19.7,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.043,
        "scicode": 0.28,
        "livecodebench": 0.288,
        "coding_index": null,
        "intelligence_index": 14.5,
        "speed": 88.83,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7133000000000003,
        "Oracle": 3.3579499999999998,
        "Explorer": 0.07485,
        "Librarian": 1.6034500000000003,
        "Designer": 0.2786,
        "Fixer": 0.21889999999999998,
        "Builder": 0.14880000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 235B A22B (Non-reasoning)": {
      "id": "43573c57-2403-46fb-af4b-a93de9a0c3f5",
      "name": "Qwen3 235B A22B (Non-reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.762,
        "gpqa": 0.613,
        "ifbench": 0.366,
        "aime": 0.327,
        "math_index": 23.7,
        "terminalbench_hard": 0.061,
        "tau2": 0.272,
        "hle": 0.047,
        "scicode": 0.299,
        "livecodebench": 0.343,
        "coding_index": 14,
        "intelligence_index": 16.9,
        "speed": 48.492,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.009,
        "Oracle": 4.00545,
        "Explorer": 0.8709500000000001,
        "Librarian": 1.8822,
        "Designer": 1.00885,
        "Fixer": 0.9582750000000001,
        "Builder": 1.56915
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 14B (Non-reasoning)": {
      "id": "ecc6524a-d521-458a-8327-5009e8ce6549",
      "name": "Qwen3 14B (Non-reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.675,
        "gpqa": 0.47,
        "ifbench": 0.239,
        "aime": 0.28,
        "math_index": 58,
        "terminalbench_hard": 0.053,
        "tau2": 0.322,
        "hle": 0.042,
        "scicode": 0.265,
        "livecodebench": 0.28,
        "coding_index": 12.4,
        "intelligence_index": 12.7,
        "speed": 53.619,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5332999999999999,
        "Oracle": 9.0606,
        "Explorer": 0.7913000000000001,
        "Librarian": 1.43995,
        "Designer": 0.8668500000000001,
        "Fixer": 0.831925,
        "Builder": 1.3747
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 30B A3B (Non-reasoning)": {
      "id": "f3169f25-8c6f-48e4-ae87-0cf872dc0ec1",
      "name": "Qwen3 30B A3B (Non-reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.71,
        "gpqa": 0.515,
        "ifbench": 0.319,
        "aime": 0.26,
        "math_index": 21.7,
        "terminalbench_hard": 0.068,
        "tau2": 0.222,
        "hle": 0.046,
        "scicode": 0.264,
        "livecodebench": 0.322,
        "coding_index": 13.3,
        "intelligence_index": 12.4,
        "speed": 69.724,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.5195500000000002,
        "Oracle": 3.6378,
        "Explorer": 0.8210000000000001,
        "Librarian": 1.4144000000000003,
        "Designer": 0.93675,
        "Fixer": 0.8964500000000001,
        "Builder": 1.4812500000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen1.5 Chat 110B": {
      "id": "d1768b3a-0a21-4e08-b3f6-56a9ab6cfbf3",
      "name": "Qwen1.5 Chat 110B",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": 0.289,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 9.5,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.0078,
        "Oracle": 0.1445,
        "Explorer": 0.0,
        "Librarian": 0.9500000000000001,
        "Designer": 0.07225,
        "Fixer": 0.04334999999999999,
        "Builder": 0.0289
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 4B (Reasoning)": {
      "id": "191a2097-cce3-49cf-881e-0c790892059f",
      "name": "Qwen3 4B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.696,
        "gpqa": 0.522,
        "ifbench": 0.325,
        "aime": 0.657,
        "math_index": 22.3,
        "terminalbench_hard": null,
        "tau2": 0.19,
        "hle": 0.051,
        "scicode": 0.035,
        "livecodebench": 0.465,
        "coding_index": null,
        "intelligence_index": 14.2,
        "speed": 87.346,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.69655,
        "Oracle": 3.8095499999999998,
        "Explorer": 0.11964999999999999,
        "Librarian": 1.5911999999999997,
        "Designer": 0.27249999999999996,
        "Fixer": 0.239525,
        "Builder": 0.173
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 8B (Non-reasoning)": {
      "id": "b2dd592a-fbc5-458a-b26d-f3964cbab82f",
      "name": "Qwen3 8B (Non-reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.643,
        "gpqa": 0.452,
        "ifbench": 0.286,
        "aime": 0.243,
        "math_index": 24.3,
        "terminalbench_hard": 0.023,
        "tau2": 0.249,
        "hle": 0.028,
        "scicode": 0.168,
        "livecodebench": 0.202,
        "coding_index": 7.1,
        "intelligence_index": 10.6,
        "speed": 70.703,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.3146499999999999,
        "Oracle": 3.9852999999999996,
        "Explorer": 0.49215,
        "Librarian": 1.2183499999999998,
        "Designer": 0.59585,
        "Fixer": 0.544425,
        "Builder": 0.83195
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 8B (Reasoning)": {
      "id": "9dba61f5-78ee-4190-8d1d-8e7063ffd386",
      "name": "Qwen3 8B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.743,
        "gpqa": 0.589,
        "ifbench": 0.335,
        "aime": 0.747,
        "math_index": 19,
        "terminalbench_hard": 0.023,
        "tau2": 0.278,
        "hle": 0.042,
        "scicode": 0.226,
        "livecodebench": 0.406,
        "coding_index": 9,
        "intelligence_index": 13.1,
        "speed": 79.432,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.6173,
        "Oracle": 3.3703,
        "Explorer": 0.6051,
        "Librarian": 1.4953500000000002,
        "Designer": 0.7464,
        "Fixer": 0.7052,
        "Builder": 1.0737
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen2.5 Coder Instruct 7B ": {
      "id": "e410e854-104d-4b35-a171-899ff9d974bb",
      "name": "Qwen2.5 Coder Instruct 7B ",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.473,
        "gpqa": 0.339,
        "ifbench": null,
        "aime": 0.053,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.048,
        "scicode": 0.148,
        "livecodebench": 0.126,
        "coding_index": null,
        "intelligence_index": 10,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.13875,
        "Oracle": 0.22980000000000003,
        "Explorer": 0.0497,
        "Librarian": 1.08535,
        "Designer": 0.1605,
        "Fixer": 0.12075000000000001,
        "Builder": 0.07645
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 4B (Non-reasoning)": {
      "id": "e46198a7-cd29-4afd-933d-cdf180f0f305",
      "name": "Qwen3 4B (Non-reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.586,
        "gpqa": 0.398,
        "ifbench": null,
        "aime": 0.213,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.037,
        "scicode": 0.167,
        "livecodebench": 0.233,
        "coding_index": null,
        "intelligence_index": 12.5,
        "speed": 83.375,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.4175,
        "Oracle": 0.30205000000000004,
        "Explorer": 0.06045,
        "Librarian": 1.349,
        "Designer": 0.19110000000000002,
        "Fixer": 0.157425,
        "Builder": 0.10405
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 Max (Preview)": {
      "id": "5b2beb12-81a9-47a1-8a2a-d0a727185b50",
      "name": "Qwen3 Max (Preview)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.838,
        "gpqa": 0.764,
        "ifbench": 0.48,
        "aime": null,
        "math_index": 75,
        "terminalbench_hard": 0.197,
        "tau2": 0.327,
        "hle": 0.093,
        "scicode": 0.37,
        "livecodebench": 0.651,
        "coding_index": 25.5,
        "intelligence_index": 25.9,
        "speed": 44.058,
        "context_length": null,
        "GDPval_AA_ELO": 1161,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 351.2732,
        "Oracle": 11.72045,
        "Explorer": 1.524,
        "Librarian": 2.8243,
        "Designer": 349.94899999999996,
        "Fixer": 1.6321750000000002,
        "Builder": 2.78995
      },
      "lastCalculated": "2026-02-14"
    },
    "QwQ 32B": {
      "id": "ceb4d610-d0a4-48c1-bea0-80ed76f1e5ca",
      "name": "QwQ 32B",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.764,
        "gpqa": 0.593,
        "ifbench": 0.388,
        "aime": 0.78,
        "math_index": 29,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.082,
        "scicode": 0.358,
        "livecodebench": 0.631,
        "coding_index": null,
        "intelligence_index": 19.7,
        "speed": 28.294,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.2613999999999996,
        "Oracle": 4.882999999999999,
        "Explorer": 0.08050000000000002,
        "Librarian": 2.148,
        "Designer": 0.30984999999999996,
        "Fixer": 0.28835,
        "Builder": 0.21155000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "QwQ 32B-Preview": {
      "id": "8823351e-8232-4c9c-8a1d-cd2c1d2c1196",
      "name": "QwQ 32B-Preview",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.648,
        "gpqa": 0.557,
        "ifbench": null,
        "aime": 0.453,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.048,
        "scicode": 0.038,
        "livecodebench": 0.337,
        "coding_index": null,
        "intelligence_index": 15.2,
        "speed": 52.893,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.7286000000000001,
        "Oracle": 0.4363000000000001,
        "Explorer": 0.06720000000000001,
        "Librarian": 1.6316,
        "Designer": 0.24125,
        "Fixer": 0.19985000000000003,
        "Builder": 0.13865000000000002
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen Chat 72B": {
      "id": "41f73c27-880c-4f30-8b07-9999ce89a4ae",
      "name": "Qwen Chat 72B",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": null,
        "gpqa": null,
        "ifbench": null,
        "aime": null,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": null,
        "scicode": null,
        "livecodebench": null,
        "coding_index": null,
        "intelligence_index": 8.8,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 0.8800000000000001,
        "Oracle": 0.0,
        "Explorer": 0.0,
        "Librarian": 0.8800000000000001,
        "Designer": 0.0,
        "Fixer": 0.0,
        "Builder": 0.0
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen3 14B (Reasoning)": {
      "id": "4559e9f0-8aad-4681-89fb-68cb915e0f16",
      "name": "Qwen3 14B (Reasoning)",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.774,
        "gpqa": 0.604,
        "ifbench": 0.405,
        "aime": 0.763,
        "math_index": 55.7,
        "terminalbench_hard": 0.038,
        "tau2": 0.345,
        "hle": 0.043,
        "scicode": 0.316,
        "livecodebench": 0.523,
        "coding_index": 13.1,
        "intelligence_index": 16.2,
        "speed": 57.46,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.95215,
        "Oracle": 8.88915,
        "Explorer": 0.8360000000000001,
        "Librarian": 1.824,
        "Designer": 0.9669000000000001,
        "Fixer": 0.942025,
        "Builder": 1.5078
      },
      "lastCalculated": "2026-02-14"
    },
    "Qwen2.5 Instruct 32B": {
      "id": "1d0db5a3-3132-4213-a94b-c2e395d08283",
      "name": "Qwen2.5 Instruct 32B",
      "provider": "Alibaba",
      "benchmarks": {
        "mmlu_pro": 0.697,
        "gpqa": 0.466,
        "ifbench": null,
        "aime": 0.11,
        "math_index": null,
        "terminalbench_hard": null,
        "tau2": null,
        "hle": 0.038,
        "scicode": 0.229,
        "livecodebench": 0.248,
        "coding_index": null,
        "intelligence_index": 13.2,
        "speed": 0,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 1.51775,
        "Oracle": 0.3266,
        "Explorer": 0.0716,
        "Librarian": 1.43595,
        "Designer": 0.22485,
        "Fixer": 0.18252500000000002,
        "Builder": 0.11865
      },
      "lastCalculated": "2026-02-14"
    },
    "Seed-OSS-36B-Instruct": {
      "id": "5c6533f3-75a2-4109-b9a9-3623afc6b86a",
      "name": "Seed-OSS-36B-Instruct",
      "provider": "ByteDance Seed",
      "benchmarks": {
        "mmlu_pro": 0.815,
        "gpqa": 0.726,
        "ifbench": 0.419,
        "aime": null,
        "math_index": 84.7,
        "terminalbench_hard": 0.068,
        "tau2": 0.494,
        "hle": 0.091,
        "scicode": 0.365,
        "livecodebench": 0.765,
        "coding_index": 16.7,
        "intelligence_index": 25,
        "speed": 31.44,
        "context_length": null,
        "GDPval_AA_ELO": null,
        "SWE_bench_Verified": null,
        "SWE_bench_Pro": null
      },
      "roleScores": {
        "Orchestrator": 2.8797,
        "Oracle": 13.15405,
        "Explorer": 1.07175,
        "Librarian": 2.74085,
        "Designer": 1.1897499999999999,
        "Fixer": 1.189375,
        "Builder": 1.91905
      },
      "lastCalculated": "2026-02-14"
    }
  },
  "calculation_config": {
    "model_selection_benchmarks": {
      "Orchestrator": {
        "description": "The central and highly important model responsible for strategic coordination, parallel delegation, problem-solving, and ensuring adherence to instructions across the entire workflow.",
        "benchmarks": {
          "GDPval-AA ELO": {
            "weight": 0.3,
            "description": "Measures strategic decision-making, planning, and workflow orchestration, from Artificial Analysis GDPval-AA."
          },
          "gpqa": {
            "weight": 0.2,
            "description": "Evaluates advanced reasoning and complex problem-solving abilities, crucial for overcoming workflow challenges, from Artificial Analysis API."
          },
          "mmlu_pro": {
            "weight": 0.15,
            "description": "Assesses general knowledge and multi-task language understanding, vital for comprehending diverse tasks, from Artificial Analysis API."
          },
          "intelligence_index": {
            "weight": 0.1,
            "description": "Overall intelligence index, reflecting the model's capacity for autonomous problem-solving, from Artificial Analysis API."
          },
          "ifbench": {
            "weight": 0.15,
            "description": "Measures precise instruction following, critical for adhering to workflow directives, from Artificial Analysis API."
          },
          "tau2": {
            "weight": 0.1,
            "description": "General efficiency and speed proxy, important for parallel delegation, from Artificial Analysis API and Tau\u00c2\u00b2-Bench."
          }
        },
        "scoring_algorithm": "(GDPval-AA_ELO * 0.3) + (gpqa * 0.2) + (mmlu_pro * 0.15) + (intelligence_index * 0.1) + (ifbench * 0.15) + (tau2 * 0.1)"
      },
      "Oracle": {
        "description": "Architectural guidance and complex debugging. Requires advanced reasoning and problem-solving.",
        "benchmarks": {
          "gpqa": {
            "weight": 0.5,
            "description": "Evaluates advanced reasoning and complex problem-solving abilities, from Artificial Analysis API."
          },
          "aime": {
            "weight": 0.2,
            "description": "Assesses mathematical reasoning and problem-solving, from Artificial Analysis API."
          },
          "math_index": {
            "weight": 0.15,
            "description": "Overall mathematical capability index, from Artificial Analysis API."
          },
          "mmlu_pro": {
            "weight": 0.1,
            "description": "Assesses general knowledge for broader architectural advice, from Artificial Analysis API."
          },
          "hle": {
            "weight": 0.05,
            "description": "Measures comprehensive knowledge for debugging and understanding complex systems, from Artificial Analysis API and Humanity's Last Exam."
          }
        },
        "scoring_algorithm": "(gpqa * 0.5) + (aime * 0.2) + (math_index * 0.15) + (mmlu_pro * 0.1) + (hle * 0.05)"
      },
      "Explorer": {
        "description": "Codebase discovery and pattern matching. Requires high speed and effective computer interaction.",
        "benchmarks": {
          "terminalbench_hard": {
            "weight": 0.4,
            "description": "Measures efficiency in terminal interaction and tool use, from Artificial Analysis API and Terminal-Bench."
          },
          "tau2": {
            "weight": 0.25,
            "description": "General efficiency and speed proxy, from Artificial Analysis API and Tau\u00c2\u00b2-Bench."
          },
          "context_length": {
            "weight": 0.15,
            "description": "Indicates capacity to handle large inputs and codebases, from OpenRouter API."
          },
          "mmlu_pro": {
            "weight": 0.1,
            "description": "Assesses general knowledge for understanding search queries and context, from Artificial Analysis API."
          },
          "hle": {
            "weight": 0.05,
            "description": "Measures comprehensive knowledge for better discovery and contextual understanding, from Artificial Analysis API and Humanity's Last Exam."
          },
          "coding_index": {
            "weight": 0.05,
            "description": "Overall coding capability index, for understanding code structures during discovery, from Artificial Analysis API."
          }
        },
        "scoring_algorithm": "(terminalbench_hard * 0.4) + (tau2 * 0.25) + (context_length / MAX_CONTEXT_LENGTH * 0.15) + (mmlu_pro * 0.1) + (hle * 0.05) + (coding_index * 0.05)"
      },
      "Librarian": {
        "description": "Responsible for gathering context, inferring needs, synthesizing multiple sources into concise packets for context compression, and handling all writing tasks.",
        "benchmarks": {
          "hle": {
            "weight": 0.3,
            "description": "Measures comprehensive knowledge retrieval and understanding, crucial for inferring needs and synthesizing information, from Artificial Analysis API and Humanity's Last Exam."
          },
          "context_length": {
            "weight": 0.25,
            "description": "Indicates capacity to handle and compress large documents and conversations, from OpenRouter API."
          },
          "mmlu_pro": {
            "weight": 0.15,
            "description": "Assesses general language understanding and coherence, vital for effective writing and synthesis, from Artificial Analysis API."
          },
          "intelligence_index": {
            "weight": 0.1,
            "description": "Reflects the model's ability to infer complex needs and generate insightful summaries, from Artificial Analysis API."
          },
          "ifbench": {
            "weight": 0.1,
            "description": "Measures precise instruction following, for accurate synthesis and writing instructions, from Artificial Analysis API."
          },
          "tau2": {
            "weight": 0.1,
            "description": "General efficiency and speed proxy, for efficient processing and synthesizing, from Artificial Analysis API and Tau\u00c2\u00b2-Bench."
          }
        },
        "scoring_algorithm": "(hle * 0.3) + (context_length / MAX_CONTEXT_LENGTH * 0.25) + (mmlu_pro * 0.15) + (intelligence_index * 0.1) + (ifbench * 0.1) + (tau2 * 0.1)"
      },
      "Designer": {
        "description": "Creates implementation plans for problems, researches code, and designs architectural solutions. Focuses on planning and research, not UI/UX creation.",
        "benchmarks": {
          "GDPval-AA ELO": {
            "weight": 0.3,
            "description": "Measures strategic planning and architectural design capabilities, from Artificial Analysis GDPval-AA."
          },
          "gpqa": {
            "weight": 0.25,
            "description": "Evaluates advanced reasoning for complex problem decomposition and solution design, from Artificial Analysis API."
          },
          "mmlu_pro": {
            "weight": 0.15,
            "description": "Assesses general knowledge and understanding for diverse problem domains, from Artificial Analysis API."
          },
          "hle": {
            "weight": 0.1,
            "description": "Measures comprehensive knowledge retrieval for thorough research and planning, from Artificial Analysis API and Humanity's Last Exam."
          },
          "ifbench": {
            "weight": 0.1,
            "description": "Measures precise instruction following, for adhering to planning constraints, from Artificial Analysis API."
          },
          "coding_index": {
            "weight": 0.05,
            "description": "Overall coding capability index, for understanding code structure in plans, from Artificial Analysis API."
          },
          "context_length": {
            "weight": 0.05,
            "description": "Indicates capacity to handle large design documents, from OpenRouter API."
          }
        },
        "scoring_algorithm": "(GDPval-AA_ELO * 0.3) + (gpqa * 0.25) + (mmlu_pro * 0.15) + (hle * 0.1) + (ifbench * 0.1) + (coding_index * 0.05) + (context_length / MAX_CONTEXT_LENGTH * 0.05)"
      },
      "Fixer": {
        "description": "The most critical and powerful model in the workflow, responsible for all development, implementation, and ensuring the entire workflow's success. Requires exceptional reasoning, instruction following, and comprehensive coding excellence, including live coding performance and efficient tool interaction.",
        "benchmarks": {
          "gpqa": {
            "weight": 0.15,
            "description": "Evaluates advanced reasoning and complex problem-solving abilities, crucial for development challenges, from Artificial Analysis API."
          },
          "SWE-bench Pro": {
            "weight": 0.15,
            "description": "Evaluates performance on complex software engineering tasks, reflecting real-world development capability, from Scale SEAL."
          },
          "SWE-bench Verified": {
            "weight": 0.15,
            "description": "Measures ability to verify and debug code, essential for robust development, from Live-SWE-agent."
          },
          "livecodebench": {
            "weight": 0.15,
            "description": "Measures live coding performance, critical for dynamic development and rapid iteration, from Artificial Analysis API."
          },
          "terminalbench_hard": {
            "weight": 0.1,
            "description": "Measures efficiency in terminal interaction and tool use, vital for navigating development environments, from Artificial Analysis API and Terminal-Bench."
          },
          "mmlu_pro": {
            "weight": 0.1,
            "description": "Assesses general language understanding, crucial for comprehending diverse requirements and generating clear code, from Artificial Analysis API."
          },
          "ifbench": {
            "weight": 0.05,
            "description": "Measures precise instruction following, critical for accurate implementation, from Artificial Analysis API."
          },
          "coding_index": {
            "weight": 0.05,
            "description": "Overall coding capability index, providing a holistic view of development prowess, from Artificial Analysis API."
          },
          "scicode": {
            "weight": 0.025,
            "description": "Measures scientific code generation, useful for specialized development tasks, from Artificial Analysis API."
          },
          "tau2": {
            "weight": 0.025,
            "description": "General efficiency and speed proxy, contributing to overall development speed, from Artificial Analysis API and Tau\u00c2\u00b2-Bench."
          }
        },
        "scoring_algorithm": "(gpqa * 0.15) + (SWE-bench_Pro * 0.15) + (SWE-bench_Verified * 0.15) + (livecodebench * 0.15) + (terminalbench_hard * 0.1) + (mmlu_pro * 0.1) + (ifbench * 0.05) + (coding_index * 0.05) + (scicode * 0.025) + (tau2 * 0.025)"
      },
      "Builder": {
        "description": "An agent for code generation and verification, used when bypassing the full workflow. Shares similar development needs with Fixer but is invoked directly for specific code tasks.",
        "benchmarks": {
          "SWE-bench Pro": {
            "weight": 0.3,
            "description": "Evaluates performance on complex software engineering tasks, from Scale SEAL."
          },
          "SWE-bench Verified": {
            "weight": 0.25,
            "description": "Measures ability to verify and debug code, from Live-SWE-agent."
          },
          "livecodebench": {
            "weight": 0.15,
            "description": "Measures live coding performance, from Artificial Analysis API."
          },
          "coding_index": {
            "weight": 0.1,
            "description": "Overall coding capability index, from Artificial Analysis API."
          },
          "gpqa": {
            "weight": 0.1,
            "description": "Evaluates advanced reasoning for complex code generation, from Artificial Analysis API."
          },
          "ifbench": {
            "weight": 0.05,
            "description": "Measures precise instruction following, for accurate code generation, from Artificial Analysis API."
          },
          "mmlu_pro": {
            "weight": 0.05,
            "description": "Assesses general knowledge for understanding diverse requirements, from Artificial Analysis API."
          }
        },
        "scoring_algorithm": "(SWE-bench_Pro * 0.3) + (SWE-bench_Verified * 0.25) + (livecodebench * 0.15) + (coding_index * 0.1) + (gpqa * 0.1) + (ifbench * 0.05) + (mmlu_pro * 0.05)"
      }
    }
  },
  "benchmark_mapping": {}
}